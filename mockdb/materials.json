[
  {
    "id": "d7915091-ac1c-4acc-bd26-4736db74a0ca",
    "title": "inzynierka.pdf",
    "content": {
      "type": "text",
      "content": "WYDZIAŁ FIZYKI I INFORMATYKI STOSOWANEJ\nKATEDRA INFORMATYKI STOSOWANEJ I FIZYKI KOMPUTEROWEJ\nProjekt dyplomowy\nSymulacyjna gra 3D oparta o własny silnik napisany z\nwykorzystaniem OpenGL\n3D simulation game based on a custom game engine written using\nOpenGL\nAutor:Piotr Krzysztof Jasiński\nKierunek studiów:Informatyka Stosowana\nOpiekun pracy:dr inż. Janusz Malinowski\nKraków, 2021\n\nSpis treści\n1  Wstęp3\n1.1Cel pracy .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .3\n1.2Istniejące rozwiązania   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .3\n1.2.1OGRE   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .3\n1.2.2Irrlicht   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .4\n1.2.3Unreal Engine   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .4\n1.2.4Raylib   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .4\n1.3Wykorzystane technologie  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .4\n2  Prezentacja aplikacji6\n2.1Część pierwsza - silnik  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .6\n2.1.1Przedstawienie modułów    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .6\n2.1.2Możliwości silnika   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .7\n2.1.3Przykład użycia   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .7\n2.2Część druga - gra pokazowa .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .9\n3  Implementacja13\n3.1Informacje wstępne    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .13\n3.1.1Wierzchołki   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .13\n3.1.2Shader  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .13\n3.2Wyświetlanie grafiki  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .14\n3.2.1Renderer  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .14\n3.2.2Renderable .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .14\n3.3Kamera.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .15\n3.4Fizyka   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .16\n3.4.1Wykrywanie kolizji .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .16\n3.4.2Rozwiązywanie kolizji   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .17\n3.4.3Aplikacja sił i tarcia  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .18\n3.5Pętla gry  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .19\n4  Rezultaty22\n4.1Silnik  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .22\n4.2Gra 3D  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .22\n5  Podsumowanie23\n2\n\nRozdział 1\nWstęp\n1.1    Cel pracy\nCelem pracy było napisanie prostego silnika gier 3D oraz wykorzystanie go do stworzenia\npokazowej gry symulacyjnej.\nSilnik gier jest narzędziem, którego głównym celem jest wspomaganie tworzenia gier.\nTermin  ten  został  rozpowszechniony  w  latach  90-tych,  wraz  ze  wzrostem  popularności\narchitektury gier cechującej się dużym stopniem separacji pomiędzy podstawowymi mo-\ndułami gry, takimi jak system detekcji kolizji czy renderowania, od części odpowiedzialnej\nza nadanie grze konkretnego charakteru - map, tekstur i modeli, zasad gry. Zastosowanie\ntakiego  schematu  pozwala  na  ponowne  użycie  dużej  części  kodu,  co  dla  twórców  gier\njest znacznie bardziej ekonomiczne, niż pisanie każdej produkcji od podstaw[8].\nMotywacją  stojącą  za  wyborem  tematu  była  chęć  poznania  sposobu  działania  pro-\njektów w tej dziedzinie od podstaw.\n1.2    Istniejące rozwiązania\nObecnie istnieje wiele silników gier o różnych stopniach posiadanej funkcjonalności. Kilka\npopularnych rozwiązań zostało krótko opisane w kolejnych sekcjach.\n1.2.1    OGRE\nOGRE[19] (Object-Oriented Graphics Rendering Engine) jest silnikiem renderowania 3D\ndostępnym  na  licencji  MIT.  Głównym  językiem  programowania  dla  OGRE  jest  C++.\nJest to projekt typu otwarte źródło (ang.open source).\nW  wersji  podstawowej  silnik  ten  pozwala  jedynie  na  rendering  grafiki  3D,  animacje\noraz  dodatkowe  efekty  wizualne.  Moduły  umożliwiające  przykładowo  obsługę  audio  i\nfizyki mogą zostać łatwo dołączone, dzięki istnieniu wrapperów na zewnętrzne biblioteki\n(jak OgreBullet dla silnika fizycznego Bullet[21] czy OgreOggSound dla biblioteki audio\nOpenAL[20]).\nOGRE posiada wsparcie dla najważniejszych platform, między innymi: Microsoft Win-\ndows, Linux, macOS, Android, iOS.\n3\n\n1.2.2    Irrlicht\nIrrlicht[18]  to  silnik  renderowania  3D  wspierany  na  platformach  Microsoft  Windows,\nLinux  oraz  macOS.  Został  napisany  w  języku  C++.  Umożliwia  między  innymi  rende-\nrowanie  grafiki  3D,  animacje  postaci  oraz  detekcję  i  reakcje  na  kolizje.  Podobnie  jak\nOGRE, jest to projekt o otwartym źródle.\n1.2.3    Unreal Engine\nUnreal  Engine[17]  -  obecnie  w  wersji  4,  która  została  wydana  w  2014  roku  (wersja  5\nujawniona  13  maja  2020r,  przewidywana  do  wydania  na  2022r),  jest  silnikiem  dostęp-\nnym  na  licencji  zamkniętej.  Głównym  językiem  programowania  dla  Unreal  jest  C++,\nale  udostępnia  on  również  system  schematów  (ang.blueprints),  który  daje  możliwość\nprogramowania z użyciem graficznego edytora.\nSilnik  ten  jest  dostępny  na  wielu  platformach,  również  mobilnych  oraz  wirtualnej\nrzeczywistości.  Wspiera  bardzo  szeroki  zakres  funkcjonalności  umożliwiający  produkcję\ngier 3D różnych gatunków\n1\n.\nUnreal  od  wersji  3  wykorzystuje  do  symulacji  fizycznych  PhysX[4],  który  jest  ze-\nstawem narzędzi programistycznych (SDK) utrzymywanym przez przedsiębiorstwo NVI-\nDIA[3]. PhysX umożliwia między innymi wielowątkowe symulacje fizyczne dla brył sztyw-\nnych, miękkich i płócien a także symulacje cząsteczek (ang.particles) oraz płynów.\n1.2.4    Raylib\nRaylib[22] to niewielka biblioteka, której głównym założeniem jest prostota użytkowania\ni integracji. Została napisana w całości w C jako projekt o otwartym źródle, a jej struk-\ntura jest podzielona na moduły z jasno wydzielonymi odpowiedzialnościami. Umożliwia\nprogramowanie  gier  2D  oraz  3D  na  wiele  platform,  w  tym  Microsoft  Windows,  Linux,\nmacOS, Android i HTML5.\nW  raylib  można  znaleźć  moduły  związane  z  renderowaniem  grafiki  2D  oraz  3D,\nsystem audio, modeli wraz z animacjami oraz moduł fizyki.\n1.3    Wykorzystane technologie\nProjekt napisano przy użyciu języka programowania C++. Do renderowania grafiki został\nużyty OpenGL[15], który jest specyfikacją utrzymywaną przez organizację Khronos Group\nInc[9]. Specyfikacja ta definiuje API umożliwiające przeprowadzanie kalkulacji i rysowanie\nz zastosowaniem karty graficznej komputera\n2\n. Kod źródłowy jest budowany za pomocą\nnarzędzia  CMake[2].  Został  on  przetestowany  przez  autora  na  platformach  Microsoft\nWindows (Windows 10) oraz Linux (Ubuntu 20.04).\nDodatkowo użyte zostały biblioteki:\n•GLAD[16]  -  biblioteka  automatyzująca  proces  ładowania  wskaźników  do  funkcji\n1\nNiepełna  lista  gier  opartych  o  Unreal  dostępna  pod  adresem:https://en.wikipedia.org/\nwiki/List_of_Unreal_Engine_games.\n2\nOpenGL  jest  implementowany  przez  producentów  kart  graficznych  i  dostarczany  jako  część\noprogramowania ich produktów.\n4\n\ndefiniowanych przez API OpenGL’a\n3\n. Załadowanie wskaźników jest konieczne, aby\nkorzystać z funkcjonalności OpenGL nowszej niż w wersji 1.1.\n•GLFW[7] - wieloplatformowa biblioteka udostępniająca możliwość stworzenia kon-\ntekstu  OpenGL,  okna  oraz  obsługi  urządzeń  wejścia  (jak  klawiatura,  mysz,  joy-\nstick).\n•stb\nimage[1]  -  biblioteka  dekodująca  obrazy  w  popularnych  formatach  do  zrozu-\nmiałego dla OpenGL formatu tablicy kolorów pikseli.\nWszystkie z wykorzystanych bibliotek są, lub należą do projektów o otwartym źródle.\n3\nManualny proces ładowania wspomnianych wskaźników jest niepraktyczny i zależny od systemu\noperacyjnego. Użycie biblioteki jest podejściem mocno zalecanym przez Khronos Group [11].\n5\n\nRozdział 2\nPrezentacja aplikacji\n2.1    Część pierwsza - silnik\n2.1.1    Przedstawienie modułów\nNa  rysunku  2.1  przedstawiono  strukturę  kodu  silnika.  Wyodrębniono  w  nim  kilka  pod-\nstawowych modułów, których odpowiedzialność została krótko opisana poniżej:\n•camera-  rzutowanie  modeli  obiektów  na  ekran  przy  zachowaniu  odpowiedniej\nperspektywy.\n•graphics-  obsługa  karty  graficznej,  wysyłanie  odpowiednich  danych  i  poleceń\nw celu wyświetlenia na ekranie graficznych reprezentacji danych (renderowanie).\n•input- obsługa myszy i klawiatury.\n•math- przeprowadzanie operacji matematycznych na macierzach, wektorach oraz\nkwaternionach.\n•physics- aplikacja podstawowych praw fizyki na dynamicznych obiektach, ob-\nsługa kolizji.\n•utils-  pozostała  funkcjonalność  -  tworzenie  logów,  pomiar  czasu,  parsowanie\nplików w formacie.objoraz.mtl.\n•window- tworzenie i utrzymywanie okna oraz kontekstu OpenGL.\nRysunek 2.1: Główna struktura kodu silnika\n6\n\n2.1.2    Możliwości silnika\nDo głównych możliwości silnika należy:\n•Renderowanie 2D oraz 3D w rzucie ortogonalnym oraz perspektywie.\n•Przydzielanie  tekstur  i  materiałów  do  renderowanych  modeli.  Wpływ  przypisania\nmateriału  o  danych  własnościach[5]  do  modelu  przedstawiono  na  rysunku  2.2.\nModel posiadający teksturę przedstawiono na rysunku 2.4.\n•Ładowanie modeli z plików w formacie.objoraz materiałów z plików w formacie\n.mtl. Przykładowy wyrenderowany model przedstawiono na rysunku 2.3.\n•Możliwość dodania oświetlenia kierunkowego oraz punktowych źródeł światła.\n•Detekcja  i  reakcja  na  kolizje\n1\n.  Przykład  działania  reakcji  na  kolizje  pokazano  na\nrysunku 2.5.\n2.1.3    Przykład użycia\nNa listingu 1 pokazano przykład użycia silnika do stworzenia okienka, w którym wyren-\nderowany jest model. Efekt uruchomienia kodu jest widoczny na rysunku 2.6.\nNa początku programu (linie 1-4) zostaje stworzone okno oraz zachodzi kompilacja\nshadera\n2\n.\nNastępnie  (linie  5  -  14)  inicjalizowa  jest  kamera,  która  zostanie  wykorzystana  do\nrzutowania modeli na ekran. Jej kolejne argumenty to:\n1.  Okno na którym zostanie wyświetlony obraz\n2.  Pozycja początkowa kamery\n3.  Punkt, w który celuje kamera\n4.  Wektor ”góry” świata\n3\n5.  Proporcja szerokości okna do jego wysokości\n6.  Odległość kamery od najbliższych obiektów, które będą rzutowane na ekran (ang.\nnear clipping plane).\n7.  Odległość kamery od najdalszych obiektów, które będą rzutowane na ekran (ang.\nfar clipping plane).\n8.  Pole widzenia kamery w stopniach (ang.field of view).\n1\nObecnie detekcja kolizji zaimplementowana jedynie dla sfer i płaszczyzn.\n2\nshader (nazywany też programem cieniowania) - program działający na karcie graficznej kom-\npuera. W OpenGL należy napisać go w języku GLSL (OpenGL Shading Language), którego składnia\nprzypomina składnię C[13].\n3\nWektor ten jest potrzebny do jednoznacznego zdefiniowania pozycji kamery. Bez niego obrót\nkamery wokół wektora kierunku, w którym jest ona zwrócona pozostaje niezdefiniowany.\n7\n\nW kolejnej linii następuje inicjalizacja renderera i warstwy. Warstwa jest wprowadzo-\nną przez autora abstrakcją, pozwalającą na powiązanie shadera, renderera oraz kamery,\nczyli wszystkich komponentów potrzebnych do narysowania modelu na ekranie. Do zde-\nfiniowanej  warstwy  można  dodać  modele  oraz  źródła  światła.  Dodane  modele  zostaną\nnarysowane po wywołaniu metodyLayer::draw(). Przykładowym zastosowaniem tej\nabstrakcji może być użycie dwóch oddzielnych warstw do wyrenderowania świata 3D w\nperspektywie i nałożonego na nim interfejsu użytkownika w rzucie ortogonalnym.\nLinie 18 - 20 odpowiadają za wczytanie modelu. Następujący po nich blok (linie 22 -\n27) definiuje dodane później do warstwy światło kierunkowe.\nKończąca przykład pętlawhileodpowiada za odświeżanie okna w każdej klatce.\nListing 1: Przykład zastosowania silnika do wyrenderowania modelu z pliku\n1mrld::Window window(\"Test window\", 800, 600);\n2mrld::Shader s(\n3\"../src/graphics/shader/shader_files/sample_vertex.shader\",\n4\"../src/graphics/shader/shader_files/sample_fragment.shader\");\n5s.create_shader_program();\n6mrld::FPSCamera cam(\n7&window,\n8mrld::vec3(0.0f, 0.0f, 20.0f),\n9mrld::vec3(0.0f, 5.0f, 0.0f),\n10mrld::vec3(0.0f, 1.0f, 0.0f),\n114.0f/3.0f,\n121.0f,\n13500.0f,\n1445.0f);\n15mrld::Renderer3D r3(&s);\n16mrld::Layer layer3d(&s, &r3, &cam);\n17\n18mrld::Model tree = mrld::ObjModelParser::parse_obj_to_model(\n19\"../res/tree1.obj\", \"../res/tree1.mtl\");\n20layer3d.add(&tree);\n21\n22mrld::directional_light light;\n23light.direction = mrld::vec3(0.0f, -1.0f, -1.0f);\n24light.diffuse = mrld::vec3(1.0f, 1.0f, 1.0f);\n25light.specular = mrld::vec3(1.0f, 1.0f, 1.0f);\n26light.ambient = mrld::vec3(0.1f, 0.1f, 0.1f);\n27s.set_directional_light(light);\n28\n29while (!window.should_close()) {\n30window.clear();\n31layer3d.draw();\n32window.update();\n33}\n8\n\nRysunek 2.2: Porównanie obiektów o materiałach oddającymi własności świetlne\nodpowiednio: szmaragdu, czerwonego plastiku i żółtej gumy\n2.2    Część druga - gra pokazowa\nSilnik został wykorzystany do stworzenia prostej gry pokazowej. Gracz może poruszać się\npo  ograniczonym  świecie  za  pomocą  klawiszy  WSAD  oraz  skakać  przy  pomocy  spacji.\nŚwiat generowany jest poprzez wylosowanie pozycji i orientacji ustalonej ilości każdego\nz dodanych modeli.\nMożliwa jest prosta interakcja z dynamicznymi obiektami (kamienie oraz kłody) po-\nprzez przytrzymanie na nich lewego lub prawego przycisku myszy - obiekty zostaną wtedy\nodpowiednio odepchnięte lub przyciągnięte do pozycji gracza.\nZrzut ekranu z gry przedstawiono na rysunku 2.7.\nKod źródłowy silnika jest dostępny jako repozytorium GitHub pod linkiem:https:\n//github.com/pjasinski990/simple_game_engine.\nKod  źródłowy  gry  jest  dostępny  jako  repozytorium  GitHub  pod  linkiem:https:\n//github.com/pjasinski990/walking_simulator.\n9\n\nRysunek 2.3: Model wyrenderowany w silniku będącym częścią tej pracy\nRysunek 2.4: Model z teksturą wyrenderowany w silniku będącym częścią tej pracy\n10\n\nRysunek 2.5: Działanie wykrywania i reakcji na kolizje na przykładzie stosu modeli\nRysunek 2.6: Efekt uruchomienia prostego programu renderującego model\n11\n\nRysunek 2.7: Zrzut ekranu z gry będącej częścią tej pracy\n12\n\nRozdział 3\nImplementacja\n3.1    Informacje wstępne\nTa sekcja ma za zadanie przybliżyć Czytelnikowi sposób działania OpenGL oraz krótko\nwyjaśnić  kroki,  których  wykonanie  jest  konieczne  do  wyświetlenia  na  ekranie  grafiki.\nInformacje  te  są  niezbędne  do  zrozumienia  pewnych  aspektów  działania  opisywanego\nsilnika.\n3.1.1    Wierzchołki\nW OpenGL dane przekazywane są do karty graficznej w formacie strumienia wierzchoł-\nków  [14].  Wierzchołek  to  zestaw  danych  opisujących  dany  punkt  w  przestrzeni.  Każdy\nwierzchołek zawiera tą samą ilość cech, tak zwanych atrybutów (ang.vertex attributes).\nAtrybutami  mogą  być  przykładowo  pozycja  wierzchołka,  wektor  normalny  powierzchni\ndo  której  należy  dany  wierzchołek  lub  kolor.  W  opisywanym  silniku  wierzchołki  mają\nzawsze format analogiczny do układu zmiennych strukturyVertexData, której dekla-\nrację przedstawiono na listingu 2.\nListing 2: Deklaracja strukturyVertexData\n1struct VertexData\n2{\n3vec3 position;\n4vec3 normal;\n5vec2 tex_coord;\n6float tex_slot;\n7float material_slot;\n8uint32_t color;\n9};\n3.1.2    Shader\nShader jest programem wykonywanym przez kartę graficzną, działającym na określonym\netapie  procesowania  grafiki  [13].  OpenGL  wyróżnia  kilka  typów  shaderów  działających\n13\n\nna różnych etapach renderowania.\nAby wyrenderować grafikę przy pomocy OpenGL należy napisać i skompilować przy-\nnajmniej  shader  wierzchołków  (ang.vertex  shader).  W  tym  shaderze  typowo  dokonuje\nsię transformacji przekazanych jako atrybutu wierzchołków pozycji, w celu zrzutowania\nmodeli na ekran w odpowiedni sposób.\nDrugim  ważnym  typem  shadera  jest  shader  fragmentów  (ang.fragment  shader),\nktóry pozwala na przeprowadzenie obliczeń dla każdego fragmentu\n1\nznajdującego się we-\nwnątrz prymitywów\n2\nokreślonych przez przesłane wierzchołki. Typowym zastosowaniem\ntego shadera jest kolorowanie pikseli, w tym kolorami będącymi rezultatem próbkowania\ntekstur, a także kalkulacja oświetlenia.\nWspółrzędne  ekranu  używane  przez  OpenGL  należą  do  przedziałów[−1,1]dla  wy-\nsokości  i  szerokości.  Tylko  fragmenty  o  współrzędnych  należących  do  tego  przedziału\nzostaną narysowane.\n3.2    Wyświetlanie grafiki\n3.2.1    Renderer\nModułem odpowiedzialnym za wyświetlanie grafiki jest modułgraphics. Istotną klasą\njest  tuRenderer,  który  wytwarza  abstrakcję  od  poleceń  specyficznych  dla  OpenGL  i\nudostępnia prosty interfejs to renderowania obiektów o typach pochodnych odRende-\nrable.\nSilnik  definiuje  dwa  typy  dziedziczące  po  klasieRenderer.  Są  to  klasyRende-\nrer2DorazRenderer3D.Renderer2Djest  przystosowany  do  renderowaniaspri-\nte’ów, czyli dwu-wymiarowych obrazków.Renderer3Dmoże renderować trójwymiaro-\nwe modele.\nKlasaRendererimplementuje  stos  transformacji  (ang.transform  stack).  Może\non  zostać  zastosowany  do  nałożenia  transformacji  na  obiekty  dodawane  do  renderera.\nWykorzystanie  stosu  transformacji  polega  na  dodaniu  na  stos  macierzy  transformacji,\nktórej  mają  zostać  poddane  wierzchołki  każdego  dodanego  następnie  modelu  (metoda\nRenderer::push(const mat4 &, bool)).  Po  zakończeniu  dodawania  ostatnio\ndodana macierz może zostać zdjęta ze stosu za pomocąRenderer::pop().\nAby wyrenderować obiekt typuRenderable, należy najpierw aktywować w rendere-\nrze tryb dodawania obiektów, poprzez wywołanie jego metodyRenderer::begin().\nNastępnie  można  dodać  do  renderera  pożądany  obiekt  za  pomocą  metodyRende-\nrer::submit(Renderable &). Po zakończeniu dodawania należy wywołaćRen-\nderer::end(), po czym można narysować wszystkie dodane obiekty wywołując me-\ntodęRenderer::flush().\n3.2.2    Renderable\nSilnik  definiuje  dwa  typy  pochodne  odRenderable:  grupa  (Group)  i  obiekt,  który\nposiada graficzną reprezentację (Drawable). Pliki kodu źródłowego zawierające imple-\nmentację tych typów przedstawiono na rysunku 3.1.\n1\nW najprostszym przypadku fragment odpowiada pojedynczemu pikselowi, istnieje jednak moż-\nliwość powstania kilku fragmentów dla jednego piksela[10].\n2\nPrymityw  to  kształt  definiujący  sposób  interpretacji  wierzchołków  przesłanych  do  karty  gra-\nficznej[12]. W tej pracy zostały użyte wyłącznie prymitywy będące trójkątami.\n14\n\nRysunek 3.1: Pliki zawierające implementację klasRenderable\nGrupa  jest  typem  agregującym  obiektyRenderable.  Grupy  zawierają  listę  doda-\nnych  obiektów  renderowalnych  oraz  transformację,  której  podlegają  wszystkie  dodane\nobiekty.\nIstnieje możliwość zagnieżdżania grup w grupach, co pozwala na tworzenie hierarchii\nrenderowania, w której transformacja grupy niższego stopnia jest relatywna do transfor-\nmacji grupy wyższego stopnia.\nImplementacjaRenderer::submit(Renderable &)polega na wywołaniu wir-\ntualnej  metody  jej  argumentuRenderable::submit\nself(Renderer &).  Po-\nzwala to na stworzenie niestandardowych implementacji dla różnych typów pochodnych\nodRenderable. Implementację tej metody dla klasyGroupprzedstawiono na listin-\ngu   3. Metoda ta wykorzystuje stos transformacji renderera, w celu nałożenia transfor-\nmacji na wszystkie należące do grupy obiekty.\nListing 3: Implementacja metodyGroup::submit\nself(Renderer &\n1void Group::submit_self(Renderer &r)\n2{\n3r.push(_transformation);\n4r.begin();\n5for (auto &&item : _children) {\n6item->submit_self(r);\n7}\n8r.end();\n9r.pop();\n10}\n3.3    Kamera\nW  module  kamery  zaimplementowane  zostały  dwie  klasy  -OrthographicCamera\norazFPSCamera, które dziedziczą po abstrakcyjnej klasieCamera(struktura modułu\nprzedstawiona na rys. 3.2).\nDziałanie kamery opiera się na ustawianiu i aktualizacji macierzy projekcji i widoku\nw  shaderze  wierzchołków.  Pozycja  każdego  wierzchołka  jest  w  tym  shaderze  transfor-\n15\n\nRysunek 3.2: Struktura modułu kamery\nmowana przez wspomniane macierze, co daje iluzję ruchu kamery.\nMacierz  widoku  transformuje  wierzchołki  do  pozycji  naprzeciw  kamery.  Macierz  ta\nmoże zmieniać się w każdej klatce, ponieważ zależy od pozycji i orientacji kamery. Kod\nodpowiedzialny  za  obliczenie  nowej  macierzy  widoku  zawarty  jest  w  metodzieCame-\nra::update\nview().\nMacierz projekcji rzutuje obiekty znajdujące się naprzeciw kamery na ekran. W klasie\nOrthographicCameratworzy  ona  rzut  ortogonalny  a  w  klasieFPSCamera-  rzut\nperspektywiczny.\nDodatkowo  klasaFPSCamerazawiera  kod  obsługujący  mysz,  dzięki  czemu  użyt-\nkownik może sterować orientacją kamery w sposób znany z gier pierwszoosobowych.\nPrzechwytywanie kursora przez kamerę można włączyć lub wyłączyć wywołując me-\ntody, odpowiednio,FPSCamera::set\ncursordisabled()i\nFPSCamera::set\ncursorenabled().\n3.4    Fizyka\nKod  odpowiedzialny  za  nadawanie  obiektom  własności  fizycznych  znajduje  się  w  klasie\nPhysicsEngine. Klasa ta zawiera metodęstep(float), która przesuwa symulację\nfizyczną o czas podany jako jej argument. Czas kroku podawany jest w sekundach.\nSilnik pozwala na tworzenie dwóch rodzajów obiektów fizycznych: obiektów statycz-\nnych,  które  nie  podlegają  siłom,  ale  mogą  wchodzić  w  kolizje  (Body)  oraz  obiektów\ndynamicznych,  które  podlegają  siłom  i  mogą  na  ich  podstawie  ulec  przemieszczeniu\n(RigidBody).\n3.4.1    Wykrywanie kolizji\nSystem  wykrywania  kolizji  zaimplementowano  w  oparciu  o  klasęCollider.  Klasa  ta\nzawiera czysto wirtualną metodęcheck\ncollision, która jest przeładowana tak, aby\nprzyjmować jako argument zarówno typCollider, jak i każdy z jego typów pochod-\nnych (deklaracje wspomnianych metod wirtualnych przedstawiono na listingu 4).\nMetoda przyjmująca typ bazowyColliderw typach pochodnych jest zawsze za-\nimplementowana w sposób przedstawiony na listingu 5. Wykonanie drugiego wywołania\nna argumencie, którego typ nie jest znany oddelegowuje wywołanie do odpowiedniej me-\ntody\n3\n. Jest to wykorzystanie techniki nazywanejdouble dispatch, która jest popularnym\nrozwiązaniem dla problemu dwóch stopni polimorfizmu.\n3\nImplementacja w oparciu o [24].\n16\n\nWywołaniecheckcollisionzwraca  strukturęcollisionpoint.  Struktu-\nra  ta  zawiera  informacje  o  kolizji  potrzebne  do  rozwiązania  jej.  Deklaracjęcolli-\nsionpointprzedstawiono na listingu 6.\nListing 4: Deklaracje metod wirtualnych klasyCollider\n1virtual collision_point check_collision(\n2const transform &ta,\n3const Collider *o,\n4const transform &tb) const = 0;\n5\n6virtual collision_point check_collision(\n7const transform &ta,\n8const PlaneCollider *o,\n9const transform &tb) const = 0;\n10\n11virtual collision_point check_collision(\n12const transform &ta,\n13const SphereCollider *o,\n14const transform &tb) const = 0;\n15\n16virtual collision_point check_collision(\n17const transform &ta,\n18const RayCollider *o,\n19const transform &tb) const = 0;\nListing 5: Implementacjacheck\ncollisiondla argumentu będącego typem ba-\nzowym\n1inline collision_point check_collision(\n2const transform &ta,\n3const Collider *o,\n4const transform &tb) const override\n5{\n6return o->check_collision(tb, this, ta);\n7}\n3.4.2    Rozwiązywanie kolizji\nKolizje są rozwiązywane przez obiekty o typieSolver. Obiekty te mogą zostać dodane\ndoPhysicsEngineza pomocą metodyPhysicsEngine::add\nsolver(Solver *).\nW każdym kroku symulacji na wykrytych kolizjach będzie wywoływana wirtualna metoda\n17\n\nListing 6: Deklaracja strukturycollisionpoint\n1struct collision_point\n2{\n3vec3 a;// deepest point of body A in body B\n4vec3 b;// deepest point of body B in body A\n5vec3 normal;// b - a normalized (points towards body A)\n6float collision_depth;// distance between a and b\n7bool has_collision;\n8};\nSolver::solve(std::vector<collision\n4\n>, float)dla każdego dodanego\nsolvera.\nW pracy zaimplementowano trzy klasy dziedzidzące po klasieSolver:\n•SimplePositionSolver-  poprawia  pozycje  ciał  tak,  aby  usunąć  penetrację\npomiędzy nimi. Efekt osiąga poprzez przesunięcie ciał wzdłuż wektora normalnego\nkolizji\n5\n.\n•RecursivePositionSolver-  osiąga  efekt  analogiczny  doSimplePosi-\ntionSolver. Bierze pod uwagę, że rozwiązanie danej kolizji może pogłębić ko-\nlizję z innymi punktami kontaktowymi rozważanego ciała i zapobiega temu zjawi-\nsku\n6\n. Obecna implementacja może dawać w niektórych sytuacjach mało naturalny\nefekt.\n•ImpulseSolver- nadaje ciałom odpowiedni pęd po kolizji.\n3.4.3    Aplikacja sił i tarcia\nPrzemieszczenie  i  prędkość  ciała  obliczane  są  w  sposób  numeryczny,  na  podstawie  sił\ndziałających na ciało w danym kroku czasowym. Metoda aplikująca na ciała siły została\nprzedstawiona na listingu 7.\nUwzględnienie  tarcia  zostało  zaimplementowane  w  sposób  polegający  na  dodaniu\nsiły  tarcia,  gdy  prędkość  ciała  w  kierunku  grawitacji  jest  mniejsza  niż  ustalony  próg.\nRozwiązanie  to  jest  proste,  ale  wadliwe  -  problem  stwarza  przede  wszystkim  fakt,  że\nprędkość ciała nie będzie tłumiona gdy porusza się ono po nachylonej powierzchni.\n4\nTypcollisionjest strukturą opakowującącollisionpoint, zawierającą również wskaź-\nniki do ciał biorących udział w kolizji.\n5\nWektor normalny kolizji to znormalizowany wektor łączący najgłębsze punkty penetracji koli-\ndujących ciał.\n6\nImplementacja na podstawie [23].\n18\n\n3.5    Pętla gry\nW celu kontrolowania częstotliwości odświeżania silnika fizycznego, w części gry projektu\nzaimplementowano klasęGameLoop.\nJej implementacja opiera się o koncept ”generowania” czasu przez system rendero-\nwania  grafiki.  Czas  ten  jest  następnie  ”zużywany”  do  przesunięcia  symulacji  fizycznej\no  ilość  kroków  zależną  od  czasu,  jaki  zajęło  wykonanie  danej  klatki\n7\n.  Implementacja\nmetody  odpowiedzialnej  za  uruchomienie  i  utrzymanie  pętli  została  przedstawiona  na\nlistingu 9. Funkcja\ncallbackwywoływana w każdej klatce została przedstawiona na\nlistingu 8.\nListing 7: Kod odpowiedzialny za aplikację sił na dynamiczne obiekty\n1void PhysicsEngine::apply_forces(float dt)\n2{\n3for (uint32_t i = 0; i < _objects.size(); ++i) {\n4if (_objects[i]->is_dynamic()) {\n5physics_properties &props = _objects[i]->phys_properties;\n6\n7props.acceleration += _gravity * props.mass;\n8props.velocity += props.acceleration / props.mass * dt;\n9_objects[i]->t.position += props.velocity * dt;\n10\n11props.acceleration = vec3();\n12}\n13}\n14}\n7\nImplementacja na podstawie [6].\n19\n\nListing 8: Kod gry wywoływany w każdej klatce\n1void Game::step(uint64_t dt_micros, uint64_t accumulator)\n2{\n3Game &instance = Game::get_instance();\n4if (instance._window.should_close()) {\n5instance._loop.stop();\n6}\n7\n8while (accumulator > dt_micros) {\n9instance.handle_keys();\n10instance._physics_world.step(accumulator * 0.000001f);\n11instance._player->update(dt_micros * 0.000001f);\n12accumulator -= dt_micros;\n13\n14if (accumulator < dt_micros) {\n15instance._physics_world.update_models();\n16}\n17}\n18instance._physics_world.interpolate_previous_state(\n19static_cast<float>(accumulator) / static_cast<float>(dt_micros));\n20\n21instance._window.clear();\n22instance._world->draw();\n23instance._window.update();\n24}\n20\n\nListing 9: Pętla gry\n1void GameLoop::start()\n2{\n3_running = true;\n4uint64_t accumulator = 0u;\n5uint64_t current_time = _timer.get_elapsed_micros();\n6uint64_t fps_timer = 0u;\n7uint32_t fps = 0;\n8\n9// accumulator is assumed to be used to advance physics\n10// by maximum possible amount of time steps every frame\n11while (_running) {\n12uint64_t new_time = _timer.get_elapsed_micros();\n13uint64_t frame_time = new_time - current_time;\n14current_time = new_time;\n15accumulator += frame_time;\n16\n17_callback(_dt, accumulator);\n18accumulator %= _dt;\n19\n20if (_timer.get_elapsed_millis() - fps_timer > 1000u) {\n21fps_timer = _timer.get_elapsed_millis();\n22_last_fps = fps;\n23fps = 0;\n24}\n25++fps;\n26}\n27}\n21\n\nRozdział 4\nRezultaty\n4.1    Silnik\nGłównym  celem  tej  pracy  było  stworzenie  prostego  silnika  3D,  co  udało  się  osiągnąć.\nSilnik posiada najważniejsze moduły wymagane do stworzenia gry, czego dowodem jest\nnapisana na jego podstawie gra pokazowa.\nSilnik ma duży potencjał do rozwoju. Wiele funkcjonalności dostępnej w istniejących\nrozwiązaniach  jest  tu  ograniczona  lub  brakuje  jej  implementacji.  Przykładami  ważnych\nfunkcji, które nie zostały jeszcze dodane są renderowanie tekstu i odtwarzanie dźwięków.\nFizyka  w  silniku  ma  mocno  ograniczone  możliwości.  Kolejnymi  etapami  rozwoju\nmogłoby  być  tu  dodanie  wsparcia  dla  ruchu  kątowego  obiektów,  poprawienie  sposobu\naplikacji  tarcia  i  dodanie  możliwości  kolizji  z  innymi  kształtami  (jak  elipsoidy  i  obiekty\nwypukłe).\nRenderowanie obrazków 2D w klasieRenderer2Djest szybkie dzięki optymalizacji\nilości wywołań funkcji rysowania OpenGL (ang.draw calls), jednak podobna optymaliza-\ncja nie została wprowadzona w klasieRenderer3D, gdzie każdy model jest renderowany\noddzielnie. Grupowanie rysowania modeli 3D jest to jeden z wielu możliwych sposobów\nzwiększenia wydajności silnika. Optymalizacja jest kolejnym obszarem możliwego dalsze-\ngo rozwoju projektu.\n4.2    Gra 3D\nNapisana  gra  pokazuje  możliwości  istotnych  części  silnika:  do  stworzenia  warstwy  3D\noraz  warstwy  interfejsu\n1\nużyto  obu  z  dostępnych  w  silniku  klas  renderera  oraz  kamery.\nDodatkowo gra zaprezentowała możliwości systemu kolizji i dynamiki a także możliwość\nobsługi klawiatury i myszy.\n1\nWarstwa interfejsu wyświetla celownik na środku ekranu.\n22\n\nRozdział 5\nPodsumowanie\nNapisanie silnika gier 3D nie jest łatwym zadaniem. Projekty tego typu łączą wiele nieza-\nleżnych i szerokich pól nauki oraz programowania, co dla potencjalnego dewelopera może\nbyć  przytłaczające.  Jest  to  jednak  bardzo  dobra  dziedzina  do  nauki,  co  było  głównym\ncelem autora przy wyborze tematu projektu.\nPraca  pozwoliła  autorowi  na,  między  innymi,  zaznajomienie  się  z  systemem  ren-\nderowania  OpenGL,  odkrycie  wielu  nieznanych  mu  wcześniej  bibliotek  i  silników  gier,\nskorzystanie  z  nowych  technik  programowania  w  C++  oraz  zastosowanie  w  praktyce\nprostej metody różniczkowania numerycznego. Ponadto zaprezentowała dobrą okazję do\nodświeżenia informacji z algebry i podstaw fizyki.\nPodsumowując,  udało  się  spełnić  cel  wyznaczony  przez  temat,  a  proces  tworzenia\nprojektu okazał się dla autora wartościowy i rozwijający.\n23\n\nBibliografia\n[1]  Sean Barrett.Repozytorium  GitHub  stb,  do  którego  należy  stb\nimage.url:\nhttps://github.com/nothings/stb. (ostatni dostęp: 15.12.2021r).\n[2]  CMake.Oficjalna strona narzędzia CMake.url:https://cmake.org/. (ostat-\nni dostęp: 15.12.2021r).\n[3]  NVIDIA Corporation.Oficjalna strona NVIDIA.url:https://www.nvidia.\ncom/. (ostatni dostęp: 15.12.2021r).\n[4]  NVIDIA Corporation.Oficjalna strona NVIDIA PhysX.url:https://developer.\nnvidia.com/physx-sdk. (ostatni dostęp: 15.12.2021r).\n[5]  Frederic Devernay.Lista własności świetlnych przykładowych materiałów.url:\nhttp://devernay.free.fr/cours/opengl/materials.html. (ostatni do-\nstęp: 15.12.2021r).\n[6]  Glenn Fiedler.Fix your timestep!url:https://gafferongames.com/post/\nfix_your_timestep/. (ostatni dostęp: 15.12.2021r).\n[7]  GLFW.Oficjalna  strona  biblioteki  GLFW.url:https://www.glfw.org/.\n(ostatni dostęp: 15.12.2021r).\n[8]  Jason Gregory. “Game Engine Architecture, 2nd edition”. In: CRC Press,\n2015. Chap. 1.3.\n[9]  Khronos Group.Oficjalna strona grupy Khronos.url:https://www.khronos.\norg/. (ostatni dostęp: 15.12.2021r).\n[10]  Khronos Group.Oficjalna  strona  grupy  Khronos  -  Fragment.url:https:\n//www.khronos.org/opengl/wiki/fragment. (ostatni dostęp: 15.12.2021r).\n[11]  Khronos Group.Oficjalna  strona  grupy  Khronos  -  ładowanie  wskaźników  do\nfunkcji  OpenGL.url:https://www.khronos.org/opengl/wiki/OpenGL_\nLoading_Library. (ostatni dostęp: 15.12.2021r).\n[12]  Khronos Group.Oficjalna  strona  grupy  Khronos  -  Primitive.url:https:\n//www.khronos.org/opengl/wiki/Primitive. (ostatni dostęp: 15.12.2021r).\n[13]  Khronos Group.Oficjalna strona grupy Khronos - Shader.url:https://www.\nkhronos.org/opengl/wiki/shader. (ostatni dostęp: 15.12.2021r).\n[14]  Khronos Group.Oficjalna  strona  grupy  Khronos  -  Vertex  Specification.url:\nhttps://www.khronos.org/opengl/wiki/Vertex_Specification. (ostatni\ndostęp: 15.12.2021r).\n[15]  Khronos Group.Oficjalna  strona  specyfikacji  OpenGL.url:https://www.\nopengl.org/. (ostatni dostęp: 15.12.2021r).\n24\n\n[16]  David Herberth.Repozytorium GitHub biblioteki GLAD.url:https://github.\ncom/Dav1dde/glad. (ostatni dostęp: 15.12.2021r).\n[17]  Epic Games Inc.Oficjalna strona silnika Unreal Engine.url:https://www.\nunrealengine.com. (ostatni dostęp: 15.12.2021r).\n[18]  Irrlicht.Oficjalna strona silnika Irrlicht.url:https://irrlicht.sourceforge.\nio/. (ostatni dostęp: 15.12.2021r).\n[19]  OGRE.Oficjalna  strona  silnika  OGRE.url:https://www.ogre3d.org/.\n(ostatni dostęp: 15.12.2021r).\n[20]  OpenAL.Oficjalna  strona  biblioteki  OpenAL.url:https://www.openal.\norg/. (ostatni dostęp: 15.12.2021r).\n[21]  Bullet Physics.Repozytorium  GitHub  silnika  fizycznego  Bullet.url:https:\n//github.com/bulletphysics/bullet3. (ostatni dostęp: 15.12.2021r).\n[22]  Raylib.Oficjalna strona raylib.url:https://www.raylib.com/index.html.\n(ostatni dostęp: 15.12.2021r).\n[23]  Florian Schornbaum.A  Real-time  Capable  Impulse-based  Collision  Response\nAlgorithm  for  Rigid  Body  Dynamics.url:https://www10.cs.fau.de/\npublications/theses/2010/Schornbaum_DA_2010.pdf. (ostatni dostęp:\n15.12.2021r).\n[24]  Iain Winter.Designing  a  physics  engine.url:https://blog.winter.dev/\n2020/designing-a-physics-engine/. (ostatni dostęp: 15.12.2021r).\n25",
      "metadata": {
        "pages": 25,
        "info": {
          "PDFFormatVersion": "1.5",
          "IsAcroFormPresent": false,
          "IsXFAPresent": false,
          "Title": "Overleaf Example",
          "Author": "",
          "Subject": "",
          "Keywords": "",
          "Creator": "LaTeX with hyperref",
          "Producer": "pdfTeX-1.40.21",
          "CreationDate": "D:20240609073752Z",
          "ModDate": "D:20240609073752Z",
          "Trapped": {
            "name": "False"
          }
        },
        "metadata": null
      }
    }
  },
  {
    "id": "743fc6b5-e2b5-487b-a60f-747a2c727c09",
    "title": "magisterka.pdf",
    "content": {
      "type": "text",
      "content": "WYDZIAŁ FIZYKI I INFORMATYKI STOSOWANEJ\nKATEDRA INFORMATYKI STOSOWANEJ I FIZYKI KOMPUTEROWEJ\nProjekt dyplomowy\nWykorzystanie systemów operacyjnych RTOS\nw urządzeniach wbudowanych\nRTOS operating system in embedded devices\nAutor:Piotr Krzysztof Jasiński\nKierunek studiów:  Informatyka Stosowana\nOpiekun pracy:dr inż. Krzysztof Świentek\nKraków, 2023\n\nSpis treści\nWstęp4\n1   Systemy operacyjne RTOS6\n1.1    Sposoby klasyfikacji   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .6\n1.1.1Klasyfikacja  ze  względu  na  sposób  uzyskania  zachowania  czasu\nrzeczywistego  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .6\n1.1.2Klasyfikacja ze względu na krytyczność dotrzymania terminu   .  .7\n1.2    RTOS a Superloop  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .7\n1.2.1Superloop  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .8\n1.2.2RTOS  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .8\n1.3    Algorytm szeregowania zadań (planista)  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .9\n1.3.1Zapisywanie kontekstu  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .9\n1.3.2Przełączanie wywłaszczające   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .11\n1.3.3Przełączanie kooperatywne   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .12\n1.4    Przerwania w systemach RTOS  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .14\n1.4.1SysTick   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .14\n1.4.2PendSV  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .14\n1.4.3SVCall .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .15\n1.5    Mechanizmy  komunikacji  międzyzadaniowej  w  systemach  czasu  rzeczy-\nwistego    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .17\n1.5.1Kolejka wiadomości   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .17\n1.5.2Semafor  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .18\n1.5.3Muteks   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .21\n1.5.4Flagi zdarzenia  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .22\n1.6    CMSIS .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .25\n1.7    CMSIS-RTOS .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .25\n2   FreeRTOS vs Keil RTX528\n2.1    Licencjonowanie i wsparcie    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .28\n2.1.1FreeRTOS .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .28\n2.1.2Keil RTX5   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .28\n2.1.3Podsumowanie   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .29\n2.2    Zarządzanie pamięcią .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .29\n2.2.1FreeRTOS .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .29\n2.2.2Keil RTX5   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .33\n2.2.3Podsumowanie   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .34\n2.3    Konfiguracja    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .35\n2.3.1FreeRTOS .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .35\n2\n\n2.3.2Keil RTX5   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .36\n2.3.3Podsumowanie   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .37\n2.4    Zadania   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .37\n2.4.1FreeRTOS .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .39\n2.4.2Keil RTX5   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .39\n2.4.3Podsumowanie   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .42\n2.5    Synchronizacja zadań .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .42\n2.5.1FreeRTOS .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .42\n2.5.2Keil RTX5   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .44\n2.5.3Podsumowanie   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .45\n2.6    Wydajność systemów .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .46\n2.6.1Pamięć    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .46\n2.6.2Prędkość    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .46\n2.6.3Podsumowanie   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .48\n3   Przykładowa aplikacja – Stacja Pogodowa49\n3.1    Komponenty   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .49\n3.2    System budowania   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .52\n3.3    Implementacja   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .54\n3.4    Zużycie pamięci .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .55\nWnioski59\nBibliografia61\n3\n\nWstęp\nObserwowany w ostatnich latach wzrost popularności urządzeń opartych o systemy wbu-\ndowane sprawia, że coraz bardziej potrzebne są również dedykowane dla nich efektywne\nrozwiązania i techniki programistyczne.\nSystemy wbudowane, czyli kompaktowe, zintegrowane systemy komputerowe po-\nsiadające ścisłą funkcję, stawiają przed programistami szereg unikalnych wyzwań, takich\njak ograniczona ilość dostępnych zasobów, utrudnione debugowanie, czy wymagania od-\nnośnie poboru energii (dla urządzeń pracujących na bateriach). W odpowiednim roz-\nwiązaniu wyzwania te powinny zostać zaadresowane tak, aby zapewnić niezawodność\noraz  bezpieczeństwo  użytkowania  produktu.  Aspekt  bezpieczeństwa  nabiera  szczegól-\nnego znaczenia dla urządzeń, których niepoprawne działanie może spowodować utratę\nżycia lub zdrowia (jak rozrusznik serca, system sterowania lotem, czy sterownik silnika\nwysokich obrotów).\nMimo, że na mikrokontrolerze działa zazwyczaj jeden program, systemy wbudowane\nnie są wolne od zagadnienia zrównoleglania obliczeń. W praktyce poprawne działanie\nsystemu tego typu często wiąże się z koniecznością wykonywania pewnych zadań „równo-\ncześnie” (np. obsługa łączności stosu Bluetooth, odczyt i przetwarzanie danych z ADC,\nobsługa GPIO). W miarę wzrostu stopnia złożoności systemu, naiwne rozwiązania (jak\nsuperpętla\n1\n) przestają się sprawdzać. Pojawia się problem efektywnej obsługi zadań blo-\nkujących, i podział czasu procesora staje się trudnym zagadnieniem o realnym wpływie\nna efektywność i bezpieczeństwo działania systemu.\nTypowym rozwiązaniem dla tego problemu jest wyposażenie systemu w znane z kom-\nputerów osobistych specjalne oprogramowanie, którego zadaniem jest stworzenie środo-\nwiska uruchamiania i kontroli zadań. Środowisko to, nazywane systemem operacyjnym,\njest odpowiedzialne za przydział czasu procesora do poszczególnych zadań, oraz za za-\npewnienie mechanizmów komunikacji i synchronizacji pomiędzy nimi.\nSystemy operacyjne znalazły swoje zastosowanie również w urządzeniach wbudowa-\nnych. Ze wspomnianych powodów bezpieczeństwa używany jest tutaj ich podzbiór nazy-\nwany systemami operacyjnymi czasu rzeczywistego (ang.Real Time Operating System\n–  RTOS). Główną różnicą, oraz istotnym założeniem zasady działania systemów typu\nczasu rzeczywistego, jest ich determinizm czasu reakcji na wydarzenie. Jeżeli działanie\nsystemu jest uważane za błędne w przypadku nie spełnienia terminu reakcji, system ten\nmożna nazwać systemem czasu rzeczywistego.\nW praktyce systemy RTOS spełniają założenie determinizmu czasu reakcji poprzez\nstosowanie  odpowiedniego  algorytmu  szeregowania  zadań  (planisty)  wraz  z  mechani-\nzmem priorytetów oraz wywłaszczania.\n1\nSuperpętla (ang.superloop) to wzorzec projektowy zakładający wykorzystanie głównej, nieskończo-\nnej pętli zawierającej wszystkie wykonywane zadania. Zostanie on opisany szerzej w późniejszej sekcji.\n4\n\nCelem  pracy  jest  opisanie  i  wyjaśnienie  zasady  działania  systemów  operacyjnych\nczasu rzeczywistego oraz poddanie analizie i porównaniu dwóch popularnych RTOSów:\nFreeRTOSa  [20]  oraz  systemu  Keil  RTX5  [6].  Porównanie  odbędzie  się  w  kontekście\nunifikującego API CMSIS-RTOS2 [5] dostarczanego przez ARM [2] oraz w oparciu o\nserię procesorów ARM Cortex-M.\nWszystkie opisy funkcjonalności przedstawianych systemów operacyjnych, a także\naplikacja  Stacja  Pogodowa,  napisana  jako  część  praktyczna  pracy,  zostały  oparte  na\nwersjach projektów:\n•FreeRTOS V10.3.1,\n•Keil RTX5.5.4.\n5\n\nRozdział 1\nSystemy operacyjne RTOS\nSystemy operacyjne czasu rzeczywistego (RTOS) są projektowane z myślą o obsłudze\naplikacji,  które  muszą  reagować  na  zdarzenia  w  określonym,  gwarantowanym  czasie.\nW przeciwieństwie do tradycyjnych systemów operacyjnych, które są optymalizowane\npod kątem maksymalnej wydajności i z myślą o doświadczeniu użytkownika (UX), RTOS\njest optymalizowany pod kątem przewidywalności i responsywności. Jego kluczową cechą\njest zdolność do deterministycznej reakcji na zdarzenia.\n1.1    Sposoby klasyfikacji\nW  systemach  czasu  rzeczywistego  (ang.real-time)  można  wyodrębnić  dwa  generalne\nsposoby klasyfikacji – podział ze względu na sposób uzyskiwania zachowania typu czasu\nrzeczywistego, oraz podział ze względu na krytyczność dotrzymania terminu\n1\n.\n1.1.1    Klasyfikacja ze względu na sposób uzyskania zachowania czasu\nrzeczywistego\n•Sprzęt(ang.Hardware) – najprostszy sposób realizacji nawet bardzo wymagają-\ncych (szybkich) założeń czasowych. Systemy sprzętowe mogą być implementowane\nza pomocą czipów logicznych, komponentów analogowych, czy urządzeń takich jak\nbezpośrednio programowalna macierz bramek (ang.Field Programmable Gate Ar-\nray – FPGA).\nSystemy czasu rzeczywistego oparte o sprzęt dobrze sprawdzają się w prostych za-\nstosowaniach, które wymagają natychmiastowego lub równoległego procesowania\ni  niewielkiego  poboru  mocy.  Ich  wadą  jest  przede  wszystkich  niska  elastyczność\ngotowego rozwiązania i duży nakład pracy i środków konieczny do ich realizacji.\n•Bare-metal  firmware– „systemybare-metal” to nazwa obejmująca rozwiąza-\nnia zbudowane bezpośrednio na sprzęcie, a więc bez wykorzystywania istniejącej\nwarstwy  abstrakcji  (takiej  jak  system  operacyjny).  Rozwiązania  tego  typu  dają\nprogramiście pełną kontrolę nad wszystkimi aspektami urządzenia. Implementacja\nrozwiązaniabare-metalmoże opierać się np. o wzorzec superpętli oraz wykorzy-\nstanie przerwań.\nRozwiązania tego typu sprawdzają się w problemach z niewielką ilością prostych\nzadań. Ich użyteczność maleje wraz ze wzrostem kompleksowości problemu. Trud-\n1\nSposoby klasyfikacji zaczerpnięte z książki Hands-On RTOS with Microcontrollers [1].\n6\n\nności  mogą  narastać  również  w  przypadku  konieczności  obsługi  przetwarzania\nasynchronicznego.\n•Firmware oparty o RTOS– o rozwiązaniu tego typu mówimy, gdy mamy do\nczynienia z mikrokontrolerem, na którym działa jądro (ang.kernel) wyposażone\nw  planistę  (ang.scheduler).  Dysponowanie  planistą  umożliwia  tu  programiście\nwykonywanie  pewnych  procesów  w  tle,  jednocześnie  utrzymując  responsywność\ndla krytycznych zadań.\nWśród zastosowań tego typu rozwiązań znajdą się bardziej skomplikowane aplika-\ncje, które byłoby trudno zgrabnie obsłużyć nie dysponując planistą. Wśród jego\nwad można wymienić wzrost kompleksowości kodu, który wiąże się z koniecznością\nobsługi współdzielenia danych pomiędzy zadaniami\n2\n.\n•Oprogramowanie (ang.software) oparte o RTOS– w przypadku tego typu\nrozwiązania mamy do czynienia z oprogramowaniem działającym na pełnowymia-\nrowym systemie operacyjnym sprawującym kontrolę nad urządzeniem wyposażo-\nnym w jednostkę zarządzania pamięcią (ang.Memory Management Unit – MMU)\noraz procesor (ang.Central Processing Unit – CPU).\nSystem  tego  typu  różni  się  od  tradycyjnego  systemu  operacyjnego  tym,  że  jest\nzaimplementowany w sposób, który uniemożliwia zablokowanie krytycznej operacji\nna nieskończony czas.\n•Standardowy  system  operacyjny–  dla  zastosowań,  w  których  wymagania\nczasowe nie są rygorystyczne, a przegapienie terminu operacji nie spowoduje nie-\nbezpiecznej sytuacji możliwe jest użycie nawet tradycyjnego systemu operacyjne-\ngo. W takim przypadku konieczny jest uważny dobór używanego oprogramowania\ni nadzorowanie konsumowanych przez nie zasobów.\n1.1.2    Klasyfikacja ze względu na krytyczność dotrzymania terminu\n•Hard  real-time  system– system czasu rzeczywistego typu „hard” musi speł-\nnić termin za każdym razem – w przeciwnym wypadku jego działanie uznaje się\nza  błędne.  Tego  typu  rozwiązania  stosuje  się  w  urządzeniach  medycznych  (jak\nrozrusznik serca) lub systemach kontrolnych o wyjątkowo ścisłych wymaganiach\nczasowych (jak system kontroli CNC urządzenia frezującego).\n•Firm real-time system– w systemie czasu rzeczywystiego typu „firm” terminu\nmuszą zostać dotrzymane prawie zawsze. Stosuje się je w przypadkach gdy ominię-\ncie terminu nie jest pożądane, ale konsekwencje tego nie są krytyczne w skutkach.\n•Soft real-time system– tego typu systemy mogą być najmniej ścisłe w dotrzy-\nmywaniu  terminów.  Oferują  jedynie  najlepsze  starania  (ang.best  efforts)  co  do\nich spełnienia.\n1.2    RTOS a Superloop\nUżycie systemu operacyjnego jest alternatywą dla prostego wzorca superpętli. Wybór\nmiędzy tymi architekturami jest podyktowany takimi czynnikami jak złożoność syste-\n2\nTerminy „wątek” i „zadanie” są w pracy używane wymiennie.\n7\n\nmu, występowanie zadań blokujących, istotność determinizmu czasu, i ilość dostępnej\npamięci.\n•Stopień  złożoności  systemu  –  superloop  jest  łatwy  do  użycia  tylko  w  mało  zło-\nżonych systemach. Trudność implementacji rośnie natomiast bardzo szybko wraz\nz ilością i skomplikowaniem zadań.\n•Występowanie zadań blokujących – superloop nie radzi sobie z zadniami blokują-\ncymi. Wywołanie takiego zadania w głównej pętli zagłodzi (ang.starve) pozostałe\nzadania.\n•Nacisk kładziony na determinizm systemu – jeżeli dotrzymanie terminu jest kry-\ntycznej wagi, lepszym wyborem będzie postawienie na dostarczany przez RTOS\nzarządzany system zadań oparty o priorytety.\n•Ilość dostępnej pamięci – należy pamiętać, że zastosowanie systemu RTOS wiąże\nsię z dodatkowym narzutem pamięci.\n1.2.1    Superloop\nSuperloop jest prostym w implementacji wzorcem zrównoleglającym, który dobrze spraw-\ndza się w aplikacjach o niewielkim stopniu skomplikowania. Może zostać z powodzeniem\nwykorzystany  w  systemach,  których  zadania  nie  są  blokujące,  a  ich  czas  wykonania\nprzewidywalny.\nImplementacja wzorca superloop została przedstawiona na listingu 1.1. Kod przed-\nstawia główną, nieskończoną pętlę, wykonującą kolejno zdefiniowane funkcje – zadania.\nWywoływane funkcje zostały nazwanecheck\nandexecutetask(sprawdź i wykonaj),\nponieważ  częstym  sposobem  na  radzenie  sobie  z  blokującymi  zadaniami  jest  zmiana\nblokowania na próbkowanie. Jeżeli zadanie nie ma żadnej pracy do wykonania, jest ono\npomijane.\nGłównymi wadami tego wzorca jest szybko rosnąca trudność implementacji większej\nilości zadań, brak możliwości ustalania priorytetów, brak automatycznego oszczędzania\nenergii (konieczność ręcznego wchodzenia w tryb niskiego poboru mocy), oraz trudność\nzaprojektowania sposobu koegzystencji zadań o zadanych czasach dostarczenia z zada-\nniami niskiej ważności.\n1.2.2    RTOS\nSystemy  operacyjne  czasu  rzeczywistego  są  projektowane  w  celu  rozwiązania  proble-\nmów występujących przy stosowaniu wzorca superloop. Mogą być z powodzeniem użyte\nw celu stworzenia skomplikowanej, skalowalnej aplikacji. Zadania blokujące są obsługi-\nwane z pomocą istniejących konstrukcji komunikacyjnych, które zapewniają efektywny\nprzydział czasu procesora, a system priorytetów ułatwia spełnianie wymagań czasowych\nsystemu.\nZastosowanie  systemu  operacyjnego  czasu  rzeczywistego  nie  ma  jednak  podstaw\nw  systemach,  które  z  powodzeniem  mogą  zostać  oparte  o  superloop.  Proste  aplika-\ncje mogą ucierpieć z powodu narzutu obliczeniowego i pamięciowego z jakim wiąże się\nintegracja systemu operacyjnego.\nPseudokod przedstawiający użycie systemu operacyjnego do uruchomienia kilku za-\ndań zaprezentowano na listingu 1.2\n3\n. Można łatwo zauważyć zmianę w sposobie uzy-\n3\nArgumentyparamsNsą teoretycznymi parametrami zadania. Mogą zawierać m.in. jego priorytet.\n8\n\nListing 1.1: Implementacja wzorca Superloop\n1check_and_execute_task1 () {\n2//  functionality 1\n3}\n4\n5check_and_execute_task2 () {\n6//  functionality 2\n7}\n8\n9...\n10check_and_execute_taskN () {\n11//  functionality N\n12}\n13\n14main() {\n15while  (1) {\n16check_and_execute_task1 ();\n17check_and_execute_task2 ();\n18...\n19check_and_execute_taskN ();\n20}\n21}\nskania  równoległości,  w  stosunku  do  wzorca  superloop.  W  tym  przypadku  na  każde\nzadanie przypada nieskończona pętla. Stworzenie iluzji wykonania równoległego zostaje\noddelegowane do wyspecjalizowanego modułu – planisty.\n1.3    Algorytm szeregowania zadań (planista)\nZapewne  najbardziej  istotną  funkcjonalnością  każdego  systemu  operacyjnego  jest  ta\ndostarczana przez planistę, a więc zdolność do przełączania kontekstu pomiędzy więcej\nniż jednym zadaniem programu.\nIstnieją dwa podstawowe rodzaje przełączania kontekstu:\n•przełączanie wywłaszczające,\n•przełączanie kooperatywne.\nW praktyce wiele systemów operacyjnych łączy oba podejścia, umożliwiając programi-\nstom wybór odpowiedniego rodzaju przełączania, w zależności od wymagań aplikacji.\n1.3.1    Zapisywanie kontekstu\nPrzełączenie wymaga uprzedniego zapisania aktualnego kontekstu. Pominięcie tego kro-\nku uniemożliwiło by późniejsze odtworzenie stanu obecnie wykonywanego zadania. Za-\npisanie kontekstu odbywa się poprzez wpisanie aktualnego stanu zadania do jegobloku\nkontrolnego(ang.TCB – Task Control BlocklubCB – Control Block)\n4\n.\n4\nImplementacje bloków kontrolnych systemów FreeRTOS i Keil RTX5 zostaną dokładniej omówione\nw późniejszym rozdziale.\n9\n\nListing 1.2: Przykład użycia systemu RTOS do uruchomienia kilku zadań\n1task1 () {\n2while (1) {\n3//  functionality 1\n4}\n5}\n6\n7task2 () {\n8while (1) {\n9//  functionality 2\n10}\n11}\n12\n13...\n14taskN () {\n15while (1) {\n16//  functionality N\n17}\n18}\n19\n20main() {\n21createTask1 (&task1 , params1);\n22createTask2 (&task2 , params2);\n23...\n24createTaskN (&taskN , params3);\n25startScheduler ();    //  never  returns\n26}\n27}\n10\n\nRysunek 1.1: Przełączanie wywłaszczające\nBlok kontrolny jest alokowany w momencie tworzenia zadania. Zawiera on pola nie-\nzbędne do opisania aktualnego stanu zadania i przywrócenia jest stanu. Zazwyczaj za-\nwiera takie dane jak:\n•wskaźnik stosu zadania (ang.SP – Stack Pointer),\n•licznik programu (ang.PC – Program Counter),\n•stan (np. „gotowy”, „zablokowany”),\n•identyfikator zadania,\n•priorytet,\n•nazwa zadania.\nDodatkowo  wymagane  jest  zapisanie  stanu  pozostałych  wykorzystywanych  aktualnie\nrejestrów. Zazwyczaj jest to osiągane poprzez położenie ich wartości na stosie zadania.\nW czasie odtwarzania stanu zadania, wartości te zostaną zdjęte ze stosu i skopiowane\ndo rejestrów.\n1.3.2    Przełączanie wywłaszczające\nPrzełączanie wywłaszczające(ang.preemptive context switching) – w tym rodzaju\nprzełączania, bieżące zadanie może być przerwane (wywłaszczone) przez planistę w do-\nwolnym  momencie,  zazwyczaj  na  rzecz  zadania  o  wyższym  priorytecie.  Przełączanie\nwywłaszczające jest przydatne w systemach czasu rzeczywistego, gdzie zadania o wy-\nsokim priorytecie muszą być obsługiwane w deterministycznym czasie. Wywłaszczanie\npozwala na osiągnięcie wysokiego stopnia responsywności systemu na istotne zdarzenia.\nDzięki  niemu  nie  trzeba  martwić  się  o  zadania  blokujące,  ani  o  zwalnianie  procesora\nw odpowiednich interwałach. O szybkie obsłużenie krytycznych zadań dba planista.\nPrzełączanie wywłaszczające pomiędzy trzema zadaniami o różnych priorytetach zo-\nstało zilustrowane na rysunku 1.1. Możemy zaobserwować na nim wywłaszczenie wątku\n„a” w momencie ustawienia wątku „b” o wyższym priorytecie w stan gotowości. Następ-\nnie wątek „b” zostaje wywłaszczony przez wątek „c”. Po zakończeniu poszczególnych\nważnych zadań („c”, „b”) wątek „a” jest kontynuowany.\nDo  wywłaszczenia  wątku  może  dojść  w  zdefiniowanych  dla  konkretnego  systemu\nmomentach. Przykłady tego typu zdarzeń przedstawiono poniżej.\n11\n\n•Moment zakończenia opóźnienia wątku o wyższym priorytecie;\n•Flaga zdarzenia (ang.event flag), na które oczekuje wątek o wyższym priorytecie\nzostała ustawiona\n5\n;\n•Zadanie o wyższym priorytecie oczekuje na token semafora, który został zwrócony;\n•Zadanie o wyższym priorytecie oczekuje na muteks, który został zwolniony;\n•Wiadomość,  na  którą  oczekuje  wątek  wyższego  priorytetu  została  wysłana  do\nkolejki;\n•Wątek o wyższym priorytecie próbuje wysłać do pełnej kolejki, z której została\nwłaśnie wyjęta wiadomość;\n•Priorytet obecnie wykonywanego zadania został obniżony, w skutek czego istnieje\nzadanie o wyższym priorytecie będące w stanie gotowości;\n•Priorytet innego, gotowego do wykonania zadania został podniesiony do wyższego\nniż obecny kontekst.\nOpóźnienia zadań są aktualizowane w przerwaniu regulatora czasowego (ang.timer)\nbędącego podstawą czasową systemu operacyjnego (zazwyczaj SysTick). Jeśli w danym\nwykonaniu przerwania zakończy się opóźnienie wątku wyższego priorytetu, obecny kon-\ntekst zostanie wywłaszczony na rzecz owego wątku.\nKwantowanie czasu(dzielenie czasu, ang.time slicing) to metoda planowania po-\nlegająca na przydzielaniu zadaniom krótkich przedziałów czasu (kawałków, ang.slices)\npo upływie których kontekst jest przełączany. Daje to iluzję jednoczesnego wykonania\nwielu zadań.\nW systemach typu RTOS, technika ta jest stosowana głównie w celu zapewnienia,\nże  żadne  z  zadań  nie  zostanie  pozbawione  dostępu  do  czasu  procesora  i  nie  będzie\n„głodować”. Jest to szczególnie ważne w scenariuszach, w których wiele zadań ma taki\nsam priorytet.\nKwantowanie czasu można zaklasyfikować jako formę przełączania wywłaszczające-\ngo. W tym przypadku wywłaszczenie następuje zazwyczaj w celu przełączenia kontekstu\nna inne zadanie o tym samym priorytecie. Zilustrowano to na rysunku 1.2, gdzie przerwa-\nnie przełącza kontekst pomiędzy dwoma zadaniami po upływie sprecyzowanego kwantu\n(ang.slice) czasu. Rysunek jest również wizualizacjąalgorytmu karuzelowego\n6\n(ang.\nround-robin), często wykorzystywanego jako algorytm przełączania w kwantowaniu cza-\nsu.\n1.3.3    Przełączanie kooperatywne\nPrzełączanie kooperatywne jest typem przełączania, w którym to zadania są odpowie-\ndzialne za zwrócenie kontroli nad CPU do planisty. Uruchomione zadanie kontynuuje\nwykonanie do momentu zakończenia, zablokowania w oczekiwaniu na zasób, lub dobro-\nwolnego zrzeczenia się procesora poprzez wywołanie odpowiedniej funkcji.\n5\nZdarzenia i inne konstrukcje sygnalizacyjne (muteksy, semafory) zostaną szerzej opisane w dalszych\nsekcjach.\n6\nAlgorytm karuzelowy polega na obsługiwaniu kilku kolejek oczekujących konsumentów po jednym\nz każdej kolejki naraz, w stałym porządku.\n12\n\nRysunek 1.2: Kwantowanie czasu\nRysunek 1.3: Przełączanie kooperatywne\nW czysto kooperatywnym systemie nie występują wywłaszczenia. Tego typu model\nmoże  stanowić  zagrożenie  dla  wymagań  czasowych,  ponieważ  źle  zaprojektowane  za-\ndania mają możliwość zablokowania procesora na dłuższy czas, przez co dotrzymanie\nterminu w zadaniu o wyższym priorytecie będzie niemożliwe.\nPrzełączanie kooperatywne pomiędzy dwoma zadaniami o różnych priorytetach zo-\nstało zilustrowane na rysunku 1.3. Procedura obsługi przerwania (ang.Interrupt Service\nRoutine  –  ISR)  przełącza  tutaj  zadanie  o  wysokim  priorytecie  w  stan  gotowości,  ale\nkontekst zostaje przełączony dopiero po zwolnieniu procesora przez zadanie o niższym\npriorytecie. Przykładem sytuacji, w której przełączanie kooperatywne działa optymal-\nnie jest aplikacja o dobrze zdefiniowanych zadaniach, których szansa na zablokowanie\nprocesora przez dłuższy czas jest znikoma. Taki system może skorzystać z głównej zalety\nprzełączania kooperatywnego, jaką jest brak ryzyka przełączenia w nieoczekiwanym mo-\nmencie. Zadania w systemie kooperatywnym nie muszą być pisane z troską o możliwość\nzmiany kontekstu w krytycznej sekcji kodu. Dodatkowym atutem jest mniejszy narzut\noperacyjny, związany z brakiem konieczności ciągłego monitorowania zadań o wyższym\npriorytecie.\n13\n\n1.4    Przerwania w systemach RTOS\nPrzerwania są bardzo użytecznym mechanizmem, wykorzystywanym ekstensywnie za-\nrówno w systemach obliczeniowych ogólnego przeznaczenia, jak i w systemach wbudo-\nwanych. Pozwalają na natychmiastową odpowiedź na predefiniowane zdarzenie. Zdarze-\nniem tym może być naciśnięciem przycisku (wykrycie zmiany sygnału na pinie mikro-\nprocesora), wygaśnięciem czasomierza, czy zakończeniem transferu danych.\nProces obsługi przerwania odbywa się w trzech krokach:\n•zapisanie obecnego stanu programu,\n•wykonanie przypisanej do zdarzenia procedury obsługi przerwania,\n•przywrócenia stanu i kontynuacja egzekucji.\nPodobnie jak przy przełączaniu zadań przez system operacyjny, obsłużenie przerwa-\nnia wymaga zapisania aktualnego stanu wykonania. W tym przypadku procedura jest\nprostsza i mniej głęboka. Zapisywane (poprzez wstawienie na stos) są jedynie kluczowe\nrejestry, takie jak Program Counter, Link Register, Program Status Register, i niektóre\nrejestry ogólnego przeznaczenia (w zależności od potrzeb procedury obsługi przerwania).\nSystemy  RTOS  również  opierają  dużą  część  swojej  funkcjonalności  o  przerwania.\nW  procesorach  Cortex-M,  na  których  skupia  się  ta  praca,  istotnymi  odpowiedzialno-\nściami zostały obarczone w szczególności trzy przerwania:\n•SysTick,\n•PendSV,\n•SVCall.\n1.4.1    SysTick\nSysTick jest w procesorach z serii Cortex-M prostym, 24-bitowyn licznikiem, będącym\nczęścią modułu NVIC (ang.Nested Vectored Interrupt Controller\n7\n). Generuje on perio-\ndyczne przerwania, które są zazwyczaj wykorzystywane jako podstawa czasowa (ang.\ntimebase) systemu operacyjnego. Przerwania wywołane przez czasomierz będący pod-\nstawą  czasową  są  wykorzystane  do  okresowych  zmian  kontekstu,  stosowanych  w  celu\nosiągnięcia wielozadaniowości.\nW procesorach Cortex-M, SysTick jest domyślnie konfigurowany jako podstawa cza-\nsową zarówno w systemie FreeRTOS, jak i Keil RTX5. W obu z nich priorytet przerwa-\nnia podstawy  czasowej  jest ustawiony jako  najniższy  możliwy.  Dzięki temu pozostałe\nprzerwania mogą być obsłużone szybciej.\n1.4.2    PendSV\nPendSV (ang.Pendable Service Call) jest przerwaniem, mającym kilka właściwości spra-\nwiających,  że  jest  dobrym  kandydatem  do  zastosowania  jako  procedura  zmieniająca\nkontekst wykonania (zadanie).\n7\nNVIC jest peryferium, którego rolą jest zarządzanie systemem przerwań.\n14\n\n•Uprzywilejowany  tryb  wykonania–  przerwania  są  wykonywane  w  trybie\nuprzywilejowanym, tzw. trybie obsługi (ang.Handler Mode)\n8\n. Oznacza to, że ma-\nją pełny dostęp do procesora. Jest to konieczne do wykonania zmiany kontekstu,\nktóra wymaga wykonania uprzywilejowanych operacji (jak bezpośrednie działania\nna niektórych rejestrach).\n•Niski priorytet przerwania– bardzo ważną własnością PendSV jest fakt, że\njest to typowo przerwanie o najniższym możliwym priorytecie. Dzięki czemu może\nzostać wywołane, niejako „zaplanowane”, z innego przerwania (przykładowo prze-\nrwania  podstawy  czasowej  systemu  operacyjnego  lub  przerwania  SVCall).  Stad\npochodzi segment jego nazwy –Pendable(można przetłumaczyć na „oczekujące”).\nNiski priorytet PendSV pozwala innym przerwaniom na zakończenie wykonania\nprzed zmianą kontekstu.\nZ wymienionych powodów właśnie to przerwanie jest używane do zmian kontekstu.\nDomyślnie, dla procesorów z serii ARM Cortex-M, konfiguruje je do tego celu zarówno\nFreeRTOS, jak i Keil RTX5.\n1.4.3    SVCall\nSVCall (ang.Supervisor Call) to kolejne przerwanie wywoływane przez oprogramowanie\n(ang.software  interrupt) używane do przeprowadzenia operacji wymagających uprzy-\nwilejowanego  trybu  wykonania.  Operacjami  tymi  mogą  być,  przykładowo,  dostęp  do\nzabezpieczonych peryferiów lub konfiguracja systemu.\nPrzerwanie to jest używane w połączeniu z szeregiem procedur wymagających użycia\ntrybu uprzywilejowanego. Programista chcący wywołać kod, który wymaga wykonania\nw trybie uprzywilejowanym powinien napisać własną procedurę SVC (ang.Service Call).\nSystem operacyjny zawiera implementacje podstawowych procedur SVC wymaganych\ndo  jego  działania.  Kilka  z  nich  zostało  przedstawione  na  listingu  1.5.  Kod  pochodzi\nz plikurtx\nkernel.c, będącego częścią implementacji systemu Keil RTX5.\nSposób implementacji procedur SVC w CMSIS-RTOS2 został przedstawiony w jego\ndokumentacji [4]. Proces obejmuje kilka kroków przedstawionych poniżej.\n1.  Skopiowanie pliku szablonowegoSVC\nTable.S[29] do projektu.\n2.  Zadeklarowanie funkcji SVC z atrybutem\nsvc(x), gdzie „x” jest kolejnym wol-\nnym indeksem SVC zaczynając od 1.\n3.  Napisanie implementacji funkcji SVC. Nazwa implementacji powinna być w for-\nmacieSVCX,  gdzie  „X”  odpowiada  indeksowi  „x”  z  deklaracji.  Przykładowa\ndeklaracja i implementacja funkcji inkrementującej licznik została przedstawiona\nna listingu 1.3.\n4.  Dodanie funkcji do listy w uprzednio skopiowanym plikuSVCTable.S. Sposób do-\ndania przykładowej funkcji z poprzedniego punktu przedstawiono na listingu 1.4.\nZasada działania przerwania SVCall następująca:\n1.  wywołanie instrukcji ARMsvcz parametrem będącym identyfikatorem żądanej\nprocedury SVC;\n8\nTryb  obsługi  i  tryb  użytkownika  to  dwa  podstawowe  tryby  operacji  w  procesorach  ARM.  Tryb\nobsługi jest uprzywilejowany.\n15\n\nListing 1.3: Przykładowa implementacja funkcji SVC o nazwieinc5bit\n1void  __svc (1)   inc_5bit (U32 *cp);\n2void  __SVC_1               (U32 *cp) {\n3// A protected  function  to  increment a 5-bit  counter.\n4__disable_irq ();\n5cp = (*cp + 1) & 0x1F;\n6__enable_irq ();\n7}\nListing 1.4: Dodanie przykładowej funkcji SVC do listy SVC\n1// file  SVC_Table.S\n2...\n3; Import  user  SVC  functions  here.\n4IMPORT   __SVC_1\n5\n6...\n7\n8; Insert  user  SVC  functions  here. SVC 0 used by RTL  Kernel.\n9DCD      __SVC_1                     ; user  SVC  function\nListing  1.5:  Definicje  procedur  SVC  dla  operacji  na  jądrze  systemu  –  implementacja\nKeil RTX5, plik źródłowyrtx\nkernel.c\n1//   Service  Calls  definitions\n2//lint ++flb \"Library  Begin\" [MISRA  Note  11]\n3SVC0_0 (KernelInitialize ,         osStatus_t)\n4SVC0_3 (KernelGetInfo ,            osStatus_t , osVersion_t *, char\n*, uint32_t)\n5SVC0_0 (KernelStart ,               osStatus_t)\n6SVC0_0 (KernelLock ,                int32_t)\n7SVC0_0 (KernelUnlock ,             int32_t)\n8SVC0_1 (KernelRestoreLock ,       int32_t , int32_t)\n9SVC0_0 (KernelSuspend ,            uint32_t)\n10SVC0_1N(KernelResume ,             void , uint32_t)\n11#ifdef  RTX_SAFETY_CLASS\n12SVC0_1 (KernelProtect ,            osStatus_t , uint32_t)\n13SVC0_2 (KernelDestroyClass ,      osStatus_t , uint32_t , uint32_t)\n14#endif\n15SVC0_0 (KernelGetState ,           osKernelState_t)\n16SVC0_0 (KernelGetTickCount ,      uint32_t)\n17SVC0_0 (KernelGetTickFreq ,       uint32_t)\n18SVC0_0 (KernelGetSysTimerCount , uint32_t)\n19SVC0_0 (KernelGetSysTimerFreq ,   uint32_t)\n20//lint  --flb \"Library  End\"\n16\n\n2.  wyzwolenie przerwania SVCall;\n3.  rozpoczęcie wykonywania procedury obsługi przerwania SVCall – procesor prze-\nchodzi do uprzywilejowanego trybu obsługi;\n4.  wybranie i wykonanie procedury o przekazanym identyfikatorze;\n5.  powrót do zadania.\n1.5    Mechanizmy komunikacji międzyzadaniowej w syste-\nmach czasu rzeczywistego\nDobrze zaprojektowana aplikacja oparta o RTOS będzie wykonywała jedynie zadania,\nktóre są w stanie dostarczyć przydatnej w danej chwili funkcjonalności. Innymi słowy,\nwątki, które oczekują na zasób powinny zostać uśpione do czasu pojawienia się zasobu.\nTego typu paradygmat programowania można określić mianemnapędzanego zda-\nrzeniami(ang.event-driven). Przedstawione w tej sekcji mechanizmy komunikacji mię-\ndzyzadaniowej są kluczowe w programowaniu opartym o zdarzenia, które jest fundamen-\ntalne dla każdej dobrze zaimplementowanej aplikacji opartej o RTOS.\nWyjątkowe dla systemów typu RTOS jest istnienie alternatywnej ścieżki egzekucji,\nktóra  może  zostać  obrana  w  przypadku  gdy  zdarzenie  blokujące  zadanie  nie  zajdzie\nw sprecyzowanym interwale czasowym określanym jakotimeout. Zdarzeniem tym może\nbyć np. oddanie semafora czy nadejście oczekiwanej wiadomości. W przypadku osiągnię-\ncia wartościtimeoutpodczas oczekiwania, akcja zostaje zakończona niepowodzeniem,\na program może, przykładowo, wykonać algorytm obsługi błędu. Implementacja takiego\nalgorytmu będzie wysoce zależna od wpływu niepowodzenia na bezpieczeństwo i inte-\ngralność systemu. Może być tak prosta jak wysłanie wiadomości do systemu logowania,\nlub tak drastyczna jak pełne zamknięcie systemu z powodu krytycznej awarii.\n1.5.1    Kolejka wiadomości\nKolejka  to  prosty,  ale  mimo  to  elastyczny  prymityw  komunikacyjno-sygnalizacyjny.\nUmożliwia ona transportowanie danych o konfigurowalnym rozmiarze w bezpieczny dla\nwielowątkowości (ang.thread-safe) sposób. Fundamentalną zasadę działania kolejki wia-\ndomości zilustrowano na rysunku 1.4. Jak można zaobserwować, podstawowe operacje\nna kolejce to odebranie i wysłanie elementu.\nKolejka wiadomości jest zasadniczo cyklicznym buforem, ma jednak kilka specjal-\nnych własności, które czynią z niej użyteczną konstrukcję w kontekście projektowania\nwielowątkowej aplikacji. Pośród tych cech znajdą się wspomniane wcześniej bezpieczeń-\nstwo  dla  wielowątkowości,  oraz  możliwość  usypiania  i  wybudzania  zadań  zależnie  od\nstanu zawartości kolejki, której dane zadanie próbuje użyć.\nPrzykładowo,  zadanie  próbujące  odebrać  wiadomość  z  pustej  kolejki  zostanie  za-\nblokowane  do  czasu  nadejścia  wiadomości.  Nadejście  wiadomości  odblokuje  zadanie,\nustawiając je w stan gotowości (rysunek 1.5).\nPrzykład zastosowania kolejki do przesyłu danych pomiędzy sensorem a systemem\nlogującym  został  zilustrowany  na  listingu  1.6.  Można  zauważyć,  że  mamy  tu  do  czy-\nnienia  z  typowym  modelem  producent-konsument.  W  przykładzie  tworzymy  kolejkę\no  rozmiarze  dziesięciu  elementów  typuSENSOR\nDATATYPE,  a  następnie  używamy  jej\ndo  przesyłu  danych  pomiędzy  wątkami.  Ostatni  parametr  w  przekazywany  do  funk-\ncjiosMessageQueuePutiosMessageQueueGetodpowiada  czasowitimeoutoperacji.\n17\n\nRysunek 1.4: Podstawowe zastosowanie kolejki – wysłanie i odebranie elementu przez\nzadanie\nW  przypadku  wysyłania  (linia  12)  nie  czekamy  aż  zwolni  się  miejsce  w  kolejce  (nie\nblokujemy), pomijając wysłanie konkretnego odczytu. Przy odbiorze (linia 19) został\npodany argumentosWaitForever. Oznacza on, że wątek będzie zablokowany do czasu\naż w kolejce pojawi się wiadomość.\n1.5.2    Semafor\nSemafor  jest  prostą  konstrukcją  używaną  do  sygnalizacji  i  synchronizacji  zadań.  Jest\nużywany głównie w celu zasygnalizowania zdarzenia. Podstawowe operacje, jakie mogą\nbyć wykonane na semaforze to akcja „zabrania” semafora, oraz akcja „oddania” sema-\nfora. Operacje te mogą być rozumiane, odpowiednio, jako zabranie i oddanie współdzie-\nlonego zasobu.\nSemafor liczący\nSemafor liczący to konstrukcja pozwalająca na limitowanie i synchronizację dostępu do\nzasobu o ograniczonej, maksymalnej ilości użytkowników. Tego typu semafor ma przypi-\nsaną wartość, która odpowiada maksymalnej ilości użytkowników zasobu. Wątek, który\notrzymuje dostęp do zasobu „bierze” semafor, zmniejszając jego wartość. Jeżeli zasób się\nskończył (wartość semafora wynosi zero), wątek próbujący zabrać semafor zostaje zablo-\nkowany. Odblokowanie następuje w momencie oddania semafora przez jeden z aktualnie\nwykorzystujących zasób wątków. Działanie semafora liczącego ukazano na rysunku 1.6,\ngdzie o zasób mający dwie „kopie” konkurują trzy wątki. Wątek „c”, nie mając dostępu\n18\n\nListing 1.6: Przykład użycia kolejki do komunikacji między dwoma wątkami\n1#include \"cmsis_os2.h\"\n2#include \"sensor.h\"\n3#include \"logger.h\"\n4\n5#define  QUEUE_SIZE  10\n6\n7osMessageQueueId_t  msgQueue;\n8\n9void  sensor_thread(void *arg) {\n10while (1) {\n11SENSOR_DATA_TYPE  data = read_sensor_data ();\n12osMessageQueuePut(msgQueue , &data , 0, 0);\n13}\n14}\n15\n16void  logging_thread(void *arg) {\n17while (1) {\n18SENSOR_DATA_TYPE  received_data;\n19osStatus_t  status = osMessageQueueGet(msgQueue , &\nreceived_data , NULL , osWaitForever);\n20\n21if(status  == osOK) {\n22// log  the  received  data\n23log_write(\"Received␣sensor␣data:␣%d\\n\", received_data\n);\n24}\n25}\n26}\n27\n28int  main(void) {\n29//  initialize  the  RTOS\n30osKernelInitialize ();\n31\n32//  create  the  message  queue\n33msgQueue = osMessageQueueNew(QUEUE_SIZE , sizeof(\nSENSOR_DATA_TYPE), NULL);\n34\n35//  create  threads\n36osThreadNew(sensor_thread , NULL , NULL);\n37osThreadNew(logging_thread , NULL , NULL);\n38\n39osKernelStart ();\n40while (1);   //  should  never  reach  here (control  taken  by the\nscheduler)\n41}\n19\n\nRysunek 1.5: Zadanie zablokowane przez oczekiwanie na wiadomość z pustej kolejki\nRysunek 1.6: Zasada działania semafora liczącego\ndo wyczerpanego zasobu, zostaje uśpiony aż do czasu zwrócenia semafora przez jeden\nz trzymających go wątków.\nAnalogicznie jak w przypadku kolejki, mamy tu do czynienia z modelem programo-\nwym opartym o zdarzenia. Oczekujące zadanie nie marnuje zasobów na niepotrzebne\nakcje, takie jak próbkowanie (ang.polling) dostępności semafora. Zostanie odblokowane\nautomatycznie, w momencie kiedy będzie miało do wykonania wartościowe obliczenia –\nzasób stanie się dostępny.\nSemafor binarny\nSemafor  binarny  jest,  w  gruncie  rzeczy,  semaforem  liczącym  o  maksymalnym  limicie\nzasobu ustawionym na jeden. Konstrukcje te są zazwyczaj stosowane do sygnalizowania\ndostępności zasobu z wykorzystaniem np. procedury obsługi obsługi przerwania: Zadanie\nmające  na  celu  synchronizację  akcji  próbuje  zabrać  pusty  semafor  binarny,  przez  co\njest  zablokowane.  Inna  asynchroniczna  część  systemu  (zadanie  lub  procedura  obsługi\nprzerwania)  oddaje  w  tym  czasie  semafor,  sygnalizując  możliwość  podjęcia  działania\n20\n\nRysunek 1.7: Zastosowanie semafora binarnego w celu synchronizacji sygnałem\n– rysunek 1.7. Oczekujące zadanie zabiera nowo oddany semafor i może kontynuować\negzekucję.\n1.5.3    Muteks\nMuteks to struktura synchronizacyjna, która działa analogicznie do semafora binarnego.\nJest stosowana do zapewnienia wyłączności nad współdzielonym zasobem jednemu wąt-\nkowi – stąd właśnie pochodzi nazwa prymitywu: ang.Mutual Exclusion, czyli wzajem-\nne wykluczenie. Kluczowa różnica odróżniająca te dwie konstrukcje ma swoje podłoże\nw słabości, na którą jest podatny semafor binarny: odwróceniu priorytetów.\nOdwrócenie priorytetów\nOdwrócenie priorytetów jest niedogodnością, na jaką możemy natrafić usiłując zastoso-\nwać semafor binarny, w celu zapewnienia zadaniu wyłącznego dostępu do zasobu.\nAby lepiej zaprezentować problem, posłużmy się przykładem. Mając trzy zadania\no różnych priorytetach:Zadanie A(priorytet wysoki),Zadanie B(średni),Zadnie C\n(niski), chcemy zapewnić wyłączny dostęp do zasobu zadaniu aktualnie trzymającemu\nsemafor binarny.\nRozważmy sytuację zilustrowaną na rysunku 1.8. Sekwencja wydarzeń jest następu-\njąca:\n1.Zadanie Czabiera semafor,\n2.Zadanie Azaczyna czekać na zwrócenie semafora,\n3.Zadanie BwywłaszczaZadanie C, zmuszającZadanie Ado dodatkowego, nie-\nspodziewanego oczekiwania,\n4.Zadanie Bkończy działanie,\n5.Zadanie Coddaje semafor,\n6.Zadanie Azabiera semafor i rozpoczyna działanie.\n21\n\nRysunek 1.8: Odwrócenie priorytetów\nW powyższym przykładzie można łatwo zauważyć dodatkową zależność, powstałą po-\nprzez użycie semafora binarnego jako sposobu dostarczenia zadaniu ekskluzywnej kon-\ntroli nad zasobem. Zadanie o wysokim priorytecie może zostać pośrednio wywłaszczone\nprzez  zadanie  o  niższym  priorytecie  (punkt  3.).  Sytuacja  ta,  nazywana  odwróceniem\npriorytetów,  jest  powodem,  dla  którego  w  przedstawionym  scenariuszu  należało  użyć\nmuteksu, który został stworzony specjalnie z myślą o nim.\nDziedziczenie priorytetów\nMuteks  implementuje  mechanizm  „dziedziczenia  priorytetów”,  polegający  na  chwilo-\nwym podniesieniu priorytetu zadania trzymającego instancję tego prymitywu, do prio-\nrytetu najbardziej krytycznego zadania, które na nią oczekuje.\nPo zmianie semafora binarnego na muteks, przykładowa sytuacja z trzema zadania-\nmi rysuje się jak pokazano na rysunku 1.9. Podniesienie („odziedziczenie”) priorytetu\nZadania Csprawia, że nie może ono zostać wywłaszczone przezZadanie B. Naprawia\nto zobrazowany powyżej problem – Zadanie A rozpoczyna wykonanie gdy tylko Zadanie\nC zwróci muteks.\nNa listingu 1.7 pokazano zastosowanie muteksu do zabezpieczenie współdzielonego\nzasobu. FunkcjaUART\nSendmoże być wywołana przez wiele wątków jednocześnie. W celu\nzapewnienia, że do interfejsu będzie wysyłać dane tylko jeden wątek naraz, otaczamy\nużycie zasobu wywołaniamiosMutexAcquireiosMutexRelease. Ponownie został użyty\nparametr  limitu  czasowego  o  wartościosWaitForever.  Oznacza  to,  że  wątek  będzie\nczekał na zasób przez nieograniczony czas.\n1.5.4    Flagi zdarzenia\nFlagi zdarzenia są użyteczną konstrukcją sygnalizacyjną, pozwalającą na informowanie\nwielu zadań o zajściu zdarzenia. Można stosować je w celu poinformowania wszystkich\nzadań obserwujących daną flagę o zajściu zdarzenia o zdefiniowanej interpretacji (np.\npusty lub pełny bufor).\nFlagi  zdarzenia  są  implementowane  jako  bity  zmiennej  numerycznej  (np.  w  Keil\nRTX5 jest touint32\nt[34]). Komunikacja zachodzi poprzez wykorzystanie charaktery-\nstycznych dla prymitywu akcji:\n22\n\nRysunek 1.9: Dziedziczenie priorytetów\nListing 1.7: Przykład zastosowania muteksu do synchronizacji korzystania z zasobu.\n1#include \"cmsis_os2.h\"\n2\n3osMutexId_t  uartMutex;   // mutex  declaration\n4\n5void  UART_SendData(const  char* data) {\n6//  acquire  the  mutex\n7osMutexAcquire(uartMutex , osWaitForever);\n8\n9// send  data\n10printf(\"%s\", data);\n11\n12//  release  the  mutex\n13osMutexRelease(uartMutex);\n14}\n15\n16int  main(void) {\n17osKernelInitialize ();\n18\n19//  create  the  mutex\n20uartMutex = osMutexNew(NULL);\n21\n22... //  start  tasks\n23\n24// start  kernel\n25osKernelStart ();\n26\n27while (1);\n28}\n23\n\n•SET– ustawienie flagi,\n•CLEAR– usunięcie flagi,\n•WAIT– wywołujące zadanie zostaje zablokowane do czasu ustawienia sprecyzowa-\nnych w wywołaniu flag.\nSposób  działania  flag  zdarzenia  jest  porównywalny  do  sygnalizacji  za  pomocą  se-\nmafora  binarnego.  Kluczową  różnicą  jest  zdolność  pierwszego  z  nich  do  komunikacji\nwielu  zdarzeń, przy  wykorzystaniu  tylko  jednego  prymitywu.  Umożliwia  to tworzenie\nkombinacji zdarzeń na które ma oczekiwać zadanie, oraz łączącej je logiki.\nNa listingu 1.8\n9\nzilustrowano przykład zastosowania dwóch flag zdarzenia do kontro-\nli procesowania danych z dwóch sensorów. Każdy z sensorów ustawia zdefiniowaną flagę\nkiedy  zakończy  wypełniać  bufor.  Procesowanie  rozpoczyna  się  gdy  obie  flagi  zostaną\nustawione. Przykład wykorzystuje interfejs programowania (ang.Application Program-\nming Interface – API) CMSIS-RTOS2, zdefiniowany przez grupę ARM\n10\n.\nAby przekształcić przykład tak, żeby procesowanie danych rozpoczęło się gdy przy-\nnajmniej jeden z buforów jest pełny (warunek logicznyOR) wystarczy podmienić para-\nmetrosFlagsWaitAllz linii 45 naosFlagsWaitAny.\nListing 1.8: Przykład zastosowania flag zdarzenia do synchronizacji procesowania danych\nz dwóch źródeł.\n1#include \"cmsis_os2.h\"\n2\n3#define  BUFFER_SIZE  100\n4#define  DATA_A_RDY  (1U << 0)\n5#define  DATA_B_RDY  (1U << 1)\n6\n7int  buffer_sensor_a[BUFFER_SIZE ];\n8int  buffer_sensor_b[BUFFER_SIZE ];\n9int  buffer_a_index = 0;\n10int  buffer_b_index = 0;\n11\n12osEventFlagsId_t  evt_id;\n13\n14void  thread_sensor_a(void *argument) {\n15while  (1) {\n16// read  data  from  sensor a\n17int  data = sensor_a_read_data ();\n18buffer_sensor_a[buffer_a_index ++] = data;\n19\n20// if  buffer  full , set  DATA_A_RDY\n21if (buffer_a_index  ==  BUFFER_SIZE) {\n22osEventFlagsSet(evt_id , DATA_A_RDY);\n23buffer_a_index = 0;\n24}\n25}\n26}\n27\n9\nDo poprawnego działania przykładu, zadanieprocess\nsensordatapowinno mieć wyższy priorytet\nniż zadaniathreadsensoraithreadsensorb.\n10\nInterfejs programowania CMSIS-RTOS2 oraz jego starszy odpowiednik CMSIS-RTOS zostaną sze-\nrzej opisane w kolejnym rozdziale.\n24\n\n28void  thread_sensor_b(void *argument) {\n29while  (1) {\n30// read  data  from  sensor b\n31int  data = sensor_b_read_data ();\n32buffer_sensor_b[buffer_b_index ++] = data;\n33\n34// if  buffer  full , set  DATA_B_RDY\n35if (buffer_b_index  ==  BUFFER_SIZE) {\n36osEventFlagsSet(evt_id , DATA_B_RDY);\n37buffer_b_index = 0;\n38}\n39}\n40}\n41\n42void  process_sensor_data(void *argument) {\n43while  (1) {\n44// wait  for  data  from  both  sensors\n45osEventFlagsWait(evt_id , DATA_A_RDY | DATA_B_RDY ,\nosFlagsWaitAll , osWaitForever);\n46\n47//  process  the  data\n48process_data(buffer_sensor_a , buffer_sensor_b);\n49\n50// clear  the  flags\n51osEventFlagsClear(evt_id , DATA_A_RDY | DATA_B_RDY);\n52}\n53}\n1.6    CMSIS\nCMSIS (ang.Common Microcontroller Software Interface Standard) jest zestawem na-\nrzędzi, interfejsów programowania (API), frameworków i przepływów pracy, mających\nna celu uproszczenie ponownego użycia oprogramowania, zmniejszenie krzywej nauki dla\ndeweloperów mikrokontrolerów, oraz przyspieszenie procesu projektowania i budowania\nfirmware’u  [10]  przeznaczonego  na  urządzenia  oparte  o  serie  mikroprocesorów  ARM\nCortex. Jest udostępniany przez ARM w oparciu o licencję Apache 2.0 [12]. Motywacją\nstojącą  za  powstaniem  CMSIS,  była  chęć  stworzenia  wspólnego  standardu  tworzenia\noprogramowania przeznaczonego na mikrokontrolery oparte o ARM.\nW skład CMSIS wchodzi kilka komponentów, z których większość została zaprojek-\ntowana pod kątem tworzenia oprogramowania na procesory z serii Cortex-M. Moduły\nnajbardziej istotne w kontekście programowania opartych o nie mikrokontrolerów zosta-\nły przedstawione w tabeli 1.1. Pełna lista komponentów widnieje na stronie ARM [11].\n1.7    CMSIS-RTOS\nCMSIS-RTOS, jak już wspomniano, jest specyfikacją definiującą interfejs programowa-\nnia dla systemów operacyjnych RTOS przeznaczonych na mikroprocesory ARM Cortex-\nM. CMSIS-RTOS został do tej pory wydany w dwóch wersjach – CMSIS-RTOS v1 oraz\nCMSIS-RTOS v2. Wersja druga została wzbogacona o możliwość alokacji dynamicznej\noraz o wsparcie dla architektury Armv8-M.\n25\n\nNazwaWsparcie Cortex-MOpis\nCore(M)WszystkieUstandaryzowanyinterfejsprogramowania\n(API) dla procesorów Cortex.\nDriverWszystkieZestaw ustandaryzowanych interfejsów dla ste-\nrowników peryferiów procesorów Cortex.\nDSPWszystkieKolekcja bibliotek przetwarzania sygnałów cy-\nfrowych  (DSP).  Dostarcza  między  innymi  im-\nplementacje  zoptymalizowane  pod  kątem  pro-\ncesowania SIMD (ang.Single  Instruction  Mul-\ntiple Data).\nNNWszystkieKolekcja sieci neuronowych stworzonych w celu\nmaksymalizacji wydajności i minimalizacji zu-\nżycia pamięci na procesorach Cortex-M.\nRTOS v1M0/M0+/M3/M4/M7Wspólny interfejs programowania dla systemów\noperacyjnych czasu rzeczywistego, wraz z refe-\nrencyjną implementacją Keil RTX4 [30].\nRTOS v2WszystkieRozszerzenie  CMSIS-RTOS  v1  wsparciem  dla\narchitektury  Armv8-M,  dynamicznym  tworze-\nniem  obiektów,  oraz  wsparciem  dla  zarządza-\nnia wieloma rdzeniami. Binarnie kompatybilny\nz RTOS v1. Referencyjna implementacja – Keil\nRTX5 [31].\nPackWszystkieZapewnia standard opisu i dostarczania dodat-\nkowych komponentów, parametrów urządzenia,\ni  dodatkowej  dokumentacji  do  urządzeń  opar-\ntych o procesory Cortex.\nTabela 1.1: Najbardziej istotne dla procesorów z serii Cortex-M komponenty CMSIS\n26\n\nW wersji CMSIS-RTOS2 zostało też wprowadzone kilka zmian związanych z dostęp-\nnymi prymitywami komunikacyjnymi oraz nazwami wywołań. Kompatybilność wsteczna\njest utrzymywana przez dodatkową warstwę translacji [38], która umożliwia mieszanie\nwywołań funkcji z wersji CMSIS-RTOS v1 i CMSIS-RTOS v2 w jednej aplikacji i osta-\nteczne płynne przejście pomiędzy wersjami API. Kompletna lista zmian w API pomiędzy\nwersjami jest dostępna na stronie Keil [35].\n27\n\nRozdział 2\nFreeRTOS vs Keil RTX5\nFreeRTOS i Keil RTX5 to popularne systemy operacyjne RTOS przeznaczone na urzą-\ndzenia wbudowane wyposażone w procesory ARM z serii Cortex-M. Keil RTX5 wspie-\nra CMSIS-RTOS2 natywnie, a FreeRTOS może używać tego interfejsu programowania\ndzięki  dodatkowej  warstwie  opakowującej.  Warstwa  ta  odpowiada  za  przekształcanie\nwywołań API CMSIS-RTOS2 na wywołania swoistych funkcji systemu FreeRTOS.\nBiorąc pod uwagę fakt posiadania wspólnego API przez oba systemy, można sku-\npić  się  na  porównaniu  innych  szczegółów  tych  implementacji,  takich  jak  wydajność,\nlicencjonowanie i wsparcie produktu, czy dostępne funkcjonalności.\n2.1    Licencjonowanie i wsparcie\n2.1.1    FreeRTOS\nSystem operacyjny FreeRTOS jest znacznie mniej restrykcyjny niż Keil RTX5, zarówno\npod względem użytku, jak i rozprzestrzeniania. Jest on dostępny pod liberalną licencją\nMIT [23], zezwalającą na m.in. użytkowanie oprogramowania w dowolnych celach, je-\ngo rozprzestrzenianie, i modyfikację. Kod źródłowy systemu FreeRTOS jest publicznie\ndostępny na repozytorium GitHub [27].\nW przypadku konieczności posiadania dedykowanego wsparcia i gwarancji dla pro-\nduktu komercyjnego, FreeRTOS oferuje także edycję licencjonowaną pod nazwą OpenR-\nTOS [42].\n2.1.2    Keil RTX5\nKeil RTX5 jest produktem firmy Keil (należącej do ARM), oraz częścią oprogramowania\nKeil  MDK  (ang.Microcontroller  Development  Kit).  Oprogramowanie  Keil  może  być\nużywane  za  darmo  w  celach  hobbystycznych  i  akademickich,  ale  wymaga  licencji  do\nzastosowań komercyjnych. Keil MDK można otrzymać w czterech edycjach:\n•Community(darmowa do zastosowań niekomercyjnych),\n•Essential,\n•Plus,\n•Professional.\n28\n\nKażda z wymienionych edycji zawiera Keil RTX5 [33], wraz z jego pełnym kodem źró-\ndłowym. Kod źródłowy jest również dostępny w repozytorium GitHub [40].\nDzięki  istnieniu  edycjiCommunity,  Keil  RTX5  może  zostać  łatwo  wykorzystany\nprzez hobbystów, natomiast edycje licencjonowane zapewniają pełne środowisko rozwo-\njowe oraz profesjonalne wsparcie techniczne dla zastosowań komercyjnych.\n2.1.3    Podsumowanie\nOba systemy operacyjne można łatwo zastosować w celach hobbystycznych lub eduka-\ncyjnych. Keil RTX5 wydaje się być lepszym wyborem do zastosowań komercyjnych, ze\nwzględu na profesjonalne wsparcie dla produktu. Dodatkowej wiarygodności nadaje mu\nfakt bycia produktem ARM, dedykowanym dla mikrokontrolerów opartych o procesory\nCortex-M.\nFreeRTOS ma przewagę w formie kosztu – może być wykorzystany do każdego celu\nza darmo. Jeśli profesjonalne wsparcie i gwarancja są koniecznością, FreeRTOS udostęp-\nnia także płatny, obejmujący je produkt. Należy również pamiętać o, wynikającej z jego\npopularności,  ogromnej  społeczności  otaczającej  rozważany  system.  Brak  profesjonal-\nnego wsparcia może zostać efektywnie nadrobiony poprzez aktywne fora użytkowników\ni ekstensywną dokumentację.\n2.2    Zarządzanie pamięcią\nOba systemy dostarczają możliwości alokowania obiektów w sposób zarówno dynamicz-\nny (tworzenie i usuwanie zmiennych w czasie działania programu) i statyczny (rozmia-\nry i lokalizacje wszystkich struktur danych są znane i niezmienne w trakcie działania\nprogramu).  Oba  systemy  dopuszczają  zastosowanie  wymienionych  sposobów  alokacji\njednocześnie w pojedynczej aplikacji.\nPrzeanalizujemy  teraz  mechanizmy  zarządzania  pamięcią  w  systemach  FreeRTOS\ni Keil RTX5, porównując je pod kątem funkcjonalności, konfiguracji i elastyczności.\n2.2.1    FreeRTOS\nAlokacja dynamiczna\nW celu stworzenia obiektu alokowanego dynamicznie, użytkownik systemu FreeRTOS\npowinien wywołać odpowiednią funkcję. W tabeli 2.1 przedstawiono wywołania specy-\nficzne dla FreeRTOSa, oraz ich odpowiedniki w przypadku stosowania warstwy CMSIS-\nRTOS2.\nAlokacja dynamiczna została w tym systemie zaimplementowana w wyjątkowo kon-\nfigurowalny  sposób.  Użytkownik  ma  do  dyspozycji  pięć  różnych  implementacji  sterty\n(ang.heap) [25].\n•heap\n1– najprostsza implementacja, nie dopuszcza usuwania stworzonych obiek-\ntów. Od wersji FreeRTOS V9.0.0 jest mniej użyteczna z powodu dodania możli-\nwości alokacji statycznej.\n•heap\n2– pozwala na usuwanie obiektów, ale nie łączy sąsiadujących wolnych blo-\nków pamięci. Implementacja przestarzała, zaleca się jej zastąpienie przezheap4.\n•heap\n3– prosta implementacja opakowująca funkcjemalloc()ifree()w celu\nzapewnienia bezpieczeństwa dla wątków.\n29\n\nFreeRTOSCMSIS-RTOS2Obiekt\nxTaskCreate()                     osThreadNew()Zadanie\nxQueueCreate()                    osMessageQueueNew()Kolejka\nxTimerCreate()                    osTimerNew()Czasomierz\n1\nxEventGroupCreate()               osEventFlagsNew()Flagi zdarzenia\nxSemaphoreCreateBinary()          osSemaphoreNew(1, 1, NULL)Semafor binarny\nxSemaphoreCreateCounting()        osSemaphoreNew(max, initial, NULL)Semafor liczący\nxSemaphoreCreateMutex()           osMutexNew(NULL)Muteks\nxSemaphoreCreateRecursiveMutex()  osMutexNew(&recursiveMutexAttr)Muteks rekursywny\n2\nTabela  2.1:  Mapowanie  funkcji  alokujących  FreeRTOS  na  ich  odpowiedniki  CMSIS–\nRTOS\n•heap\n4– działa jakheap2, ale zapewnia łączenie sąsiadujacych wolnych bloków\npamięci w celu zmniejszenia fragmentacji.\n•heap5– działa jakheap4, ale pozwala na rozprzestrzenienie bloku pamięci sterty\nna wiele nieprzylegających obszarów pamięci.\nWybór implementacji polega na zlinkowaniu odpowiedniego pliku źródłowego. Przy-\nkładowo, w celu użycia implementacjiheap\n4, w liście źródeł naszego projektu powinien\nznaleźć się plik o ścieżceRTOS/Source/portable/MemMang/heap4.c[26].\nFreeRTOS  udostępnia  również  możliwość  stworzenia  własnej  implementacji.  Wy-\nstarczy dostarczyć odpowiedni plik źródłowy zawierający implementacje przynajmniej\ndwóch najbardziej istotnych funkcji:\n•void *pvPortMalloc(size\nt xSize)– funkcja dokonująca alokacji,\n•void vPortFree(void *pv)– funkcja dokonująca zwolnienia pamięci.\nPlik ten należy zlinkować w miejscu jednej z domyślnych implementacji.\nUwaga: Użytkownik nie musi korzystać z dynamicznej alokacji. Wszystkie obiekty\nmogą zostać zaalokowane statycznie. W takiej sytuacji implementacje funkcji alokacji\ndynamicznej nie muszą być dołączone do programu.\nAlokacja statyczna\nFreeRTOS ma pełne wsparcie dla alokacji statycznej, poprzez użycie specjalnych odpo-\nwiedników dla zwykłych (dynamicznych) funkcji alokujących. Odpowiedniki te wylisto-\nwano w tabeli 2.2.\nAlokacja statyczna może zostać zastosowana również w przypadku korzystania z war-\nstwy  CMSIS  systemu  FreeRTOS.  W  takiej  konfiguracji  wybór  funkcji  statycznej  jest\nuwarunkowany  podaniem  odpowiednich  argumentów.  Przykładowo  w  celu  statycznej\nalokacji zadania, do funkcjiosThreadNew()musi zostać podana struktura atrybutów,\nzawierająca  ustawione  wskaźniki  i  rozmiary  pamięci  dla  bloku  kontrolnego  oraz  sto-\nsu zadania. Struktura została przedstawiona na listingu 2.1, a wspomniane wymagane\natrybuty znajdują się w liniach 4-7 (włącznie). Fragment kodu ze standardowej biblio-\nteki, który zawiera warunek wybierający użytą do stworzenia nowego zadania funkcję\nalokującą przedstawiono na listingu 2.2.\n1\nCzasomierze pozwalają na zaplanowanie wykonania funkcji po upływie zadanego czasu.\n2\nMuteks rekursywny może zostać zabrany wiele razy przez jedną funkcję (wywołania rekursywne).\n30\n\nDynamiczneStatyczneObiekt\nxTaskCreate()xTaskCreateStatic()Zadanie\nxQueueCreate()xQueueCreateStatic()Kolejka\nxTimerCreate()xTimerCreateStatic()Czasomierz\nxEventGroupCreate()xEventGroupCreateStatic()Flagi zdarzenia\nxSemaphoreCreateBinary()xSemaphoreCreateBinaryStatic()Semafor binarny\nxSemaphoreCreateCounting()\nxSemaphoreCreateCountingStatic()Semafor liczący\nxSemaphoreCreateMutex()xSemaphoreCreateMutexStatic()Muteks\nxSemaphoreCreateRecursiveMutex()xSemaphoreCreateRecursiveMutexStatic()Muteks rekursywny\nTabela 2.2: Mapowanie funkcji alokacji dynamicznych do funkcji alokacji statycznych w\nFreeRTOS\nListing 2.1: Struktura atrybutów zadania w CMSIS-RTOS2\n1typedef  struct {\n2const  char *name;          ///< name of the  thread\n3uint32_t  attr_bits;       ///< attribute  bits\n4void *cb_mem;               ///< memory  for  control  block\n5uint32_t  cb_size;          ///< size of  provided  memory  for\ncontrol  block\n6void *stack_mem;           ///< memory  for  stack\n7uint32_t  stack_size;      ///< size of stack\n8osPriority_t  priority;    ///< initial  thread  priority (default:\nosPriorityNormal)\n9TZ_ModuleId_t  tz_module; ///< TrustZone  module  identifier\n10uint32_t  reserved;         ///< reserved (must be 0)\n11} osThreadAttr_t;\n31\n\nListing 2.2: Warunek wybierający stosowaną metodę alokacji w FreeRTOS z warstwą\nCMSIS. Plik źródłowycmsisos2.c.\n1if ((attr ->cb_mem  != NULL) && (attr ->cb_size  >= sizeof(\nStaticTask_t))\n2&& (attr ->stack_mem  != NULL) && (attr ->stack_size  >   0U))\n{\n3mem = 1;\n4}\n5else {\n6if ((attr ->cb_mem  == NULL) && (attr ->cb_size  == 0U) && (attr\n->stack_mem  == NULL)) {\n7mem = 0;\n8}\n9}\n10\n11...\n12\n13if (mem == 1) {\n14#if (configSUPPORT_STATIC_ALLOCATION  == 1)\n15hTask = xTaskCreateStatic (( TaskFunction_t)func , name ,\nstack , argument , prio , (StackType_t *)attr ->stack_mem ,\n(StaticTask_t  *)attr ->cb_mem);\n16#endif\n17}\n18else {\n19if (mem == 0) {\n20#if (configSUPPORT_DYNAMIC_ALLOCATION  == 1)\n21if (xTaskCreate  (( TaskFunction_t)func , name , (\nuint16_t)stack , argument , prio , &hTask) !=  pdPASS)\n{\n22hTask = NULL;\n23}\n24#endif\n25}\n26}\n32\n\nRysunek 2.1: Globalna pula pamięci – alokacja w systemie Keil RTX5 (źródło: [32])\n2.2.2    Keil RTX5\nKeil RTX5, podobnie jak FreeRTOS, udostępnia zarówno alokację dynamiczną, jak i sta-\ntyczną. Alokacja w kodzie odbywa się w sposób analogiczny do metody przedstawionej\ndla systemu FreeRTOS z warstwą CMSIS. Funkcje tworzące nowe obiekty zostały wy-\nlistowane w kolumnie CMSIS-RTOS2 tabeli 2.1.\nAlokacja dynamiczna\nW systemie Keil RTX5 istnieją dwa schematy dla alokacji dynamicznej, z której oba\nkorzystają z uprzednio stworzonych pul pamięci: globalnej puli pamięci oraz pul pamięci\ndedykowanych konkretnym typom obiektów.\nWybór sposobu alokacji dynamicznej odbywa się pośrednio, poprzez skonfigurowanie\nsystemu w odpowiedni sposób. Konfiguracja ta, z kolei, polega na ustawieniu odpowied-\nnich definicji preprocesora w pliku konfiguracyjnym\n3\n.\nMożna skonfigurować więcej niż jedną formę alokacji dynamicznej. W takim przy-\npadku priorytet buforów jest następujący:\nPule dedykowane→Pula globalna,\ngdzie  pula  globalna  jest  wykorzystywana  w  przypadku  braku  konfiguracji,  lub  braku\nmiejsca w pulach dedykowanych.\nGlobalna pula pamięcijest domyślnym sposobem alokacji w tym systemie. Meto-\nda ta polega na alokowaniu wszystkich obiektów do pojedynczego, globalnego obszaru\npamięci. Taki sposób alokacji jest łatwy w konfiguracji, ale ma słabość w formie podatno-\nści na fragmentację pamięci, gdy obiekty o różnych rozmiarach są alokowane i zwalniane.\nProblem został zwizualizowany na rysunku 2.1.\nAlternatywą dla globalnej puli pamięci sąpule dedykowane. Prezentują one al-\nternatywne, dopuszczane przez system Keil RTX5, podejście do alokacji, polegające na\nwydzieleniu osobnych bloków dla każdego rodzaju obiektu. Dedykowane pule pamięci\nmożna wygenerować dla następujących typów:\n•zadanie,\n•czasomierz,\n•flagi zdarzenia,\n3\nPoszczególne opcje konfiguracyjne zostaną szerzej opisane w kolejnym rozdziale.\n33\n\n•muteks,\n•semafor,\n•kolejka wiadomości,\n•pula pamięci\n4\n.\nObiekty te mają przewidywalny rozmiar, przez co mogą niezawodnie być realokowane\nw blok o tym samym rozmiarze, uprzednio zwolniony przez inną instancję. Pozwala to\nna  znaczne  ograniczenie  problemu  fragmentacji  pamięci.  Alokacja  tą  metodą  została\nzwizualizowana na rysunku 2.2.\nRysunek 2.2: Dedykowane pule pamięci – alokacja w systemie Keil RTX5 (źródło: [32])\nAlokacja statyczna\nAlokacja statyczna, analogicznie jak dla systemu FreeRTOS, odbywa się poprzez podanie\nodpowiednich  buforów  wraz  z  ich  rozmiarami  jako  argument  funkcji  alokującej  nowy\nobiekt (przykład na listingu 2.1 – dla alokacji statycznej wymagane podanie pól z linii\n4-7).\n2.2.3    Podsumowanie\nW kontekście zarządzania pamięcią, zarówno FreeRTOS jak i Keil RTX5 oferują szerokie\nmożliwości alokacji statycznej i dynamicznej.\nW alokacji dynamicznej FreeRTOS wyróżnia się elastycznością, poprzez możliwość\nłatwej implementacji własnych metod alokacji. Implementacja systemu Keil RTX5 uży-\nwająca  dedykowanych  puli  pamięci  może  być  natomiast  szybsza  i  mniej  podatna  na\nfragmentację. Należy jednak pamiętać, że dzięki prostocie implementacji nowych sposo-\nbów alokacji dynamicznej można bez trudu dodać do systemu FreeRTOS własną wersję\nalokacji  w  oparciu  o  pule  pamięci.  Warto  również  wspomnieć,  że  najbardziej  nieza-\nwodną metodą alokacji, zwłaszcza w kontekście systemów wbudowanych, jest alokacja\nstatyczna, która pozwala na uzyskanie pewnych rezultatów w deterministycznym czasie\ni często umożliwia całkowite uniknięcie alokacji dynamicznej i związanego z nią nakładu\nczasowego.\n4\nPula pamięci może być obiektem w systemie Keil RTX5. Umożliwia zdefiniowanie sztywnego obszaru\npamięci o N blokach określonej wielkości do wykorzystania przez aplikację.\n34\n\n2.3    Konfiguracja\nOba  prezentowane  systemy  operacyjne  można  skonfigurować  poprzez  edycję  przezna-\nczonego do tego celu pliku nagłówkowego. Konfiguracja odbywa się poprzez ustawienie\nodpowiednich wartości w definicjach preprocesora.\n2.3.1    FreeRTOS\nDefinicje konfiguracyjne dla systemu FreeRTOS można znaleźć w pliku nagłówkowym\no nazwieFreeRTOSConfig.h[24]. Istotne oraz interesujące konfiguracje dla tego systemu\nprzedstawiono poniżej.\n•configUSE\nPREEMMPTION– ustawienie włączy w planiście wywłaszczanie. Wyze-\nrowanie sprawi, że będzie wykorzystywanie jedynie przełączanie kooperatywne.\n•configSUPPORT\nSTATICALLOCATION–  ustawienie  uruchamia  możliwość  alokacji\nstatycznej obiektów.\n•configSUPPORTDYNAMICALLOCATION– ustawienie uruchamia możliwość alokacji\ndynamicznej obiektów.\n•configUSETICKLESSIDLE– ustawienie sprawi, że w czasie bezczynności mikro-\nkontroler zostanie wprowadzony w tryb niskiego poboru mocy typutickless, a więc\nrównież licznik będący podstawą czasową systemu zostanie wyłączony.\n•configMINIMAL\nSTACKSIZE– ustawia wielkość stosu zadania bezczynnego (ang.\nidle) w bajtach.\n•configTOTALHEAPSIZE– ustawia ilość dostępnej pamięci na stercie (w bajtach).\nUżywany tylko gdy alokacja dynamiczna jest włączona.\n•Konfiguracja  funkcji  typu  „hook”  (np.configUSETICKHOOK)  –  FreeRTOS  po-\nzwala na wstrzyknięcie kodu użytkownika do niektórych funkcjonalności, poprzez\nużycie funkcji typuhook. Muszą one zostać uruchomione w konfiguracji.\n•configMAX\nPRIORITIES– ustala limit priorytetów w aplikacji.\n•Konfiguracje uruchamiające lub wyłączające prymitywy sygnalizacyjne i synchro-\nnizacyjne, np.configUSEMUTEXES.\n•configCHECKFORSTACKOVERFLOW– włączy sprawdzanie przepełnienia stosu.\n•configUSE\nTIMESLICING– wyłączenie tej konfiguracji sprawi, że planista nie bę-\ndzie przełączał między zadaniami o tym samym priorytecie w każdym ticku sys-\ntemu.\n•configGENERATERUNTIMESTATS– uruchamia generowanie statystyk z działania\nsystemu.\n•configTRACEFACILITY– dodaje funkcjonalność odpowiedzialną za zapisywanie\nwydarzeń w czasie działania systemu. Zdarzenia te mogą zostać zwizualizowane\nw  czasie  rzeczywistym  za  pomocą  specjalnego  oprogramowania  utrzymywanego\nprzez FreeRTOS, nazwanegoTracealyzer[21].\n35\n\nFreeRTOS oferuje dość wszechstronne możliwości konfiguracji, dzięki czemu można\ngo  dostosować  do  szerokich  potrzeb  sprzętowych  i  aplikacyjnych.  System  pozwala  na\nskonfigurowanie podstawowych funkcjonalności, jak sposób uzyskania wielozadaniowo-\nści, częstotliwość taktowania, czy schematy zarządzania pamięcią, ale dopuszcza także\nbardziej granularną konfigurację poprzez danie użytkownikowi kontroli nad implemen-\ntacją sterty, czy dopuszczeniem niestandardowych implementacji niektórych elementów,\nnp. wątku bezczynnego czy błędu alokacji. Zużycie zasobów może być kontrolowane po-\nprzez  ustalenie  m.in  rozmiarów  stosów,  maksymalnej  ilości  priorytetów,  i  dostępnych\nprymitywów synchronizacyjnych i komunikacyjnych.\nMożliwe  jest  także  skonfigurowanie  zmiennej  przetrzymującej  wartość  „tick”  jako\nzmienną 16-bitową, co znacznie poprawi wydajność na procesorach 8- i 16-bitowych.\nOtrzymujemy  też  konfiguracje  poprawiające  debugging  i  ułatwiające  analizę  (jak\nconfigASSERT), sprawdzanie przepełnienia stosu, oraz statystyki z uruchomienia. Ist-\nnieje również możliwość zapisywania i wizualizacji zdarzeń (jak zdarzenia prymitywów\nkomunikacyjnych,  wywołania  procedur  obsługi  przerwań,  zmiany  kontekstu)  w  czasie\nrzeczywistym.\nPomimo swojego ogólnego przeznaczenia\n5\n, możliwości konfiguracyjne systemu Fre-\neRTOS  sprawiają,  że  wymagana  funkcjonalność  może  zostać  uzyskana  na  używanej\nplatformie w efektywny sposób. Plusem jest również modularność, zapewniana poprzez\nmożliwość zarządzania dostępnością poszczególnych komponentów systemu.\n2.3.2    Keil RTX5\nPlikiem konfiguracyjnym systemu Keil RTX5 jest plikRTX\nConfig.h. Po otworzeniu go,\nrównież znajdziemy wiele ciekawych opcji konfiguracyjnych.\n•OSDYNAMICMEMSIZE– definiuje rozmiar globalnej puli pamięci dynamicznej (po-\ndany w bajtach).\n•OS\nSTACKSIZE– definiuje rozmiar stosu zadań o ustawionym rozmiarze domyśl-\nnym.\n•OSROBINENABLE– uruchamia przełączanie między wątkami o równym priorytecie.\n•OSROBINTIMEOUT– definiuje długość kwanta czasu w przełączaniu między zada-\nniami o tym samym priorytecie.\n•OSOBJPTRCHECK– sprawdza wyrównanie i region pamięci wskaźnika obiektu.\n•OSSVCPTRCHECK–  sprawdza  wyrównanie  i  region  pamięci  wskaźnika  funkcji\nSVC.\n•Konfiguracje związane z rozmiarem pamięci przeznaczonej dla dynamicznej alo-\nkacji obiektów i zadań, np.OSTIMERNUM.\n•OSIDLETHREADSTACKSIZE–  definiuje  rozmiar  stosu  dla  wątku  bezczynności\n(idle).\n•OSSTACKCHECK– włącza sprawdzanie przepełnienia stosu.\n•OSSTACKWATERMARK– włącza inicjalizację stosów zadań ze wskaźnikiem – zna-\nkiem wodnym, umożliwiającym analizę zużycia pamięci stosu.\n5\nFreeRTOS został przeniesiony na liczne platformy od szeregu dostawców [18].\n36\n\n•OSOBJMEMUSAGE– uruchamia zbieranie statystyk ze zużycia pamięci przez obiek-\nty.\n•OSPRIVILEGEMODE– ustawia domyślny tryb procesora dla wykonywania zadania.\n•OSTIMERTHREADPRIO– definiuje priorytet dla wątku czasomierzy.\n•OS\nSAFETYFEATURES– uruchamia dodatkowe mechanizmy związane z bezpieczeń-\nstwem funkcjonalnym (ang.Functional Safety – FuSa). Opcja ta jest szczególnie\nprzydatna w systemach, które muszą spełniać rygorystyczne normy bezpieczeń-\nstwa, jak ISO 26262 w motoryzacji czy IEC 61508 w automatyce przemysłowej.\nKeil RTX5 umożliwia bardziej granularną manipulację alokacją pamięci dynamicz-\nnej niż jest to w przypadku systemu FreeRTOS. Pozwala na efektywne wykorzystanie\npamięci,  poprzez  możliwość  zdefiniowania  bloków  w  sposób  oparty  o  rozmiar  i  ilość\nwykorzystywanych  w  aplikacji  obiektów.  Programistom  zostaje  udostępniony  również\nszereg opcji konfiguracyjnych poświęconych funkcjom debugowania, analizy działania,\ni bezpieczeństwu.\n2.3.3    Podsumowanie\nFreeRTOS odznacza się elastycznością – dostępność możliwości takich jak dokonywanie\nalteracji  w  dostępnych  komponentach  systemu,  łatwe  wstrzykiwanie  niestandardowej\nfunkcjonalności, czy dostępność prostego mechanizmu integracji nowych implementacji\nsterty sprawiają, że jest on dobrze dostosowany do „majsterkowania” przy jego sposobie\ndziałania.\nSystem  Keil  RTX5  wyróżnia  się  możliwościami  debugowania,  analizy  działania,\ni  bezpieczeństwa.  W  przeciwieństwie  do  FreeRTOSa,  który  umożliwia  tylko  genero-\nwanie statystyk z czasu działania zadań (poprzez wykorzystanie opcji konfiguracyjnej\nconfigGENERATE\nRUNTIMESTATS), Keil RTX5 udostępnia również zapisywanie zużycia\npamięci  poświęconej  poszczególnym  obiektom  i  stosom  zadań.  Jest  tu  również  możli-\nwe monitorowanie zdarzeń (analogiczne do dostarczanego przezconfigTRACE\nFACILITY\nFreeRTOSa). Zdarzenia mogą być przeglądane w programie dostarczanym przez Keil –\nKeil Event Viewer.\nMechanizm zapisywania zdarzeń istnieje więc w obu systemach. Informacje dostar-\nczane przez Tracealyzer lub Event Viewer można wykorzystać do głębokiej analizy dzia-\nłania aplikacji, przykładowo, w celu zidentyfikowania wąskich gardeł.\n2.4    Zadania\nMożliwość tworzenia zadań i nadawania im priorytetów to podstawowa funkcjonalność\nkażdego systemu operacyjnego, również czasu rzeczywistego.\nCMSIS-RTOS2 API dostarcza dostarcza wielu funkcji do manipulacji zadaniami.\n•osThreadNew()–  tworzy  nowe  zadanie  i  dodaje  je  do  puli  aktywnych  zadań\n6\n.\nPrzykład użycia pokazano na listingu 2.3.\n•osThreadGetStackSpace(osThreadId\nt id)– zwraca dostępną pamięć stosu za-\ndania.\n6\nZobacz rysunek 2.4.\n37\n\nListing 2.3: Przykład tworzenia zadania w CMSIS-RTOS2 API\n1#include \"cmsis_os2.h\"\n2\n3void  myThread(void *argument) {\n4while  (1) {\n5// Task  logic\n6}\n7}\n8\n9int  main (void) {\n10const  osThreadAttr_t  thread_attr = {\n11.name = \"myThread\",                   // Name of the  thread\n12.priority = osPriorityNormal ,       //  Initial  thread  priority\n13.stack_size = 1024 * 4                // Set  custom  stack  size\nfor  thread\n14};\n15\n16osThreadId_t  tid;\n17osKernelInitialize ();\n18tid = osThreadNew(myThread , NULL , &thread_attr); //  Create  the\nthread\n19\n20if (tid != NULL) {\n21osKernelStart ();                       // Start  kernel  scheduling\n22}\n23\n24for  (;;) {}\n25}\n•osThreadSetPriority(osThreadIdt id, osPriorityt priority)–  zmienia\npriorytet zadania.\n•osThreadYield()– przekazuje kontrolę nad procesorem kolejnemu zadaniu bę-\ndącemu w stanie „READY”.\n•osThreadSuspend(osThreadId\nt id)– zatrzymuje wykonanie zadania.\n•osThreadResume(osThreadIdt id)– kontynuuje wykonanie zadania.\n•osThreadExit()– zakańcza działanie wywołującego zadania.\n•osThreadTerminate(osThreadIdt id)– zakańcza działanie wątku o przekaza-\nnym parametrzeid.\n•osThreadGetCount()– zwraca ilość aktywnych zadań.\n•osThreadEnumerate(osThreadId\nt *threads, uint32t max)– zwraca aktyw-\nne wątki. Numery identyfikacyjne wątków zostaną wpisane do parametruthreads.\n38\n\n2.4.1    FreeRTOS\nOba  systemy  operacyjne  porządkują  informacje  o  zadaniu  –  jego  blok  kontrolny  –\nw  oparciu  o  strukturę  języka  programowania  C.  Struktura  TCB  w  systemie  FreeR-\nTOS  jest  zależna  od  opcji  konfiguracyjnych,  i  może  mieć  różny  rozmiar  zależnie  od\nilości  aktywowanych  komponentów  systemu.  Przykładowo,  włączenie  muteksów  doda\ndo deklaracji bloku kontrolnego dwie zmienne, każda o rozmiarze 4 bajty\n7\n.\nW typowej konfiguracji, blok kontrolny zadania systemu FreeRTOS ma wielkość 64\nbajtów\n8\n[22]. Dodanie notyfikacji zadań\n9\nzwiększy rozmiar każdego zadania o 8 bajtów.\nDodanie  muteksów  obciąży  każde  zadanie  o  kolejne  8  bajtów.  W  pełnej  konfiguracji\nrozmiar bloku kontrolnego zadania FreeRTOSa może przekroczyć nawet 130 bajtów\n10\n.\nMożliwe stany zadania w systemie FreeRTOS to:\n•eRunning– zadanie aktualnie w toku;\n•eReady– zadanie gotowe do wykonania;\n•eBlocked– zadanie zablokowane;\n•eSuspended– zadanie zatrzymane lub zablokowane na nieskończony okres czasu;\n•eDeleted– zadanie zostało usunięte, ale blok kontrolny jeszcze nie został zwol-\nniony;\n•eInvalid– używane jako nieprawidłowy stan zadania.\nMożliwe przejścia między stanami zadania zostały zilustrowane na rysunku 2.3.\n2.4.2    Keil RTX5\nW przypadku systemu Keil RTX5 rozmiar bloku kontrolnego zadania jest spójny mię-\ndzy konfiguracjami, a więc blok kontrolny wspiera wszystkie funkcjonalności systemu\nw  każdej  sytuacji.  Deklaracja  owej  struktury  danych  dla  systemu  Keil  RTX5  została\nprzedstawiona na listingu 2.4. Jej rozmiar wynosi 80 bajtów.\nMożliwe stany zadania w systemie Keil RTX5 to:\n•osRtxThreadInactive– zadanie nie jest na liście planowania (zakończyło działa-\nnie lub nie zostało jeszcze rozpoczęte),\n•osRtxThreadReady– zadanie gotowe do wykonania,\n•osRtxThreadRunning– zadanie aktualnie w toku,\n•osRtxThreadBlocked– zadanie zablokowane,\n•osRtxThreadTerminated– zadanie zakończyło działanie.\nMożliwe przejścia między stanami zadania zostały zilustrowane na rysunku 2.4. Dla\nzadań zablokowanych system definiuje kilka dodatkowych stanów typuWaitingopar-\ntych oBlocked. Stany te kategoryzują dodatkowo powód zablokowania (jak na przykład\nosRtxThreadWaitingMutex).\n7\nZmienne te są odpowiedzialne za poprawną obsługę mechanizmu dziedziczenia priorytetu.\n8\nRozważana architektura 32-bitowa.\n9\nNotyfikacje zadania (ang.Task Notifications) to lekka alternatywa dla prymitywów synchronizacyj-\nnych, umożliwiająca bezpośrednią komunikację z konkretnym zadaniem. Zostanie ona szerzej opisana w\nkolejnym rozdziale.\n10\nFreeRTOS: wersja V10.3.1.\n39\n\nRysunek 2.3: Dostępne stany zadań w systemie FreeRTOS. Źródło [16].\nRysunek 2.4: Dostępne stany zadań w systemie Keil RTX5. Źródło [36].\n40\n\nListing 2.4: Implementacja bloku kontrolnego zadania w systemie Keil RTX5\n1/// Thread  Control  Block\n2typedef  struct  osRtxThread_s {\n3uint8_t                                id;   ///< Object  Identifier\n4uint8_t                            state;   ///< Object  State\n5uint8_t                            flags;   ///< Object  Flags\n6uint8_t                             attr;   ///< Object  Attributes\n7const  char                        *name;   ///< Object  Name\n8struct  osRtxThread_s    *thread_next;   ///< Link  pointer  to next\nThread  in  Object  list\n9struct  osRtxThread_s    *thread_prev;   ///< Link  pointer  to\nprevious  Thread  in  Object  list\n10struct  osRtxThread_s     *delay_next;   ///< Link  pointer  to next\nThread  in  Delay  list\n11struct  osRtxThread_s     *delay_prev;   ///< Link  pointer  to\nprevious  Thread  in Delay  list\n12struct  osRtxThread_s    *thread_join;   ///< Thread  waiting  to\nJoin\n13uint32_t                           delay;   ///< Delay  Time/Round\nRobin  Time  Tick\n14int8_t                          priority;   ///< Thread  Priority\n15int8_t                    priority_base;   ///< Base  Priority\n16uint8_t                     stack_frame;   ///< Stack  Frame (\nEXC_RETURN [7..0])\n17uint8_t                  flags_options;   ///< Thread/Event  Flags\nOptions\n18uint32_t                     wait_flags;   ///< Waiting  Thread/Event\nFlags\n19uint32_t                  thread_flags;   ///< Thread  Flags\n20struct  osRtxMutex_s      *mutex_list;   ///< Link  pointer  to list\nof owned  Mutexes\n21void                         *stack_mem;   ///< Stack  Memory\n22uint32_t                     stack_size;   ///< Stack  Size\n23uint32_t                              sp;   ///< Current  Stack\nPointer\n24uint32_t                    thread_addr;   ///< Thread  entry  address\n25uint32_t                      tz_memory;   ///< TrustZone  Memory\nIdentifier\n26uint8_t                             zone;   ///< Thread  Zone\n27uint8_t                     reserved [3];\n28struct  osRtxThread_s      *wdog_next;   ///< Link  pointer  to next\nThread  in  Watchdog  list\n29uint32_t                      wdog_tick;   ///< Watchdog  tick\ncounter\n30} osRtxThread_t;\n41\n\nTabela 2.3: Przegląd dostępnych prymitywów komunikacyjno-sygnalizacyjnych w Fre-\neRTOS i Keil RTX5\nFreeRTOSKeil RTX5\nNotyfikacje zadania (Task Notifications)Flagi wątku (Thread Flags)\nGrupy zdarzenia (Event Groups)Flagi zdarzenia (Event Flags)\nBufor strumienia (Stream Buffer)BRAK\nBufor wiadomości (Message Buffer)BRAK\nKolejka (Queue)Kolejka wiadomości (Message Queue)\nSemafor binarny (Binary Semaphore)Semafor (Semaphore)\nSemafor liczący (Counting Semaphore)Semafor (Semaphore)\n13\nMuteks (Mutex)Muteks (Mutex)\nMuteks rekursywny (Recursive Mutex)Muteks (Mutex)\n14\nBRAKPula pamięci (Memory Pool)\n2.4.3    Podsumowanie\nOba systemy operacyjne wykorzystują analogiczne podejścia do zarządzania zadaniami,\nw oparciu o zbliżone zbiory dostępnych stanów. FreeRTOS wykazuje w swojej implemen-\ntacji bloków kontrolnych zadań pewną przewagę, wynikającą z zastosowania makr do\nwarunkowej kompilacji dodatkowych pól, wymaganych tylko po włączeniu opcjonalnych\nfunkcjonalności. Umożliwia to zmniejszenie zużycia pamięci RAM na bloki kontrolne w\nminimalnych konfiguracjach.\n2.5    Synchronizacja zadań\nOba systemy operacyjne udostępniają serię konstrukcji komunikacyjnych, które niekiedy\ndostarczają analogicznych funkcjonalności pod różnymi nazwami. Przykładowo, „Flagi\nwątku”  (ang.Thread  Flags)  systemu  Keil  RTX5  są  nazywane  „Notyfikacjami  zada-\nnia”  (ang.Task  Notifications)  we  FreeRTOSie.  Tabela  2.3  indeksuje  dostępne  w  obu\nsystemach prymitywy, oraz unaocznia ewentualne różnice w nazewnictwie\n11\n. Prymity-\nwy systemu FreeRTOS z pierwszej kolumny mogą być wykorzystywane z użyciem API\nCMSIS-RTOS2,  poprzez  wywołania  odnoszące  się  do  odpowiednich  prymitywów  Keil\nRTX5 z drugiej kolumny\n12\n. Dla wpisów z wartością „BRAK” w drugiej kolumnie, jest\nto niemożliwe – jedyną metodą jest bezpośrednie wywołanie API FreeRTOSa.\n2.5.1    FreeRTOS\nFreeRTOS implementuje semafory i muteksy w oparciu o kolejkę. Dzięki takiemu po-\ndejściu możliwe jest ograniczenie zużycia pamięci ROM w aplikacji (poprzez redukcję\nilości kodu). Z implementacyjnej strony wygląda to dość interesująco.\n•Kolejka, służąca do przesyłania wiadomości o ustalonym rozmiarze między za-\ndaniami, jest centralnym prymitywem zaimplementowanym od podstaw.\n11\nMechanizmy mogą różnić się szczegółami implementacyjnymi, jednak ich funkcja pozostaje zbliżona.\n12\nKeil RTX5 używa CMSIS-RTOS2 natywnie.\n13\nW  systemie  Keil  RTX5  różnica  między  typami  semafora  jest  czysto  koncepcyjna.  Oba  rodzaje\nprymitywu mogą być stworzone poprzez wywołanieosSemaphoreNewz różnymi parametrami.\n14\nPodobnie jak w przypadku semafora – w systemie Keil RTX5 muteks rekursywny można stworzyć\npoprzez wywołanieosMutexNewz paramteremosMutexRecursive.\n42\n\n•Semaforjest kolejką długości zero, o początku i końcu wskazującymi naNULL.\nZmienna określająca ilość czekających wiadomościuxMessagesWaitingjest usta-\nwiana na 1 w, przypadku semafora binarnego, lub zdefiniowany przez programi-\nstę parametr, w przypadku semafora liczącego. Odebranie wiadomości jest jedno-\nznaczne z „wzięciem” semafora, wysłanie wiadomości – z „oddaniem” go.\n•Muteksjest zaimplementowany analogicznie do semafora binarnego. Dodatkowa\nflagauxQueueTypeokreśla czy kolejka jest muteksem. Umożliwia ona selektywne\ndodanie logiki odpowiadającej za dziedziczenie priorytetu.\nSposób implementacji mechanizmów komunikacyjnych w systemie FreeRTOS – opar-\ncie  podstawowych  prymitywów  o  kolejkę  –  znacznie  zmniejsza  zużycie  pamięci  ROM\nsystemu,  nie  jest  to  jednak  rozwiązanie  pozbawione  wad.  Zastosowanie  takiej  meto-\ndy wymusza deklarację dodatkowych, niekoniecznych w innej sytuacji, pól w każdym\nz prymitywów. Ponosimy zatem koszt w formie zwiększonego zużycia pamięci RAM.\nPoza typowymi prymitywami komunikacyjnymi – muteksem, semaforem, i kolejką,\nFreeRTOS udostępnia również następujące konstrukcje:\n•notyfikacje zadania,\n•grupy zdarzenia,\n•bufory strumienia,\n•bufory wiadomości.\nNotyfikacje zadania\nNotyfikacje zadania (ang.Task Notifications) to lekki\n15\nmechanizm komunikacyjny opar-\nty  o  struktury  sygnalizacyjne  przypisane  bezpośrednio  do  zadań  (należące  do  bloku\nkontrolnego zadania).\nSą one relatywnie wszechstronną konstrukcją, i mogą być używane zarówno w sposób\nanalogiczny do semafora (przez użycie wywołańxTaskNotifyGiveixTaskNotifyTake)\njak  i  grup  zdarzenia  (ang.Event  Groups)  –  poprzez  użycie  wywołańxTaskNotify\nixTaskNotifyWait). Prymityw umożliwia również przekazywanie 32-bitowych wartości,\nco w pewnych warunkach może pozwolić na uniknięcie konieczności użycia kolejki.\nOpisana wszechstronność pozwala na zastosowanie notyfikacji zadań w wielu sytu-\nacjach, w których inaczej byłoby konieczne stworzenie dedykowanej, zewnętrznej struk-\ntury komunikacyjnej. Dodatkowo, bezpośrednia natura notyfikacji zadania pozwala na\nodblokowanie czekającego wątku 45% szybciej niż w przypadku wykorzystania dedyko-\nwanego, oddzielnego obiektu przy jednoczesnym niższym zużyciu pamięci RAM [19].\nOgraniczeniem w stosowaniu notyfikacji zadań jest ich dedykowana natura – zdarze-\nnie może zostać wysyłane naraz tylko do jednego zadania.\nGrupy zdarzenia\nGrupy zdarzenia (ang.Event Groups) to prymityw sygnalizacyjny, pozwalający na syn-\nchronizowanie wielu zadań w oparciu o flagi reprezentujące zajście zdarzenia. Pojedyn-\ncza grupa zdarzenia zawiera w systemie FreeRTOS liczbę bitów (flag) zdarzenia zależną\nod definicji konfiguracji systemowejconfigTICK\nTYPEWIDTHINBITS:\n15\nPojedyncza notyfikacja jest definiowana przez 8-bitową flagę stanu i 32-bitową wartość.\n43\n\n•8 dla wartościTICKTYPEWIDTH16BITS,\n•24 dla wartościTICKTYPEWIDTH32BITS,\n•56 dla wartościTICKTYPEWIDTH64BITS.\nPodstawowe  operacje  na  grupach  zdarzenia  to  ustawienie  flag,  czyszczenie  flag,\ni oczekiwanie na flagę lub zestaw flag.\nBufor strumienia i wiadomości\nBufor strumienia i bufor wiadomości (ang.Stream and Message Buffers) to prymitywy\nkomunikacyjne służące dla przesyłu danych pomiędzy dwoma zadaniami, lub procedurą\nobsługi przerwania a zadaniem. Przeznaczeniem tych struktur jest komunikacja jednego\nnadawcy z jednym odbiorcą\n16\n– w tym kierunku zostały one zoptymalizowane (w prze-\nciwieństwie do kolejki, której można użyć do transportu danych pomiędzy większymi\nilościami producentów i konsumentów).\nBufory strumienia umożliwiają transfer poprzez wysłanie lub odbiór arbitralnej ilo-\nści  bajtów.  Bufory  wiadomości  (zaimplementowane  na  podstawie  bufora  strumienia)\ndziałają w zbliżony sposób, ale przekazują wiadomości o określonym rozmiarze. Obie\nstruktury są typowo używane do implementacji architektury producent-konsument.\n2.5.2    Keil RTX5\nW systemie Keil RTX5 każdy z podstawowych mechanizmów komunikacyjnych jest za-\nimplementowany osobno – nie ma tutaj prymitywu bazowego, o który oparte są pozosta-\nłe. Oznacza to, że semafory, muteksy i kolejki wiadomości są niezależnymi jednostkami,\nkażda zoptymalizowana pod konkretny scenariusz użycia.\nPoza wspomnianymi podstawowymi mechanizmami synchronizacji i komunikacji Ke-\nil RTX5 udostępnia również następujące struktury:\n•flagi wątku,\n•flagi zdarzenia,\n•pula pamięci.\nFlagi wątku\nFlagi wątku (ang.Thread  Flags) Keil RTX5 są odpowiednikiem „notyfikacji zadania”\nz systemu FreeRTOS. Udostępniany przez CMSIS-RTOS2 interfejs jest dla tego mecha-\nnizmu następujący:\n•osThreadFlagsSet(osThreadId\nt tid, uint32t flags)–  ustawia  flagi  dla\nkonkretnego zadania,\n•osThreadFlagsClear(uint32t flags)– czyści flagi dla wywołującego zadania,\n•osThreadFlagsGet(void)– zwraca flagi dla wywołującego zadania,\n16\nKomunikacja między wieloma zadaniami jest możliwa, ale wymaga spełnienia specjalnych warunków\n– wysyłanie lub odbiór muszą być wywołany bez opóźnienia i z sekcji krytycznej.\n44\n\nRysunek 2.5: Pula pamięci w Keil RTX5 – wizualizacja sposobu alokacji. (Źródło: [37])\n•osThreadFlagsWait(uint32\nt flags, uint32t options, uint32t to)– cze-\nka na ustawienie flag, maksymalnie przez sprecyzowany czastimeout(parametr\nto).\nOstatnia z funkcji może czekać na dowolną, lub wszystkie ustawione flagi (logikaOR\nvs  AND). Domyślnie, flagi, na które oczekiwano zostaną automatycznie wyczyszczone\npo  wejściu  do  oczekującego  zadania.  Zachowanie  to  można  zmienić  poprzez  podanie\nodpowiedniej opcji (osFlagsNoClear) jako argument omawianej funkcji.\nFlagi wątku są w systemie Keil RTX5 implementowane jako bity pojedynczej zmien-\nnej typuuint32\nt, a zatem ich ilość wynosi 32.\nFlagi zdarzenia\nFlagi  zdarzenia  (ang.Event  Flags)  mają  działanie  analogiczne  do  „grup  zdarzenia”\nprzedstawionych w sekcji odnoszącej się do systemu FreeRTOS. Podobnie jak dla flag\nwątku, najważniejszymi funkcjami w zasięgu programisty jest zestawosEventFlagsSet,\nosEventFlagsClear,osEventFlagsGet, orazosEventFlagsClear.\nZachowanie flag zdarzenia jest analogiczne do działania flag wątku – różnica polega\nna braku asocjacji z konkretnym zadaniem, przez co obiekt tego typu można wykorzystać\ndo synchronizacji większej ilości zadań.\nPula pamięci\nPula pamięci (ang.Memory  Pool) jest  w systemie Keil  RTX5  mechanizmem alokacji\ni komunikacji międzyzadaniowej. Umożliwia tworzenie bloków pamięci o ustalonym roz-\nmiarze. Bloki te posiadają własność bezpieczeństwa dla wielowątkowości, dzięki czemu\nmogą być używane do dzielenia danych między zadaniami (współdzielona pamięć).\nPula pamięci jest implementowana jako lista dostępnych, niewykorzystanych bloków\no ustalonym rozmiarze. Rozmiar i ilość bloków są definiowane w czasie tworzenia obiektu\npuli pamięci (wywołanieosMemoryPoolNew).\nWizualizację działania puli pamięci przedstawiono na rysunku 2.5. Alokacja bloku,\nodbywająca się poprzez wywołanieosMemoryPoolAlloc, odpina jeden element z listy\npustych bloków, i zwraca jego adres użytkownikowi. Zwolnienie bloku pamięci (poprzez\nużycie funkcjiosMemoryPoolFree) ponownie doda blok do listy. Rezultatem wykorzysta-\nnia tego podejścia jest alokacja znacznie szybsza niż dynamiczne przydzielanie pamięci,\noraz całkowite uniknięcie problemu fragmentacji.\n2.5.3    Podsumowanie\nOba systemy implementują podstawowe mechanizmy komunikacji i sygnalizacji, które\nsą w stanie zaspokoić wszelkie potrzeby zarządzania wielowątkowością, jakie można na-\npotkać  programując  aplikację  opartą  o  RTOS.  Prymitywy  komunikacyjne  specyficzne\n45\n\nTabela 2.4: Porównanie wielkości bloków kontrolnych podstawowych obiektów w syste-\nmach Keil RTX5 i FreeRTOS.\nPrymitywFreeRTOS (bajty)Keil RTX5 (bajty)\nZadanie64\n18\n80\nKolejka8052\nSemafor8016\nMuteks8028\ndla poszczególnych systemów mają ograniczoną liczbę zastosowań, i mogą być z powo-\ndzeniem zastąpione innymi, dostępnymi mechanizmami.\nGłówną różnicą w sposobie wdrożenia komunikacji międzyzadaniowej jest fakt, że\nFreeRTOS implementuje podstawowe prymitywy w oparciu o pojedynczy obiekt – ko-\nlejkę. Jest to kompromis, pozwalający na zaoszczędzenie pamięci kodu (ROM) kosztem\nzwiększonego  rozmiaru  bloków  kontrolnych  kolejek,  semaforów,  i  muteksów\n17\n,  a  więc\npamięci roboczej (RAM).\n2.6    Wydajność systemów\n2.6.1    Pamięć\nDokumentacja przedstawianych systemów operacyjnych wspomina prognozowane zuży-\ncie pamięci ROM (ang.Read-Only  Memory, zazwyczaj implementowana przez Flash).\nDla systemu FreeRTOS jest to 5-10kB [22], natomiast dla Keil RTX5 – 5kB [39]. Można\nspodziewać się, że są to oczekiwane wartości dla minimalnych konfiguracji. FreeRTOS,\nmimo posiadania kilku implementacji mechanizmów komunikacyjnych opartych o jeden\n– kolejkę, szacuje większe zużycie niż Keil RTX5. Nie jest to do końca zgodne z oczekiwa-\nniami, a zatem w kolejnym rozdziale zostanie podjęta próba dokładniejszego określenia\nzużycia pamięci ROM przez oba systemy.\nW celu porównania narzutu pamięciowego systemów operacyjnych dla pamięci o do-\nstępie swobodnym (RAM, ang.Random Access Memory), poddano analizie wielkości ich\nbloków kontrolnych zadań oraz mechanizmów komunikacyjno-sygnalizacyjnych. Porów-\nnanie wielkości bloków kontrolnych dla podstawowych obiektów zostało przedstawiona\nna tabeli 2.4. Zgodnie z przewidywaniami, bloki kontrolne prymitywów synchronizacyj-\nnych są znacznie mniejsze w systemie Keil RTX5.\n2.6.2    Prędkość\nPorównanie prędkości zostało zaczerpnięte z pracy pt.Benchmarking and Comparison of\nTwo Open-source RTOSs for Embedded Systems Based on ARM Cortex-M4 MCU[41].\nTesty  zostały  wykonane  na  mikrokontrolerze  STM32F429  wyposażonym  w  procesor\nARM Cortex-M4. Wersja FreeRTOSa zastosowana przez autorów to FreeRTOS v10.2.0.\nWersja CMSIS-RTOS2 nie została podana, jednak autorzy stwierdzają użycie najnow-\nszych  wersji,  a  aktualną  wersją  RTX  równoległą  z  FreeRTOSem  v10.2.0  (wydaną  25\nlutego 2019 roku) była wersja RTX5.4.0.\nPorównywana jest prędkość przeprowadzenia następujących operacji:\n17\nDokładne różnice między rozmiarami bloków kontrolnych zostaną zbadane w kolejnej sekcji.\n18\nZależne od konfiguracji.\n46\n\nRysunek 2.6: Porównanie szybkości wykonania podstawowych operacji w FreeRTOSie\ni Keil RTX5. Źródło: [41].\n•zmiany kontekstu – czas przełączenia kontekstu pomiędzy zadaniami o tym samym\npriorytecie,\n•wywłaszczenia  –  czas  przełączenia  kontekstu  na  zadanie  o  wyższym  priorytecie\nniż obecny,\n•przekazania semafora – czas przekazania świeżo odblokowanego semafora zadaniu\noczekującemu na niego,\n•przekazania wiadomości – czas odbioru wysłanej wiadomości przez oczekujące na\nnią zadanie.\nCzas operacji jest mierzony przez zastosowanie komponentu ARM DWT – ang.Data\nWatchpoint and Trace. Jedną z jego funkcjonalności jest licznik cykli, co jest używane do\nokreślenia ilości cykli wymaganej do przeprowadzenia analizowanej akcji. Analiza jest\npowtórzona 50000 razy, a otrzymany wynik ilości cykli uśredniany. Otrzymana średnia,\npodzielona przez taktowanie mikrokontrolera (w tym przypadku 80MHz), jest finalnym\nwynikiem.\nRezultaty analizy zostały przedstawione w tabeli 2.5. Wizualizację rezultatów przed-\nstawiono na rysunku 2.6.\nFreeRTOSKeil RTX5\nZmiana kontekstu1.7452μs3.5266μs\nWywłaszczenie4.5342μs4.6524μs\nPrzekazanie semafora3.6093μs16.4899μs\nPrzekazanie wiadomości19.2067μs4.5129μs\nTabela  2.5:  Porównanie  szybkości  wykonania  podstawowych  operacji  w  FreeRTOSie\ni Keil RTX5. Źródło: [41].\n47\n\n2.6.3    Podsumowanie\nFreeRTOS szacuje objętość pamięci kodu jako większą niż jego odpowiednik autorstwa\nKeil. Jest to niespodziewane, i zostanie poddane dodatkowej analizie w kolejnym roz-\ndziale. Nie ulega natomiast wątpliwości, że FreeRTOS implementuje większe bloki kon-\ntrolne podstawowych prymitywów (z możliwym wyjątkiem bloku kontrolnego zadania\n– zależne od konfiguracji).\nW  porównaniu  prędkości,  FreeRTOS  jest  liderem  w  trzech  z  czterech  analizowa-\nnych scenariuszy. Szczególnie istotna wydaje się być ponad dwukrotnie szybsza zmiana\nkontekstu zapewniana przez FreeRTOS. Różnica ta może mieć istotny wpływ na wy-\ndajność w typowej aplikacji korzystającej z kwantowania czasu do przełączania między\nzadaniami o tym samym priorytecie.\n48\n\nRozdział 3\nPrzykładowa aplikacja – Stacja\nPogodowa\nW  celu  zapoznania  się  z  przedstawianymi  systemami  operacyjnymi  napisana  została\naplikacja  –  Stacja  Pogodowa.  Stacja  Pogodowa  zawiera  wyłącznie  wywołania  RTOS\nzgodne z CMSIS-RTOS2, a zatem może zostać uruchomiona na obu systemach, poprzez\nustawienie  źródeł  RTOS  na  implementację  systemu  operacyjnego  FreeRTOS  (z  war-\nstwą opakowującą CMSIS-RTOS2) lub Keil RTX5. Projekt jest dostępny w publicznym\nrepozytorium pod linkiem: Stacja Pogodowa (GitHub)\n1\n.\nIstotnym celem projektu było sprawdzenie prawdziwości założenia o przeźroczystości\nimplementacji FreeRTOSa względem warstwy opakowującej CMSIS-RTOS2. W szcze-\ngólności, celem autora było wykorzystanie tego samego kodu do zbudowania aplikacji\nopartej o różne systemy operacyjne. Zadanie to udało się zrealizować.\nFunkcjonalność stacji pogodowej to zbieranie danych dot. temperatury, wilgotności,\nciśnienia,  oraz  jakości  powietrza.  Dane  te  są  przetwarzane  i  przesyłane  przez  UART\nw formie logów, oraz pokazywane na wyświetlaczu typu e-papier. Zdjęcie kompletnego\nprojektu przedstawiono na rysunku 3.1.\n3.1    Komponenty\nProjekt Stacja Pogodowa został oparty o komponenty przedstawione poniżej.\n•Płytkę deweloperską STM Nucleo-L476RG, zawierającą:\n–32-bitowy mikroprocesor ARM Cortex-M4 o taktowaniu 80MHz,\n–1MB pamięci Flash,\n–128kB pamięci SRAM.\n•Sensor Bosch BME680, umożliwiający pomiar:\n–temperatury,\n–wilgotności,\n–ciśnienia,\n–stężenia lotnych związków organicznych (ang.Volatile Organic Compounds –\nVOC).\n1\nAdres linku: https://github.com/pjasinski990/stmweatherstation.\n49\n\nRysunek 3.1: Projekt Stacja Pogodowa – zdjęcie\nRysunek 3.2: Projekt Stacja Pogodowa – moduły\n50\n\nRysunek 3.3: Projekt Stacja Pogodowa – połączenia\n•Wyświetlacz typu e-papier (papier elektroniczny).\nMikrokontroler  STM32L476RG,  który  oparta  jest  użyta  płytka  deweloperska,  jest\nrównież  wyposażony  w  trzy  interfejsy  SPI,  z  których  dwa  zostały  wykorzystane  do\npodłączenia  modułów  e-papieru  oraz  sensora.  Pełną  specyfikację  i  możliwości  płytki\ndeweloperskiej można znaleźć na stronie dostawcy [44].\nUżyty  moduł  sensora  jest  zaawansowanym,  wielofunkcyjnym  czujnikiem  produko-\nwanym przez Bosch. Jego zasięg operacyjny, w którym wykazuje pełną dokładność to:\n•temperatura od -40°Cdo 85°C,\n•wilgotność od 0% do 100%,\n•ciśnienie od 300hPa do 1100hPa,\nco jest zdecydowanie wystarczające dla zastosowań projektu.\nDostarczana  przez  Bosch  biblioteka  BSEC  (ang.Bosch  Sensortec  Environmental\nCluster) [9] umożliwia przetworzenie danych z sensora na dane czytelne dla człowieka.\nW  szczególności,  przetwarza  dane  zebrane  z  sensora  stężenia  lotnych  związków  orga-\nnicznych  na  indeks  jakości  powietrza  IAQ  (ang.Indoor  Air  Quality).  Lotne  związki\norganiczne  to  organiczne  związki  chemiczne  charakteryzujące  się  wysokim  ciśnieniem\npary nasyconej w temperaturze pokojowej. Ta cecha umożliwia im łatwe odparowanie\nlub sublimację do atmosfery, przyczyniając się do zanieczyszczenia powietrza. Źródła\ntego typu zanieczyszczeń to między innymi urządzenia spalające paliwo, wyroby tyto-\nniowe, czy niektóre materiały budowlane. Wśród związków typu VOC można wymienić\nmiędzy innymi etanol, toluen, benzen, czy formaldehyd. Zastosowany sensor umożliwia\npomiar stężenia:\n•etanu,\n•izoprenu,\n•etanolu,\n51\n\nRysunek 3.4: Wartość indeksu jakości powietrza (IAQ) a jakość powietrza. Źródło: [7].\n•acetonu,\n•tlenku węgla (II).\nZebrane dane są przetwarzane do pojedynczej, skalarnej wielkości reprezentującej jakość\npowietrza. Jakość powietrza odpowiadająca poszczególnym wartościom indeksu została\nzilustrowana na rysunku 3.4.\nZastosowany  moduł  e-papieru  [15]  to  czarno-biały  wyświetlacz  o  przekątnej  1.54\ncala i rozdzielczości 200x200 pikseli. Jest produktem firmy Waveshare [14], która do-\nstarcza również bibliotekę przeznaczoną do obsługi tego modułu wraz z instrukcją jej\nintegracji [13].\nE-papier to specyficzny rodzaj wyświetlacza, którego działanie opiera się na prze-\nmieszczaniu naładowanych cząsteczek tuszu za pomocą pola elektrycznego. Umożliwia\nto uzyskanie dobrego kontrastu nawet w pełnym słońcu, oraz bardzo niskiego zużycia\nenergii – podświetlenie jest zbędne, a energia wymagana jedynie do zmiany położenia\npikseli. Ustawiony obraz utrzymuje się na wyświetlaczu nawet po odłączeniu zasilania.\nWadą e-papieru jest długi czas odświeżania (nawet kilka sekund). Cechy te sprawiają,\nże wyświetlacz oparty o papier elektroniczny jest dobrym wyborem dla projektu stacji\npogodowej. Zastosowanie to nie wymaga częstego odświeżania, a niskie zużycie energii\numożliwia użycie zasilania bateryjnego.\nSchemat modułowy projektu został przestawiony na rysunku 3.2. Moduły zostały\npołączone jak pokazano na rysunku 3.3.\n3.2    System budowania\nProjekt jest budowany za pomocą łańcucha narzędzi (ang.toolchain) GNU Arm Embed-\nded, czyli kolekcji narzędzi deweloperskich stworzonych do programowania na procesory\nz rodzin ARM Cortex-A, Cortex-R, i Cortex-M [3].\nSystem budowania został oparty o oprogramowanie GNU Make [28]. Jest to dość\nnietypowa metoda dla systemu operacyjnego Keil RTX5, który zazwyczaj jest rozwijany\nw zintegrowanym środowisku KeilμVision, dostarczającym łańcuch narzędzi i system\nbudowania. Z tego powodu integracja RTOSa w projekcie okazała się wyzwaniem, które\njednak ostatecznie udało się zrealizować.\n52\n\nPlik  opisujący  sposób  generowania  projektu  ze  źródeł  –Makefilezostał  począt-\nkowo  stworzony  przez  oprogramowanie  STM32CubeMX  [45]  wraz  z  resztą  szablonu\nprojektu (początkowo opartego wyłącznie o FreeRTOS). Do projektu zostały następnie\nręcznie dodane źródła systemu operacyjnego Keil RTX5, zaczerpnięte z repozytorium\nGitHub [40]. PlikMakefilezostał edytowany tak, aby umożliwić podmianę stosownych\nplików źródłowych systemu operacyjnego zależnie od wartości flagi.\nW  aktualnej  wersji\n2\nprojekt  może  zostać  zbudowany  na  podstawie  systemu  Keil\nRTX5 poprzez wywołaniemakez celem (ang.build target)allbez żadnej flagi:\n$ make  all\nW celu wykorzystania systemu FreeRTOS, należy podać flagęUSEFREERTOS:\n$ make  all  USE_FREERTOS =1\nRóżnice  między  sposobem  budowania  poszczególnych  systemów  operacyjnych  zo-\nstały zilustrowane na listingu 3.1. Oprócz wspomnianych różnic w plikach źródłowych,\nróżnią się też wymagane pliki nagłówkowe. Rozbieżności między dodawanymi kataloga-\nmi plików nagłówkowych zindeksowano na listingu 3.2.\n// Keil  RTX5  sources\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Config/RTX_Config\n.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/Source/os_systick.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_lib.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_system\n.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_kernel\n.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_thread\n.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/\nrtx_msgqueue.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_delay.\nc\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_memory\n.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_evr.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/\nrtx_evflags.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_timer.\nc\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/rtx_mutex.\nc\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/\nrtx_semaphore.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/\nrtx_mempool.c\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Source/\nirq_armv7m_rtx.s\n//  FreeRTOS  sources\n2\nCommit hash: ab3c1d67ff2b7f2ce3505fd9b474632f6f112e05\n53\n\n// Keil  RTX5  includes\nMiddlewares/Third_Party/CMSIS_5/CMSIS/Core/Include\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/Include\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Include\nMiddlewares/Third_Party/CMSIS_5/CMSIS/RTOS2/RTX/Config\nMiddlewares/Third_Party/CMSIS_5/Device/ARM/ARMCM4/Include\n//  FreeRTOS  includes\nMiddlewares/Third_Party/FreeRTOS/Source/include\nMiddlewares/Third_Party/FreeRTOS/Source/CMSIS_RTOS_V2\nMiddlewares/Third_Party/FreeRTOS/Source/portable/GCC/ARM_CM4F\nListing 3.2: Katalogi plików nagłówkowych zmieniane przez flagę budowania\nMiddlewares/Third_Party/FreeRTOS/Source/croutine.c\nMiddlewares/Third_Party/FreeRTOS/Source/event_groups.c\nMiddlewares/Third_Party/FreeRTOS/Source/list.c\nMiddlewares/Third_Party/FreeRTOS/Source/queue.c\nMiddlewares/Third_Party/FreeRTOS/Source/stream_buffer.c\nMiddlewares/Third_Party/FreeRTOS/Source/tasks.c\nMiddlewares/Third_Party/FreeRTOS/Source/timers.c\nMiddlewares/Third_Party/FreeRTOS/Source/CMSIS_RTOS_V2/cmsis_os2.c\nMiddlewares/Third_Party/FreeRTOS/Source/portable/MemMang/heap_4.c\nMiddlewares/Third_Party/FreeRTOS/Source/portable/GCC/ARM_CM4F/\nport.c\nListing 3.1: Pliki źródłowe zmieniane przez flagę budowania\n3.3    Implementacja\nImplementacja aplikacji uruchamia trzy zadania:\n•maintask, odpowiedzialne jedynie za inicjalizację modułów i zadań,\n•sensortask, odpowiedzialne za zbiór i przetwarzanie danych pogodowych z sen-\nsora (dane są zbierane raz na ok. 3s),\n•epaper\ntask, odpowiedzialne za odbiór przetworzonych danych z sensora i prezen-\ntowanie ich na wyświetlaczu. Zebranie nowych danych i odświeżenie wyświetlacza\nodbywa się raz na 20s.\nDeklaracje zadań zostały zaprezentowane na listingu 3.3. Dla każdego z zadań zo-\nstała sprecyzowana nazwa, priorytet, oraz rozmiar stosu (w bajtach). Największy stos\njest wymagany przez zadanie sensora, które przeprowadza złożone obliczenia w oparciu\no bibliotekę Bosch BSEC [9]. Są one stosowane do przetworzenia danych z sensora na\nczytelne dla człowieka wielkości (w szczególności jakość powietrza).\nW kodzie zostało zaimplementowane kilka modułów.\n•logger– moduł loggera umożliwia przesyłanie logów na peryferium UART w spo-\nsób bezpieczny dla wielowątkowości. Współdzielony zasób jest chroniony mutek-\nsem, a wykorzystanie w loggerze modułu RTC (ang.Real-Time  Clock) pozwala\nna dodanie znaku czasu (ang.timestamp) do przesyłanych logów.\n54\n\nListing 3.3: Deklaracja zadań projektu Stacja Pogodowa\n1osThreadId_t  main_task_handle;\n2const  osThreadAttr_t  main_task_attributes = {\n3.name = \"main_task\",\n4.stack_size = 1024,\n5.priority = (osPriority_t)osPriorityNormal ,\n6};\n7osThreadId_t  sensor_task_handle;\n8const  osThreadAttr_t  sensor_task_attributes = {\n9.name = \"sensor_task\",\n10.stack_size = 4096,\n11.priority = (osPriority_t)osPriorityNormal ,\n12};\n13osThreadId_t  epaper_task_handle;\n14const  osThreadAttr_t  epaper_task_attributes = {\n15.name = \"epaper_task\",\n16.stack_size = 1024,\n17.priority = (osPriority_t)osPriorityHigh ,\n18};\n•epaper–  moduł  odpowiedzialny  za  wyświetlanie  interfejsu  graficznego  na  pod-\nłączonym  e-papierze.  Jest  on  oparty  o  bibliotekę  dostarczaną  przez  sprzedawcę\nzastosowanego modułu wyświetlacza [13], którą opakowuje dostarczając wygodne\nfunkcje użytkowe.\n•sensor– moduł sensora oparty o sterownik Bosch [8] oraz bibliotekę BSEC [9].\nDostarcza funkcjonalności związanych ze zbieraniem i przesyłem odczytów z sen-\nsora.\nZadaniu e-papieru przydzielono wysoki priorytet. Pełni ono rolę konsumenta dla da-\nnych z sensora, i wykonuje się rzadziej. Diagram logiki projektu został przedstawiony na\nrysunku 3.5, gdzie przedstawiono przepływ kontroli w aplikacji, oraz sposób komunikacji\nmiędzy zadaniami.\n3.4    Zużycie pamięci\nW celu wykonania dodatkowej analizy zużycia pamięci przez systemu operacyjne, pod-\njęto próbę wyizolowania ich skompilowanych źródeł z projektu Stacja Pogodowa. Ilość\npamięci dynamicznej została ustawiona jako 4MB (4096 bajtów) dla obu systemów.\nAnalizę  wykonano  w  oparciu  o  skrypt  napisany  w  języku  Python\n3\n.  Skrypt  znaj-\nduje  pliki  obiektowe  wygenerowane  z  podanych  źródeł.  Następnie  używa  narzędzia\narm-none-eabi-nm, w celu wygenerowania analizy zawartych w pliku obiektowym sym-\nboli. Symbole te są grupowane do trzech sekcji:\n•.text– kod aplikacji (funkcje),\n•.bss(ang.block started by symbol) – niezainicjalizowane zmienne globalne i sta-\ntyczne,\n3\nSkrypt dostępny w repozytorium projektu pod nazwąmemorycollector.py.\n55\n\nRysunek 3.5: Stacja Pogodowa – diagram\nTabela 3.1: Zużycie pamięci Flash przez systemy operacyjne w aplikacji „Stacja Pogo-\ndowa”.\nSekcjaFreeRTOS (bajty)Keil RTX5 (bajty)\n.text34 51031 814\n.bss7 50113 077\n.data4368\nSuma:42 01545 259\n•.data– zainicjalizowane symbole statyczne i globalne.\nListingi 3.4 oraz 3.5 przedstawiają wyjście wywołania skryptu kodu, odpowiednio,\nFreeRTOSa  oraz  Keil  RTX5.  W  tabeli  3.1  zostało  przedstawione  porównanie  dla  po-\nszczególnych sekcji.\nIstotną wartością jest tutaj zużycie pamięci w segmencie.text, czyli sekcji zawie-\nrającej instrukcje. Widzimy niewielką (∼3kB) przewagę systemu Keil RTX5.\nZnaczny wpływ na zużycie pamięci ROM może mieć też segment.data, który za-\nwiera zmienne zainicjalizowane, a więc kompilator musi znać ich wartości. Wartości te\nzostaną skopiowane do pamięci RAM po resecie mikrokontrolera (zazwyczaj w proce-\ndurze obsługi przerwaniaReset, przed wejściem do funkcjimain). W tym przypadku\nsegmenty.dataobu systemów nie mają znacznych rozmiarów (w porównaniu do zuży-\ncia w segmencie.text). Większe zużycie pamięci wykazuje dla tej sekcji system Keil\nRTX5.\nOstatnia z rozważanych sekcji, czyli sekcja.bsszawiera niezainicjalizowane dane.\nDo pamięci ROM zostaną zapisane jedynie informacje o obszarach, jakie należy wyzero-\nwać, a więc mimo znacznych rozmiarów danych jakie zwróciło narzędzienm, jedynie ich\nniewielki fragment zostanie faktycznie zapisany w pamięci trwałej. Największy wpływ\nna zwrócony rozmiar tej sekcji ma w systemie FreeRTOS plikheap\n4.o, który deklaruje\npamięć przeznaczoną na stertę. Dla systemu Keil RTX5 plikiem takim jestrtx\nlib.o,\nw którym również deklarowana jest pamięć dynamiczna. Pomimo tej samej ilości dekla-\n56\n\nListing 3.4: Wyjście wywołania skryptu analizującego zużycie pamięci dla źródeł Fre-\neRTOS.\nMemory  usage  for  build/croutine.o: {'text': 0,'bss': 0,'data':\n0}\nMemory  usage  for  build/queue.o: {'text': 5848,'bss': 64,'data':\n0}\nMemory  usage  for  build/list.o: {'text': 360,'bss': 0,'data': 0}\nMemory  usage  for  build/tasks.o: {'text': 9216,'bss': 1280,'data\n': 0}\nMemory  usage  for  build/stream_buffer.o: {'text': 3604,'bss': 0,\n'data': 0}\nMemory  usage  for  build/timers.o: {'text': 2882,'bss': 300,'data\n': 0}\nMemory  usage  for  build/event_groups.o: {'text': 1784,'bss': 0,'\ndata': 0}\nMemory  usage  for  build/heap_4.o: {'text': 1238,'bss': 4128,'\ndata': 0}\nMemory  usage  for  build/port.o: {'text': 1156,'bss': 5,'data':\n4}\nMemory  usage  for  build/cmsis_os2.o: {'text': 8422,'bss': 1724,'\ndata': 0}\nSums: {'text': 34510,'bss': 7501,'data': 4}\nTotal: 42015\nrowanej pamięci dynamicznej, dla systemu FreeRTOS została tu zwrócona zauważalnie\nmniejsza wartość.\nZużycie pamięci przez kompletną implementację aplikacji opartą o poszczególne sys-\ntemy operacyjne przedstawiono w tabeli 3.2. Co ciekawe, pomimo lepszego wyniku sys-\ntemu Keil RTX5 w porównaniu dla wyizolowanych modułów systemów operacyjnych, to\nFreeRTOS jest liderem we wszystkich sekcjach dla kompletnej aplikacji. Może to suge-\nrować, że moduły FreeRTOSa są ze sobą mocniej powiązane, przez co proces linkowania\nskutkuje mniejszym obrazem niż jest to w przypadku systemu Keil RTX5.\nOstateczny  wynik  jest  zgodny  z  przewidywaniami,  jakie  można  poczynić  na  pod-\nstawie  sposobu  implementacji  synchronizacji  zadań  w  systemie  FreeRTOS  (wszystkie\npodstawowe prymitywy oparte o kolejkę).\nTabela  3.2:  Porównanie  zużycia  pamięci  przez  Stację  Pogodową  opartą  o  Keil  RTX5\ni FreeRTOS (w bajtach).\ntextdatabsssuma\nKeil RTX5128 1202 24872 224202 592\nFreeRTOS127 2161 92866 648195 792\n57\n\nListing 3.5: Wyjście wywołania skryptu analizującego zużycie pamięci dla źródeł Keil\nRTX5.\nMemory  usage  for  build/irq_armv7m_rtx.o: {'text': 142,'bss': 0,\n'data': 0}\nMemory  usage  for  build/os_systick.o: {'text': 0,'bss': 1,'data\n': 0}\nMemory  usage  for  build/RTX_Config.o: {'text': 0,'bss': 0,'data\n': 0}\nMemory  usage  for  build/rtx_delay.o: {'text': 428,'bss': 0,'data\n': 0}\nMemory  usage  for  build/rtx_evflags.o: {'text': 2740,'bss': 0,'\ndata': 12}\nMemory  usage  for  build/rtx_evr.o: {'text': 0,'bss': 0,'data':\n0}\nMemory  usage  for  build/rtx_kernel.o: {'text': 3346,'bss': 0,'\ndata': 164}\nMemory  usage  for  build/rtx_lib.o: {'text': 0,'bss': 13076,'data\n': 120}\nMemory  usage  for  build/rtx_memory.o: {'text': 58,'bss': 0,'data\n': 0}\nMemory  usage  for  build/rtx_mempool.o: {'text': 3322,'bss': 0,'\ndata': 12}\nMemory  usage  for  build/rtx_msgqueue.o: {'text': 4626,'bss': 0,'\ndata': 12}\nMemory  usage  for  build/rtx_mutex.o: {'text': 2694,'bss': 0,'\ndata': 12}\nMemory  usage  for  build/rtx_semaphore.o: {'text': 2296,'bss': 0,\n'data': 12}\nMemory  usage  for  build/rtx_system.o: {'text': 986,'bss': 0,'\ndata': 0}\nMemory  usage  for  build/rtx_thread.o: {'text': 8860,'bss': 0,'\ndata': 12}\nMemory  usage  for  build/rtx_timer.o: {'text': 2316,'bss': 0,'\ndata': 12}\nSums: {'text': 31814,'bss': 13077,'data': 368}\nTotal: 45259\n58\n\nWnioski\nNa podstawie analizy systemów Keil RTX5 oraz FreeRTOSa przeprowadzonej w procesie\npisania pracy, dokonane zostało kilka obserwacji.\n•FreeRTOS jest znacznie lepiej udokumentowanym projektem. Dodatkowym atu-\ntem systemu jest otaczająca go duża społeczność, która powstała przez 20 lat jego\nistnienia [17]. Fakty te wpływają na łatwość znajdywania odpowiedzi na pytania\ni rozwiązań problemów online.\n•FreeRTOS  jest  bardziej  rozpoznawalny,  a  przez  to  szerzej  wspierany  (np.  przez\nSEGGER Thread Aware Debugging [43]). Można powiedzieć, że względu na swoją\ndługą obecność na rynku i popularność stał się de facto standardem sam w sobie.\n•W subiektywnym odczuciu autora, Keil RTX5 zawiera istotnie czystszą implemen-\ntację. Kod jest bardziej uporządkowany i łatwiejszy do czytania. Nie zobaczymy\ntutaj labiryntu makr i definicji warunkowych, z którymi spotkamy się nader czę-\nsto czytając kod FreeRTOSa. Jest to w pewnym sensie spodziewane – Keil RTX5\njest implementacją referencyjną, a więc powinien, oprócz ścisłego przestrzegania\nwymagań specyfikacji, pełnić rolę edukacyjną.\n•Atutem systemu FreeRTOS jest możliwość łatwej integracji w dowolnym środowi-\nsku programistycznym. Keil RTX5 został zaprojektowany do używania ze zintegro-\nwanym środowiskiem programistycznym KeilμVision, co ogranicza elastyczność\nużytkownika w doborze narzędzi projektowych.\n•W  przypadku  możliwości  oraz  chęci  wykorzystania  środowiska  KeilμVision  dla\nsystemu Keil RTX5, jest ono znacznym ułatwieniem w kontekście konfiguracji i de-\nbugowania projektu. Ścisła integracja narzędzi pozwala na płynny proces rozwoju\naplikacji. FreeRTOS, dzięki swojej popularności jest natomiast dostępny w wielu\nnarzędziach konfiguracyjnych dostarczanych przez sprzedawców mikrokontrolerów\n(m.in. STM – STM32CubeMX [45]). KeilμVision również pozwala na skonfiguro-\nwanie projektu w celu użycia FreeRTOSa.\nWszechstronność  czyni  FreeRTOS  atrakcyjnym  wyborem  dla  hobbystów,  inżynie-\nrów, i developerów, którzy szukają darmowej, łatwo modyfikowalnej platformy do za-\nstosowań w różnorodnych projektach, od prostych aplikacji wbudowanych po zaawan-\nsowane systemy czasu rzeczywistego.\nKeil RTX5 może okazać się lepszy do komercyjnych zastosowań, biorąc pod uwagę\nfunkcje bezpieczeństwa, głębokiej analizy działania (Event Viewer, ułatwione debugo-\nwanie poprzez ścisłą integrację z KeilμVision), i profesjonalne wsparcie.\nBiorąc pod uwagę wszystkie wspomniane czynniki, ostateczna decyzja będzie z pew-\nnością zależeć od wymagań projektowych, budżetu, i preferencji programistów.\n59\n\nPo zapoznaniu się z oboma systemami preferencja autora leży po stronie FreeRTOSa.\nGłównymi czynnikami stojącymi za tą decyzją są ekstensywność dokumentacji, łatwa\nmożliwość doboru dowolnych narzędzi projektowych, oraz nie ustępująca alternatywie\nwydajność.\n60\n\nBibliografia\n[1]    Brian  Amos.Hands-On  RTOS  with  Microcontrollers:  Building  real-time  embed-\nded  systems  using  FreeRTOS,  STM32  MCUs,  and  SEGGER  debug  tools.  Packt\nPublishing, 2020.\n[2]    ARM.ARM  –  strona  spółki.url:https://www.arm.com/.  (ostatni  dostęp:\n20.09.2023r).\n[3]    ARM.ARM  downloads  –  toolchain  support.url:https://developer.arm.com\n/downloads/-/gnu-rm. (ostatni dostęp: 20.09.2023r).\n[4]    ARM.CMSIS-RTOS – SVC Functions.url:https://www.keil.com/pack/doc\n/CMSIS/RTOS/html/svcFunctions.html. (ostatni dostęp: 20.09.2023r).\n[5]    ARM.CMSIS-RTOS2 – strona główna dokumentacji.url:https://www.keil.c\nom/pack/doc/CMSIS/RTOS2/html/index.html. (ostatni dostęp: 20.09.2023r).\n[6]    ARM.Keil  RTX5  –  strona  projektu.url:https://www.arm.com/products\n/development-tools/embedded-and-software/rtx5-rtos.  (ostatni  dostęp:\n20.09.2023r).\n[7]    Bosch.BME680  –  datasheet.url:https://www.bosch-sensortec.com/medi\na/boschsensortec/downloads/datasheets/bst-bme680-ds001.pdf. (ostatni\ndostęp: 20.09.2023r).\n[8]    Bosch.Bosch  BME68X  driver  –  GitHub  repository.url:https://github.com\n/BoschSensortec/BME68x-Sensor-API. (ostatni dostęp: 20.09.2023r).\n[9]    Bosch.BSEC – strona oprogramowania.url:https://www.bosch-sensortec.c\nom/software-tools/software/bsec/. (ostatni dostęp: 20.09.2023r).\n[10]    ARM CMSIS.Definicja CMSIS.url:https://arm-software.github.io/CMSI\nS_5/General/html/index.html. (ostatni dostęp: 20.09.2023r).\n[11]    ARM  CMSIS.Komponenty  CMSIS.url:https : / / arm - software . github .\nio/CMSIS_5/General/html/index.html#CM_Components.  (ostatni  dostęp:\n20.09.2023r).\n[12]    ARM CMSIS.Licencja CMSIS.url:https://arm-software.github.io/CMSI\nS_5/General/html/index.html#License. (ostatni dostęp: 20.09.2023r).\n[13]    Waveshare  Electronics.Waveshare  Electronics  –  integracja  modułu  1.54inch  w\nsystemie opartym o mikrokontroler STM.url:https://www.waveshare.com/wi\nki/1.54inch_e-Paper_Module_Manual#Working_With_STM32. (ostatni dostęp:\n20.09.2023r).\n[14]    Waveshare Electronics.Waveshare  Electronics  –  strona  główna  producenta.url:\nhttps://www.waveshare.com/. (ostatni dostęp: 20.09.2023r).\n61\n\n[15]    Waveshare  Electronics.Waveshare  Electronics  –  wykorzystany  moduł  e-papieru.\nurl:https://www.waveshare.com/1.54inch-e-paper-module.htm. (ostatni\ndostęp: 20.09.2023r).\n[16]    FreeRTOS.FreeRTOS – dostępne stany zadań.url:https://www.freertos.or\ng/RTOS-task-states.html. (ostatni dostęp: 20.09.2023r).\n[17]    FreeRTOS.FreeRTOS  –  historia.url:http://www.openrtos.net/RTOS.html.\n(ostatni dostęp: 20.09.2023r).\n[18]    FreeRTOS.FreeRTOS – lista wspieranych platform.url:https://www.freerto\ns.org/RTOS_ports.html. (ostatni dostęp: 20.09.2023r).\n[19]    FreeRTOS.FreeRTOS  –  Notyfikacje  zadań.url:https://www.freertos.org\n/RTOS-task-notifications.html. (ostatni dostęp: 20.09.2023r).\n[20]    FreeRTOS.FreeRTOS – strona projektu.url:https://www.freertos.org/ind\nex.html. (ostatni dostęp: 20.09.2023r).\n[21]    FreeRTOS.FreeRTOS  –  tracing.url:https://www.freertos.org/FreeRTOS-\nPlus/FreeRTOS_Plus_Trace/RTOS_Trace_Instructions.html. (ostatni dostęp:\n20.09.2023r).\n[22]    FreeRTOS.FreeRTOS – zużycie pamięci (FAQ).url:https://www.freertos.o\nrg/FAQMem.html#ROMUse. (ostatni dostęp: 20.09.2023r).\n[23]    FreeRTOS.Licencja FreeRTOS.url:https://www.freertos.org/a00114.htm\nl. (ostatni dostęp: 20.09.2023r).\n[24]    FreeRTOS.Opis konfiguracji systemu operacyjnego FreeRTOS.url:https://ww\nw.freertos.org/a00110.html. (ostatni dostęp: 20.09.2023r).\n[25]    FreeRTOS.Opis  możliwych  implementacji  stery  w  alokacji  dynamicznej  w  sys-\ntemie  FreeRTOS.url:https://www.freertos.org/a00111.html#heap_1.\n(ostatni dostęp: 20.09.2023r).\n[26]    FreeRTOS.Pliki  źródłowe  FreeRTOS  zawierające  implmentacje  sterty  –  repozy-\ntorium  GitHub,  wersja  FreeRTOS  V10.6.1.url:https://github.com/Free\nRTOS/FreeRTOS-Kernel/tree/V10.6.1/portable/MemMang.  (ostatni  dostęp:\n20.09.2023r).\n[27]    FreeRTOS.Repozytorium zawierające implementację FreeRTOS.url:https://g\nithub.com/FreeRTOS/FreeRTOS. (ostatni dostęp: 20.09.2023r).\n[28]    GNU.GNU  Make  software.url:https://www.gnu.org/software/make/.\n(ostatni dostęp: 20.09.2023r).\n[29]    Keil.CMSIS-RTOS – szablon funkcji SVC (GitHub).url:https://github.com\n/ARM-software/CMSIS_5/blob/develop/CMSIS/RTOS/RTX/SRC/GCC/SVC_Table\n.S. (ostatni dostęp: 20.09.2023r).\n[30]    Keil.CMSIS-RTOS1 – strona główna dokumentacji.url:https://www.keil.co\nm/pack/doc/CMSIS/RTOS/html/index.html. (ostatni dostęp: 20.09.2023r).\n[31]    Keil.CMSIS-RTOS2 – strona główna dokumentacji.url:https://www.keil.co\nm/pack/doc/CMSIS/RTOS2/html/index.html. (ostatni dostęp: 20.09.2023r).\n[32]    Keil.Dokumentacja  Keil  RTX5  –  Theory  of  Operation.url:https://www.ke\nil.com/pack/doc/cmsis/RTOS2/html/theory_of_operation.html. (ostatni\ndostęp: 20.09.2023r).\n62\n\n[33]    Keil.Edycje Keil MDK.url:https://developer.arm.com/Tools%20and%20So\nftware/Keil%20MDK#Editions. (ostatni dostęp: 20.09.2023r).\n[34]    Keil.Implementacja  flag  zdarzeń  w  systemie  Keil  RTX5,  repozytorium  GitHub.\nurl:https://github.com/ARM-software/CMSIS_5/blob/a75f01746df18bb5b\n929dfb8dc6c9407fac3a0f3/CMSIS/RTOS2/RTX/Include/rtx_os.h#L184C8-L18\n4C8. (ostatni dostęp: 20.09.2023r).\n[35]    Keil.Keil  –  lista  zmian  w  API  pomiędzy  CMSIS-RTOS  v1  a  CMSIS-RTOS  v2.\nurl:https://www.keil.com/pack/doc/CMSIS/RTOS2/html/os2MigrationFun\nctions.html. (ostatni dostęp: 20.09.2023r).\n[36]    Keil.Keil RTX5 – dostępne stany zadań.url:https://www.keil.com/pack/do\nc/CMSIS/RTOS/html/group__CMSIS__RTOS__ThreadMgmt.html. (ostatni dostęp:\n20.09.2023r).\n[37]    Keil.Keil  RTX5  –  pula  pamięci.url:https://www.keil.com/pack/doc/C\nMSIS/RTOS2/html/group__CMSIS__RTOS__PoolMgmt.html.  (ostatni  dostęp:\n20.09.2023r).\n[38]    Keil.Keil RTX5 – repozytorium GitHub. Plik zawierający warstwę translacji po-\nmiędzy  API  CMSIS-RTOS  v1  i  CMSIS-RTOS  v2.url:https://github.com\n/ARM-software/CMSIS_5/blob/develop/CMSIS/RTOS2/RTX/Library/cmsis_os\n1.c. (ostatni dostęp: 20.09.2023r).\n[39]    Keil.Keil RTX5 – zużycie pamięci ROM.url:https://www.keil.com/pack/do\nc/CMSIS/RTOS2/html/rtos2_tutorial.html. (ostatni dostęp: 20.09.2023r).\n[40]    Keil.Repozytorium  zawierające  implementację  Keil  RTX5.url:https://gith\nub.com/ARM-software/CMSIS_5/tree/develop/CMSIS/RTOS2/RTX.  (ostatni\ndostęp: 20.09.2023r).\n[41]    Yahia Mazzi, Ahmed Gaga, and Fatima Errahimi. “Benchmarking and Compari-\nson of Two Open-source RTOSs for Embedded Systems Based on ARM Cortex-M4\nMCU”. In:Indian  Journal  of  Science  and  Technology14 (Apr. 2021), pp. 1261–\n1273.doi:10.17485/IJST/v14i16.387.\n[42]    FreeRTOS  OpenRTOS.Strona  internetowa  produktu  OpenRTOS.url:https:\n//www.highintegritysystems.com/openrtos. (ostatni dostęp: 20.09.2023r).\n[43]    SEGGER.Thread Aware Debugging.url:https://www.segger.com/products\n/debug-probes/j-link/tools/j-link-gdb-server/thread-aware-debuggin\ng. (ostatni dostęp: 20.09.2023r).\n[44]    STM.NUCLEO-L476RG – strona produktu.url:https://www.st.com/en/eva\nluation-tools/nucleo-l476rg.html. (ostatni dostęp: 20.09.2023r).\n[45]    STM.STM32CubeMX – strona produktu.url:https://www.st.com/en/develo\npment-tools/stm32cubemx.html. (ostatni dostęp: 20.09.2023r).\n63",
      "metadata": {
        "pages": 63,
        "info": {
          "PDFFormatVersion": "1.5",
          "IsAcroFormPresent": false,
          "IsXFAPresent": false,
          "Title": "Overleaf Example",
          "Author": "",
          "Subject": "",
          "Keywords": "",
          "Creator": "LaTeX with hyperref",
          "Producer": "pdfTeX-1.40.24",
          "CreationDate": "D:20240609074322Z",
          "ModDate": "D:20240609074322Z",
          "Trapped": {
            "name": "False"
          }
        },
        "metadata": null
      }
    }
  },
  {
    "id": "e9b1a840-ec5d-40c6-8d46-54293a2d8f51",
    "title": "Statistics A Very Short Introduction (Very Short Introductions) by David J. Hand (z-lib.org).pdf",
    "content": {
      "type": "text",
      "content": "Statistics: A Very Short Introduction\n\nVERY SHORT INTRODUCTIONSare for anyone wanting a stimulating and\naccessible way in to a new subject. They are written by experts, and have been\npublished in more than 25 languages worldwide.\nThe series began in 1995, and now represents a wide variety of topics in\nhistory, philosophy, religion, science, and the humanities. Over the next\nfew years it will grow to a library of around 200 volumes – a Very Short\nIntroduction to everything from ancient Egypt and Indian philosophy to\nconceptual art and cosmology.\nVery Short Introductions available now:\nAFRICAN HISTORY\nJohn Parker and Richard Rathbone\nAMERICAN POLITICAL PARTIES\nAND ELECTIONSL. Sandy Maisel\nTHE AMERICAN PRESIDENCY\nCharles O. Jones\nANARCHISMColin Ward\nANCIENT EGYPTIan Shaw\nANCIENT PHILOSOPHYJulia Annas\nANCIENT WARFARE\nHarry Sidebottom\nANGLICANISMMark Chapman\nTHE ANGLO-SAXON AGEJohn Blair\nANIMAL RIGHTSDavid DeGrazia\nAntisemitismSteven Beller\nARCHAEOLOGYPaul Bahn\nARCHITECTUREAndrew Ballantyne\nARISTOTLEJonathan Barnes\nART HISTORYDana Arnold\nART THEORYCynthia Freeland\nTHE HISTORY OF ASTRONOMY\nMichael Hoskin\nATHEISMJulian Baggini\nAUGUSTINEHenry Chadwick\nAUTISMUta Frith\nBARTHESJonathan Culler\nBESTSELLERSJohn Sutherland\nTHE BIBLEJohn Riches\nTHE BRAINMichael O’Shea\nBRITISH POLITICSAnthony Wright\nBUDDHAMichael Carrithers\nBUDDHISMDamien Keown\nBUDDHIST ETHICSDamien Keown\nCAPITALISMJames Fulcher\nCATHOLICISMGerald O’Collins\nTHE CELTSBarry Cunliffe\nCHAOSLeonard Smith\nCHOICE THEORYMichael Allingham\nCHRISTIAN ARTBeth Williamson\nCHRISTIANITYLinda Woodhead\nCITIZENSHIPRichard Bellamy\nCLASSICSMary Beard and\nJohn Henderson\nCLASSICAL MYTHOLOGY\nHelen Morales\nCLAUSEWITZMichael Howard\nTHE COLD WARRobert McMahon\nCONSCIOUSNESSSusan Blackmore\nCONTEMPORARY ART\nJulian Stallabrass\nCONTINENTAL PHILOSOPHY\nSimon Critchley\nCOSMOLOGYPeter Coles\nTHE CRUSADESChristopher Tyerman\nCRYPTOGRAPHY\nFred Piper and Sean Murphy\nDADA AND SURREALISM\nDavid Hopkins\nDARWINJonathan Howard\nTHE DEAD SEA SCROLLS\nTimothy Lim\nDEMOCRACY\nBernard Crick\nD\nESCARTESTom Sorell\nDESIGNJohn Heskett\nDINOSAURSDavid Norman\nDOCUMENTARY FILM\nPatricia Aufderheide\nDREAMINGJ. Allan Hobson\nDRUGSLeslie Iversen\nTHE EARTHMartin Redfern\nECONOMICSPartha Dasgupta\nEGYPTIAN MYTHGeraldine Pinch\nEIGHTEENTH-CENTURY BRITAIN\nPaul Langford\n\nTHE ELEMENTSPhilip Ball\nEMOTIONDylan Evans\nEMPIREStephen Howe\nENGELSTerrell Carver\nETHICSSimon Blackburn\nTHE EUROPEAN UNIONJohn Pinder\nand Simon Usherwood\nEVOLUTION\nBrian and Deborah Charlesworth\nEXISTENTIALISMThomas Flynn\nFASCISMKevin Passmore\nFEMINISMMargaret Walters\nTHE FIRST WORLD WAR\nMichael Howard\nFOSSILSKeith Thomson\nFOUCAULTGary Gutting\nFREE WILLThomas Pink\nTHE FRENCH REVOLUTION\nWilliam Doyle\nFREUDAnthony Storr\nFUNDAMENTALISMMalise Ruthven\nGALAXIESJohn Gribbin\nGALILEOStillman Drake\nGame TheoryKen Binmore\nGANDHIBhikhu Parekh\nGEOGRAPHYJohn A. Matthews and\nDavid T. Herbert\nGEOPOLITICSKlaus Dodds\nGERMAN LITERATURE\nNicholas Boyle\nGLOBAL CATASTROPHESBill McGuire\nGLOBALIZATIONManfred Steger\nGLOBAL WARMINGMark Maslin\nTHE GREAT DEPRESSION AND\nTHE NEW DEALEric Rauchway\nHABERMASJames Gordon Finlayson\nHEGELPeter Singer\nHEIDEGGERMichael Inwood\nHIEROGLYPHSPenelope Wilson\nHINDUISMKim Knott\nHISTORYJohn H. Arnold\nHISTORY of LifeMichael Benton\nTHE HISTORY OF MEDICINE\nWilliam Bynum\nHIV/AIDSAlan Whiteside\nHOBBESRichard Tuck\nHUMAN EVOLUTIONBernard Wood\nHUMAN RIGHTSAndrew Clapham\nHUMEA. J. Ayer\nIDEOLOGYMichael Freeden\nINDIAN PHILOSOPHYSue Hamilton\nINTELLIGENCEIan J. Deary\nINTERNATIONAL MIGRATION\nKhalid Koser\nINTERNATIONAL RELATIONS\nPaul Wilkinson\nISLAMMalise Ruthven\nJOURNALISMIan Hargreaves\nJUDAISMNorman Solomon\nJUNGAn\nthony Stevens\nKABBALAHJoseph Dan\nKAFKARitchie Robertson\nKANTRoger Scruton\nKIERKEGAARDPatrick Gardiner\nTHE KORANMichael Cook\nLAWRaymond Wacks\nLINGUISTICSPeter Matthews\nLITERARY THEORYJonathan Culler\nLOCKEJohn Dunn\nLOGICGraham Priest\nMACHIAVELLIQuentin Skinner\nTHE MARQUIS DE SADEJohn Phillips\nMARXPeter Singer\nMATHEMATICSTimothy Gowers\nTHE MEANING OF LIFE\nTerry Eagleton\nMEDICAL ETHICSTony Hope\nMEDIEVAL BRITAIN\nJohn Gillingham and Ralph A. Griffiths\nMEMORYJonathan Foster\nMODERN ARTDavid Cottington\nMODERN CHINARana Mitter\nMODERN IRELANDSenia Pašeta\nMOLECULESPhilip Ball\nMORMONISM\nRichard Lyman Bushman\nMUSICNicholas Cook\nMYTHRobert A. Segal\nNATIONALISMSteven Grosby\nNELSON MANDELAElleke Boehmer\nTHE NEW TESTAMENT AS\nLITERATUREKyle Keefer\nNEWTONRobert Iliffe\nNIETZSCHEMichael Tanner\nNINETEENTH-CENTURY BRITAIN\nChristopher Harvie and\nH. C. G. Matthew\nNORTHERN IRELAND\nMarc Mulholland\nNUCLEAR WEAPONS\nJoseph M. Siracusa\nTHE OLD TESTAMENT\nMichael D. Coogan\nPARTICLE PHYSICSFrank Close\n\nPAULE. P. Sanders\nPHILOSOPHYEdward Craig\nPHILOSOPHY OF LAW\nRaymond Wacks\nPHILOSOPHY OF SCIENCE\nSamir Okasha\nPHOTOGRAPHYSteve Edwards\nPLATOJulia Annas\nPOLITICAL PHILOSOPHY\nDavid Miller\nPOLITICSKenneth Minogue\nPOSTCOLONIALISMRobert Young\nPOSTMODERNISMChristopher Butler\nPOSTSTRUCTURALISM\nCatherine Belsey\nPREHISTORYChris Gosden\nPRESOCRATIC PHILOSOPHY\nCatherine Osborne\nPSYCHIATRYTom Burns\nPSYCHOLOGY\nGillian Butler and Freda McManus\nTHE QUAKERSPink Dandelion\nQUANTUM THEORY\nJohn Polkinghorne\nRACISMAli Rattansi\nRELATIVITYRussell Stannard\nRELIGION IN AMERICATimothy Beal\nTHE RENAISSANCEJerry Brotton\nRENAISSANCE ART\nGeraldine A. Johnson\nROMAN BRITAINPeter Salway\nTHE ROMAN EMPIRE\nChristopher Kelly\nROUSSEAURobert Wokler\nRUSSELLA. C. Grayling\nRUSSIAN LITERATURECatriona Kelly\nTHE RUSSIAN REVOLUTION\nS. A. Smith\nSCHIZOPHRENIA\nChris Frith and Eve Johnstone\nSCHOPENHAUER\nChristopher Janaway\nSCIENCE AND RELIGION\nThomas Dixon\nSCOTLANDRab Houston\nSEXUALITYVéronique Mottier\nSHAKESPEAREGermaine Greer\nSIKHISMEleanor Nesbitt\nSOCIAL AND CULTURAL\nANTHROPOLOGY\nJohn Monaghan and Peter Just\nSOCIALISMMichael Newman\nSOCIOLOGYSteve Bruce\nSOCRATESC. C. W. Taylor\nTHE SPANISH CIVIL WAR\nHelen Graham\nSPINOZARoger Scruton\nSTATISTICSDavid J. Hand\nSTUART BRITAINJohn Morrill\nTERRORISMCharles Townshend\nTHEOLOGYDavid F. Ford\nTHE HISTORY OF TIME\nLeofranc Holford-Strevens\nTRAGEDYAdrian Poole\nTHE TUDORSJohn Guy\nTWENTIETH-CENTURY BRITAIN\nKenneth O. Morgan\nTHE UNITED NATIONS\nJussi M. Hanhimäki\nTHE VIETNAM WAR\nM\nark Atwood Lawrence\nTHE VIKINGSJulian Richards\nWITTGENSTEINA. C. Grayling\nWORLD MUSICPhilip Bohlman\nTHE WORLD TRADE\nORGANIZATIONAmrita Narlikar\nAvailable Soon:\nAPOCRYPHAL GOSPELSPaul Foster\nBEAUTYRoger Scruton\nExpressionismKaterina Reed-Tsocha\nFREE SPEECHNigel Warburton\nMODERN JAPAN\nChristopher Goto-Jones\nNOTHINGFrank Close\nPHILOSOPHY OF RELIGION\nJack Copeland and Diane Proudfoot\nSUPERCONDUCTIVITY\nStephen Blundell\nFor more information visit our websites\nwww.oup.com/uk/vsi\nwww.oup.com/us\n\nDavid J. Hand\nStatistics\nA  Very  Short  Introduction\n1\n\n1\nGreat Clarendon Street, OxfordOX26DP\nOxford University Press is a department of the University of Oxford.\nIt furthers the University’s objective of excellence in research, scholarship,\nand education by publishing worldwide in\nOxford New York\nAuckland Cape Town Dar es Salaam Hong Kong Karachi\nKuala Lumpur Madrid Melbourne Mexico City Nairobi\nNew Delhi Shanghai Taipei Toronto\nWith offices in\nArgentina Austria Brazil Chile Czech Republic France Greece\nGuatemala Hungary Italy Japan Poland Portugal Singapore\nSouth Korea Switzerland Thailand Turkey Ukraine Vietnam\nOxford is a registered trade mark of Oxford University Press\nin the UK and in certain other countries\nPublishedintheUnitedStates\nby Oxford University Press Inc., New York\nc\n©David J. Hand 2008\nThe moral rights of the author have been asserted\nDatabase right Oxford University Press (maker)\nFirst Published 2008\nAll rights reserved. No part of this publication may be reproduced,\nstored in a retrieval system, or transmitted, in any form or by any means,\nwithout the prior permission in writing of Oxford University Press,\nor as expressly permitted by law, or under terms agreed with the appropriate\nreprographics rights organization. Enquiries concerning reproduction\noutside the scope of the above should be sent to the Rights Department,\nOxford University Press, at the address above\nYou must not circulate this book in any other binding or cover\nand you must impose the same condition on any acquirer\nBritish Library Cataloguing in Publication Data\nData available\nLibrary of Congress Cataloging in Publication Data\nData available\nISBN 978–0–19–923356–4\n13579108642\nTypeset by SPI Publisher Services, Pondicherry, India\nPrinted in Great Britain by\nAshford Colour Press Ltd, Gosport, Hampshire\n\nContents\nPrefaceix\nList of illustrationsxi\n1\nSurrounded by statistics1\n2\nSimple descriptions21\n3\nCollecting good data36\n4\nProbability55\n5\nEstimation and inference75\n6\nStatistical models and methods92\n7\nStatistical computing110\nFurther reading115\nEndnote117\nIndex119\n\nThis page intentionally left blank \n\nPreface\nStatistical ideas and methods underlie just about every aspect of\nmodern life. Sometimes the role of statistics is obvious, but often\nthe statistical ideas and tools are hidden in the background. In\neither case, because of the ubiquity of statistical ideas, it is clearly\nextremely useful to have some understanding of them. The aim of\nthis book is to provide such understanding.\nStatistics suffers from an unfortunate but fundamental\nmisconception which misleads people about its essential nature.\nThis mistaken belief is that it requires extensive tedious arithmetic\nmanipulation, and that, as a consequence, it is a dry and dusty\ndiscipline, devoid of imagination, creativity, or excitement. But\nthis is a completely false image of the modern discipline of\nstatistics. It is an image based on a perception dating from more\nthan half a century ago. In particular, it entirely ignores the fact\nthat the computer has transformed the discipline, changing it\nfrom one hinging around arithmetic to one based on the use of\nadvanced software tools to probe data in a search for\nunderstanding and enlightenment. That is what the modern\ndiscipline is all about: the use of tools to aid perception and\nprovide ways to shed light, routes to understanding, instruments\nfor monitoring and guiding, and systemstoassistdecision-making.\nAll of these, and more, are aspects of the modern discipline.\n\nThe aim of this book is to give the reader some understanding of\nthis modern discipline. Now, clearly, in a book as short as this one,\nI cannot go into detail. Instead of detail, I have taken a high-level\nview, a bird’s eye view, of the entire discipline, trying to convey the\nnature of statistical philosophy, ideas, tools, and methods. I hope\nthe book will give the reader some understanding of how the\nmodern discipline works, how important it is, and, indeed, why it\nis so important.\nThe first chapter presents some basic definitions, along with\nillustrations to convey some of the power, importance, and,\nindeed, excitement of statistics. The second chapter introduces\nsome of the most elementary of statistical ideas, ideas which the\nreader may well have already encountered, concerned with basic\nsummaries of data. Chapter 3 cautions us that the validity of any\nconclusions we draw depends critically on the quality of the raw\ndata, and also describes strategies for efficient collection of data.\nIf data provide one of the legs on which statistics stands, the other\nis probability, and Chapter 4 introduces basic concepts of\nprobability. Proceeding from the two legs of data and probability,\nin Chapter 5 statistics starts to walk, with a description of how one\ndraws conclusions and makes inferences from data. Chapter 6\npresents a lightning overview of some important statistical\nmethods, showing how they form part of an interconnected\nnetwork of ideas and methods for extracting understanding from\ndata. Finally, Chapter 7 looks at just some of the ways the\ncomputer has impacted the discipline.\nI would like to thank Emily Kenway, Shelley Channon, Martin\nCrowder, and an anonymous reader for commenting on drafts of\nthis book. Their comments have materially improved it, and\nhelped to iron out obscurities in the explanations. Of course, any\nsuch which remain are entirely my own fault.\nDavid J. Hand\nImperial College, London\n\nList of illustrations\n1.  Distribution of American\nbaseball players’ salaries\n31\nc\n©David Hand\n2.  A cumulative probability\ndistribution\n66\nc\n©David Hand\n3.  A probability density\nfunction\n67\nc\n©David Hand\n4.  The normal distribution70\nc\n©David Hand\n5.  Fitting a line to data100\nc\n©David Hand\n6.  A ‘scatterplot matrix’ of two\ntypes of athletic events\n107\nc\n©David Hand\n7.  A time series plot of ATM\nwithdrawals\n108\nc\n©David Hand\n8.  Distribution of the light\nscatter values from\nphytoplankton cells of\ndifferent species\n108\nc\n©David Hand\n\nThis page intentionally left blank \n\nChapter 1\nSurrounded by statistics\nTo those who say ‘there are lies, damned lies, and statistics’, I\noften quote Frederick Mosteller, who said that ‘it is easy to lie with\nstatistics, but easier to lie without them’.\nModern statistics\nI want to begin with an assertion that many readers might find\nsurprising:statistics is the most exciting of disciplines.Myaimin\nthis book is to show you that this assertion is true and to show you\nwhy it is true. I hope to dispel some of the old misconceptions of\nthe nature of statistics, and to show what the modern discipline\nlooks like, as well as to illustrate some of its awesome power, as\nwell as its ubiquity.\nIn particular, in this introductory chapter I want to convey two\nthings. The first is a flavour of the revolution that has taken place\nin the past few decades. I want to explain how statistics has been\ntransformed from a dry Victorian discipline concerned with the\nmanual manipulation of columns of numbers, to a highly\nsophisticated modern technology involving the use of the most\nadvanced of software tools. I want to illustrate how today’s\nstatisticians use these tools to probe data in the search for\nstructures and patterns, and how they use this technology to peel\nback the layers of mystification and obscurity, revealing the truths\n1\n\nStatistics\nbeneath. Modern statistics, like telescopes, microscopes, X-rays,\nradar, and medical scans, enables us to see things invisible to the\nnaked eye. Modern statistics enables us to see through the mists\nand confusion of the world about us, to grasp the underlying\nreality.\nSo that is the first thing I want to convey in this chapter: the sheer\npower and excitement of the modern discipline, where it has come\nfrom, and what it can do. The second thing I hope to convey is the\nubiquity of statistics. No aspect of modern life is untouched by\nit. Modern medicine is built on statistics: for example, the\nrandomized controlled trial has been described as ‘one of the\nsimplest, most powerful, and revolutionary tools of research’.\nUnderstanding the processes by which plagues spread prevent\nthem from decimating humanity. Effective government hinges on\ncareful statistical analysis of data describing the economy and\nsociety: perhaps that is an argument for insisting that all those in\ngovernment should take mandatory statistics courses. Farmers,\nfood technologists, and supermarkets all implicitly use statistics to\ndecide what to grow, how to process it, and how to package and\ndistribute it. Hydrologists decide how high to build flood defences\nby analysing meteorological statistics. Engineers building\ncomputer systems use the statistics of reliability to ensure that\nthey do not crash too often. Air traffic control systems are built on\ncomplex statistical models, working in real time. Although you\nmay not recognize it, statistical ideas and tools are hidden in just\nabout every aspect of modern life.\nSome definitions\nOne good working definition of statistics might be that it isthe\ntechnology of extracting meaning from data.However,no\ndefinition is perfect. In particular, this definition makes no\nreference to chance and probability, which are the mainstays of\nmany applications of statistics. So another working definition\nmight be that it is thetechnology of handling uncertainty.Yet\n2\n\nSurrounded by statistics\nother definitions, or more precise definitions, might put more\nemphasis on the roles that statistics plays. Thus we might say that\nstatistics is the key discipline forpredicting the futureor for\nmaking inferences about the unknown,orforproducing\nconvenient summaries of data. Taken together these definitions\nbroadly cover the essence of the discipline, though different\napplications will provide very different manifestations. For\nexample, decision-making, forecasting, real-time monitoring,\nfraud detection, census enumeration, and analysis of gene\nsequences are all applications of statistics, and yet may require\nvery different methods and tools. One thing to note about these\ndefinitions is that I have deliberately chosen the word ‘technology’\nrather than science. A technology is the application of science and\nits discoveries, and that is what statistics is: the application of our\nunderstanding of how to extract information from data, and our\nunderstanding of uncertainty. Nevertheless, statistics is sometimes\nreferred to as a science. Indeed, one of the most stimulating\nstatistical journals is called just that:Statistical Science.\nSo far in this book, and in particular in the preceding paragraph,\nI have referred to thediscipline of statistics, but the word\n‘statistics’ also has another meaning: it is the plural of ‘statistic’. A\nstatistic is a numerical fact or summary. For example, a summary\nof the data describing some population: perhaps its size, the birth\nrate, or the crime rate. So in one sense this book is about\nindividual numerical facts. But in a very real sense it is about\nmuch more than that. It is about how to collect, manipulate,\nanalyse, and deduce things from those numerical facts. It is about\nthe technology itself. This means that a reader hoping to find\ntables of numbers in this book (e.g. ‘sports statistics’) will be\ndisappointed. But a reader hoping to gain understanding of how\nbusinesses make decisions, of how astronomers discover new types\nof stars, of how medical researchers identify the genes associated\nwith a particular disease, of how banks decide whether or not to\ngive someone a credit card, of how insurance companies decide on\nthe cost of a premium, of how to construct spam filters which\n3\n\nStatistics\nprevent obscene advertisements reaching your email inbox, and so\non and on, will be rewarded.\nAll of this explains why ‘statistics’ can be both singular and plural:\nthere is one discipline which is statistics, but there are many\nnumbers which are statistics.\nSo much for the word ‘statistics’. My first working definition also\nused the word ‘data’. The word ‘data’ is the plural of the Latin word\n‘datum’, meaning ‘something given’, fromdare, meaning ‘to give’.\nAs such, one might imagine that it should be treated as a plural\nword:‘thedataarepoor’and‘thesedatashowthat...’,ratherthan\n‘the data is poor’ and ‘this data shows that’. However, the English\nlanguage changes over time. Increasingly, nowadays ‘data’ is\ntreated as describing a continuum, as in ‘the water is wet’ rather\nthan ‘the water are wet’. My own inclination is to adopt whatever\nsounds more euphonious in any particular context. Usually, to my\nears, this means sticking to the plural usage, but occasionally I\nmay lapse.\nData are typically numbers: the results of measurements, counts,\nor other processes. We can think of such data as providing a\nsimplified representation of whatever we are studying. If we are\nconcerned with school children, and in particular their academic\nability and suitability for different kinds of careers, we might\nchoose to study the numbers giving their results in various tests\nand examinations. These numbers would provide an indication of\ntheir abilities and inclinations. Admittedly, the representation\nwould not be perfect. A low score might simply indicate that\nsomeone was feeling ill during the examination. A missing value\ndoes not tell us much about their ability, but merely that they did\nnot sit the examination. I will say more aboutdata qualitylater.\nIt matters because of the general principle (which applies\nthroughout life, not merely in statistics) that if we have poor\nmaterial to work with then the results will be poor. Statisticians\n4\n\nSurrounded by statistics\ncan perform amazing feats in extracting understanding from\nnumbers, but they cannot perform miracles.\nOf course, many situations do not appear to produce numerical\ndata directly. Much raw data appears to be in the form of pictures,\nwords, or even things such as electronic or acoustic signals. Thus,\nsatellite images of crops or rain forest coverage, verbal\ndescriptions of side effects suffered when taking medication, and\nsounds uttered when speaking, do not appear to be numbers.\nHowever, close examination shows that, when these things are\nmeasured and recorded, they are translated into numerical\nrepresentations or into representations which can themselves be\nfurther translated into numbers. Satellite pictures and other\nphotographs, for example, are represented as millions of tiny\nelements, called pixels, each of which is described in terms of the\n(numerical) intensities of the different colours making it up. Text\ncan be processed into word counts or measures of similarity\nbetween words and phrases; this is the sort of representation used\nby web search engines, such as Google. Spoken words are\nrepresented by the numerical intensities of the waveforms making\nup the individual parts of speech. In general, although not all data\nare numerical, most data are translated into numerical form at\nsome stage. And most of statistics deals with numerical data.\nLies, damned lies, and setting the record straight\nThe remark that there are ‘lies, damned lies, and statistics’, which\nwas quoted at the start of this chapter, has been variously\nattributed to Mark Twain and Benjamin Disraeli, among others.\nSeveral people have made similar remarks. Thus ‘like dreams,\nstatistics are a form of wish fulfilment’ (Jean Baudrillard, inCool\nMemories,Chapter4);‘...theworshipofstatisticshashadthe\nparticularly unfortunate result of making the job of the plain,\noutright liar that much easier’ (Tom Burnan, inThe Dictionary of\nMisinformation, p. 246); ‘statistics is “hocuspocus” with numbers’\n5\n\nStatistics\n(Audrey Habera and Richard Runyon, inGeneral Statistics,p.3);\n‘legal proceedings are like statistics. If you manipulate them, you\ncan prove anything’ (Arthur Hailey, inAirport,p.385).Andsoon.\nClearly there is much suspicion of statistics. We might also wonder\nif there is an element of fear of the discipline. It is certainly true\nthat the statistician often plays the role of someone who must\nexercise caution, possibly even being the bearer of bad news.\nStatisticians working in research environments, for example in\nmedical schools or social contexts, may well have to explain that\nthe data are inadequate to answer a particular question, or simply\nthat the answer is not what the researcher wanted to hear. That\nmay be unfortunate from the researcher’s perspective, but it is a\nlittle unfair then to blame the statistical messenger.\nIn many cases, suspicion is generated by those who selectively\nchoose statistics. If there is more than one way to summarize a set\nof data, all looking at slightly different aspects, then different\npeople can choose to emphasize different summaries. A particular\nexample is in crime statistics. In Britain, perhaps the most\nimportant source of crime statistics is theBritish Crime Survey.\nThis estimates the level of crime by directly asking a sample of\npeople of which crimes they have been victims over the past year.\nIn contrast, theRecorded Crime Statisticsseries includes all\noffences notifiable to the Home Office which have been recorded\nby the police. By definition, this excludes certain minor offences.\nMore importantly, of course, it excludes crimes which are not\nreported to the police in the first place. With such differences, it is\nno wonder that the figures can differ between the two sets of\nstatistics, even to the extent that certain categories of crime may\nappear to be decreasing over time according to one set of figures\nbut increasing according to the other.\nThe crime statistics figures also illustrate another potential cause\nof suspicion of statistics. When a particular measure is used as an\nindicator of the performance of a system, people may choose to\n6\n\nSurrounded by statistics\ntarget that measure, improving its value but at the cost of other\naspects of the system. The chosen measure then improves\ndisproportionately, and becomes useless as a measure of\nperformance of the system. For example, the police could reduce\nthe rate of shoplifting by focusing all their resources on it, at the\ncost of allowing other kinds of crime to rise. As a result, the rate of\nshoplifting becomes useless as an indicator of crime rate. This\nphenomenon has been termed ‘Goodhart’s law’, named after\nCharles Goodhart, a former Chief Adviser to the Bank of England.\nThe point to all this is that the problem lies not with the statistics\nper se, but with the use made of those statistics, and the\nmisunderstanding of how the statistics are produced and what\nthey really mean. Perhaps it is perfectly natural to be suspicious of\nthings we do not understand. The solution is to dispel that lack of\nunderstanding.\nYet another cause of suspicion arises in a fundamental way as a\nconsequence of the very nature of scientific advance. Thus, one\nday we might read in the newspaper of a scientific study appearing\nto show that a particular kind of food is bad for us, and the next\nday that it is good. Naturally enough this generates confusion, the\nfeeling that the scientists do not know the answer, and perhaps\nthat they are not to be trusted. Inevitably, such scientific\ninvestigations make heavy use of statistical analyses, so some of\nthis suspicion transfers to statistics. But it is the very essence of\nscientific advance that new discoveries are made that change our\nunderstanding. Where we once might have thought simply that\ndietaryfatwasbadforus,furtherstudiesmayhaveledusto\nrecognize that there are different kinds of fats, some beneficial and\nsome detrimental. The picture is more complicated than we first\nthought, so it is hardly surprising that the initial studies led to\nconflicting and apparently contradictory conclusions.\nA fourth cause of suspicion arises from elementary\nmisunderstandings of basic statistics. As an exercise, the reader\n7\n\nStatistics\nmight try to decide what is suspicious about each of the following\nstatements (the answers are in the endnote at the back of the\nbook).\n1)  We read in a report that earlier diagnosis of a medical condition\nleads to longer survival times, so that screening programmes are\nbeneficial.\n2)  We are told that a stated price has already been reduced by a 25%\ndiscount for eligible customers, but we are not eligible so we have\nto pay 25% more than the stated price.\n3)  We hear of a prediction that life expectancy will reach 150 years in\nthe next century, based on simple extrapolation from increases\nover the past 100 years.\n4)  We are told that ‘every year since 1950, the number of American\nchildren gunned down has doubled’.\nSometimes the misunderstandings are not so elementary, or, at\nleast, they arise from relatively deep statistical concepts. It would\nbe surprising if, after more than a century of development, there\nwere not some deep counter-intuitive ideas in statistics. One such\nis known as theProsecutor’s Fallacy. It describes confusion\nbetween the probability that something will be true (e.g. the\ndefendant is guilty) if you have some evidence (e.g. the defendant’s\ngloves at the scene of the crime), with the probability of finding\nthat evidence if you assume that the defendant is guilty. This is a\ncommon confusion, not merely in the courts, and we will examine\nit more closely later.\nIf there is suspicion and mistrust of statistics, it is clear that the\nblame lies not with the statistics or how they were calculated, but\nrather with the use made of those statistics. It is unfair to blame\nthe discipline, or the statistician who extracts the meaning from\nthe data. Rather, the blame lies with those who do not understand\nwhat the numbers are saying, or who wilfully misuse the results.\n8\n\nSurrounded by statistics\nWe do not blame a gun for murdering someone: rather it is the\nperson firing the gun who is blamed.\nData\nWehaveseenthatdataaretherawmaterialonwhichthe\ndiscipline of statistics is built, as well as the raw material from\nwhich individual statistics themselves are calculated, and that\nthese data are typically numbers. In fact, however, data are more\nthan merely numbers. To be useful, that is to enable us to carry\nout some meaningful statistical analysis, the numbers must be\nassociated with some meaning. For example, we need to know\nwhat the measurements are measurementsof,andjustwhathas\nbeen counted when we are presented with a count. To produce\nvalid and accurate results when we carry out our statistical\nanalysis, we also need to know something about how the values\nhave been obtained. Did everyone we asked give answers to a\nquestionnaire, or did only some people answer? If only some\nanswered, are they properly representative of the population of\npeople we wish to make a statement about, or is the sample\ndistorted in some way? Does, for example, our sample\ndisproportionately exclude young people? Likewise, we need to\nknow if patients dropped out of a clinical trial. And whether the\ndata are up to date. We need to know if a measuring instrument is\nreliable, or if it has a maximum value which is recorded when the\ntrue value is excessively high. Can we assume that a pulse rate\nrecorded by a nurse is accurate, or is it only a rough value? There\nis an infinite number of such questions which could be asked, and\nwe need to be alert for any which could influence the conclusions\nwe draw. Or else suspicions of the kind described above might be\nentirely legitimate.\nOne way of looking at data is to regard it asevidence.Without\ndata, our ideas and theories about the world around us are mere\nspeculations. Data provide a grounding, linking our ideas and\ntheories to reality, and allowing us to validate and test our\n9\n\nStatistics\nunderstanding. Statistical methods are then used to compare the\ndata with our ideas and theories, to see how good a match there is.\nA poor match leads us to think again, to re-evaluate our ideas and\nreformulate them so that they better match what we actually\nobserve to be the case. But perhaps I should insert a cautionary\nnote here. This is that a poor match could also be a consequence\nof poor data quality. We must be alert for this possibility: our\ntheories may be sound but our measuring instruments may be\nlacking in some way. In general, however, a good match between\nthe observed data and what our theories say the data should be\nlike reassures us that we are on the right track. It reassures us that\nour ideas really do reflect the truth of what is going on.\nImplicit in this is that, to be meaningful, our ideas and theories\nmust yield predictions, which we can compare with our data. If\nthey do not tell us what we should expect to observe, or if the\npredictions are so general that any data will conform with our\ntheories, then the theories are not much use: anything would do.\nPsychoanalysis and astrology have been criticized on such\ngrounds.\nData also allow us to steer our way through a complex world – to\nmake decisions about the best actions to take. We take our\nmeasurements, count our totals, and we use statistical methods to\nextract information from these data to describe how the world is\nbehaving and what we should do to make it behave how we want.\nThese principles are illustrated by aircraft autopilots, automobile\nSatNav systems, economic indicators such as inflation rate and\nGDP, monitoring patients in intensive care units, and evaluations\nof complex social policies.\nGiven the fundamental role of data as tying observations about the\nworld around us to our ideas and understanding of that world, it is\nnot stretching things too far to describe data, and the technology\nof extracting meaning from it, as the cornerstone of modern\ncivilization. That is why I used the subtitle ‘how data rule our\n10\n\nSurrounded by statistics\nworld’, for my bookInformation Generation(see Further\nreading).\nGreater statistics\nAlthough the roots can be traced as far back as we like, the\ndiscipline of statistics itself is really only a couple of centuries old.\nThe Royal Statistical Society was established in 1834, and the\nAmerican Statistical Association in 1839, whilst the world’s first\nuniversity statistics department was set up in 1911, at University\nCollege, London. Early statistics had several strands, which\neventually combined to become the modern discipline. One of\nthese strands was the understanding of probability, dating from\nthe mid-17th century, which emerged in part from questions\nconcerning gambling. Another was the appreciation that\nmeasurements are rarely error free, so that some analysis was\nneeded to extract sensible meaning from them. In the early years,\nthis was especially important in astronomy. Yet another strand\nwas the gradual use of statistical data to enable governments to\nrun their country. In fact, it is this usage which led to the word\n‘statistics’: data about ‘the State’. Every advanced country now has\nits own national statistical office.\nAs it developed, so the discipline of statistics went through several\nphases. The first, leading up to around the end of the 19th century,\nwas characterized by discursive explorations of data. Then the\nfirst half of the 20th century saw the discipline becoming\nmathematicized, to the extent that many saw it as a branch of\nmathematics (it deals with numbers, doesn’t it?). Indeed,\nuniversity statisticians are still often based within mathematics\ndepartments. The second half of the 20th century saw the advent\nof the computer, and it was this change which elevated statistics\nfrom drudgery to excitement. The computer removed the need for\npractitioners to have special arithmetic skills – they no longer\nneeded to spend endless hours on numerical manipulation. It is\nanalogous to the change from having to walk everywhere to being\n11\n\nStatistics\nable to drive: journeys which would have previously taken days\nnow take a matter of minutes; journeys which would have been\ntoo lengthy to contemplate now become feasible.\nThe second half of the 20th century also saw the appearance of\nother schools of data analysis, with origins not in classical\nstatistics but in other areas, especially computer science. These\ninclude machine learning, pattern recognition, and data mining.\nAs these other disciplines developed, so there were sometimes\ntensions between the different schools and statistics. The truth is,\nhowever, that the varying perspectives provided by these different\nschools all have something to contribute to the analysis of data, to\nthe extent that nowadays modern statisticians pick freely from the\ntools provided by all these areas. I will describe some of these tools\nlater on. With this in mind, in this book I take a broad definition\nof statistics, following the definition of ‘greater statistics’ given by\nthe eminent statistician John Chambers, who said: ‘Greater\nstatistics can be defined simply, if loosely, as everything related to\nlearning from data, from the first planning or collection to the last\npresentation or report.’ Trying to define boundaries between the\ndifferent data-analytic disciplines is both pointless and futile.\nSo, modern statistics is not about calculation, it is about\ninvestigation. Some have even described statistics as thescientific\nmethod in action. Although, as I noted above, one still often finds\nmany statisticians based in mathematics departments in\nuniversities, one also finds them in medical schools, social science\ndepartments, including economics, and many other departments,\nranging from engineering to psychology. And outside universities\nlarge numbers work in government and in industry, in the\npharmaceutical sector, marketing, telecoms, banking, and a host\nof other areas. All managers rely on statistical skills to help them\ninterpret the data describing their department, corporation,\nproduction, personnel, etc. These people are not manipulating\nmathematical symbols and formulae, but are using statistical tools\nand methods to gain insight and understanding from evidence,\n12\n\nSurrounded by statistics\nfrom data. In doing so, they need to consider a wide variety of\nintrinsically non-mathematical issues such as data quality, how\nthe data were or should be collected, defining the problem,\nidentifying the broader objective of the analysis (understanding,\nprediction, decision, etc.), determining how much uncertainty is\nassociated with the conclusion, and a host of other issues.\nAs I hope is clear from the above, statistics is ubiquitous, in that it\nis applied in all walks of life. This has had a reciprocal impact on\nthe development of statistics itself. As statistical methods were\napplied in new areas, so the particular problems, requirements,\nand characteristics of those areas led to the development of new\nstatistical methods and tools. And then, once they had been\ndeveloped, these new methods and tools spread out, finding\napplications in other areas.\nSome examples\nExample 1: Spam filtering\n‘Spam’ is the term used to describe unsolicited bulk email\nmessages automatically sent out to many recipients, typically\nmany millions of recipients. These messages will be advertising\nmessages, often offensive, and they may be fronts for confidence\ntricksters. They include things such as debt consolidation offers,\nget-rich-quick schemes, prescription drugs, stock market tips, and\ndubious sexual aids. The principle underlying them is that if you\nemail enough people, some are likely to be interested in – or taken\nin by – your offer. Unless the messages are from organizations\nspecifically asked for information, most of them will be of no\ninterest, and nobody will want to waste time reading and deleting\nthem. Which brings us to spam filters. These are computer\nprograms that automatically scan incoming email messages and\ndecide which are likely to be spam. The filters can be set up so that\nthe program deletes the spam messages automatically, sends them\nto a holding folder for later examination, or takes some other\nappropriate action. There are various estimates of the amount of\n13\n\nStatistics\nspam sent out, but at the time of writing, one estimate is that over\n90 billion spam messages are sent each day – and since this\nnumber has been rising dramatically month on month, it is likely\nto be substantially greater by the time you read this.\nThere are various techniques for preventing spam. Very simple\napproaches just check for the occurrence of keywords in the\nmessage. For example, if a message includes the word ‘viagra’ it\nmight be blocked. However, one of the characteristics of spam\ndetection is that it is something of an arms race. Once those\nresponsible become aware that their messages are being blocked\nby a particular method, they seek ways round that method. For\nexample, they might seek deliberately to misspell ‘viagra’ as\n‘v1agra’ or ‘v-iagra’, so that you can recognize it but the automatic\nprogram cannot.\nMore sophisticated spam detection tools are based on statistical\nmodels of the word content of spam messages. For example, they\nmight use estimates of the probabilities of particular words or\nword combinations arising in spam messages. Then a message\nthat contains too many high-probability words is suspect. More\nsophisticated tools build models for the probability that one word\nwill follow another, in a sequence, hence enabling the detection\nof suspicious phrases and sets of words. Yet other methods use\nstatistical models of images, to detect such things as skin tones in\nan emailed picture.\nExample 2: The Sally Clark case\nIn 1999, Sally Clark, a young British lawyer, was tried, convicted,\nand given a life sentence for murdering her two baby sons. Her\nfirst child died in 1996, aged 11 weeks, and her second died in\n1998, aged 8 weeks. The verdict depended on what has become a\nbyword for the misunderstanding and misuse of statistics, when\nthe paediatrician Sir Roy Meadow, in his role as expert witness for\nthe prosecution, claimed that the chance of two children dying\n14\n\nSurrounded by statistics\nfrom cot death was 1 in 73 million. He obtained this figure by\nsimply multiplying together the chance for the two deaths\nseparately. In doing so, in his ignorance of basic statistics, he\nentirely ignored the fact that one such death in a family is likely to\nmean that another such death is more likely.\nStudy of past data shows that the probability of a randomly\nselected baby suffering a cot death in a family such as the Clarks’\nis about 1 in 8,500. If one then makes the assumption that the\noccurrence of one such death does not change the probability of\nanother, then the chances of two such deaths in the same family\nwould be 1/8,500 times 1/8,500; that is, about one in 73 million.\nBut the assumption here is a big one, and careful statistical\nanalysis of past data suggests that, in fact, the chance of a second\ncot death is substantially increased when one has already\noccurred. Indeed, the calculations suggest that several such\nmultiple deaths should be expected to occur each year in a nation\nthe size of the UK. The website of the Foundation for the Study\nof Infant Death says ‘it is very rare for cot death to occur twice in\nthe same family, though occasionally an inherited disorder,\nsuch as a metabolic defect, may cause more than one infant to die\nunexpectedly’.\nIn the Sally Clark case, there was more evidence suggesting that\nshe was innocent, and eventually it became clear that her second\nson had a bacterial infection known to predispose towards sudden\ninfant death. Ms Clark was subsequently released on appeal in\n2003. Tragically, she died in March 2007, aged just 42. More\ndetails of this terrible misunderstanding and misuse of statistics\nare given in an excellent article by Helen Joyce and on the website\nlisted in the Further reading at the end of this book.\nExample 3: Star clusters\nAs our ability to probe further and further into the universe has\nincreased, so it has become apparent that astronomic objects tend\n15\n\nStatistics\nto cluster together, and do so in a hierarchical way, so that stars\nform clusters, clusters of stars themselves form higher level\nclusters, and these then cluster in turn. In particular, our own\ngalaxy, which is a cluster of stars, is a member of theLocal Group\nof about thirty galaxies, and this in turn is a member of theLocal\nSupercluster. At the largest scale, the Universe looks rather like a\nfoam, with filaments consisting of Superclusters lying on the edges\nof vast empty spaces. But how was all this discovered? Even if we\nuse powerful telescopes to look out from the Earth, we simply see\na sky of stars. The answer is that teasing out this clustering\nstructure, and indeed discovering it in the first place, required\nstatistical techniques. One class of techniques involves calculating\nthe distances from each star to its few closest stars. Stars which\nhave more stars closer than expected by chance are in locally dense\nregions – local clusters.\nOf course, there is much more to it than that. Interstellar dust\nclouds will obscure the view of distant objects, and these dust\nclouds are not distributed uniformly in space. Likewise, faint\nobjects will only be seen if they are near enough to the Earth.\nA thin filament of galaxies seen end on from the Earth could\nappear to be a dense cluster. And so on. Sophisticated statistical\ncorrections need to be applied so that we can discern the\nunderlying truth from the apparent distributions of objects.\nUnderstanding the structure of the universe sheds light both on\nhow it came to be, and on its future development.\nExample 4: Manufacturing chemicals\nI have already remarked that while statisticians may be able to\nperform amazing feats, they cannot perform miracles. In\nparticular, the quality of their conclusions will be moderated by\nthe quality of the data. Given this, it is hardly surprising that there\nare important subdisciplines of statistics concerned with how best\nto collect data. These are discussed in Chapter 3. One of these\n16\n\nSurrounded by statistics\nsubdisciplines isexperimental design. Experimental design\ntechniques are used in situations where it is possible to control or\nmanipulate some of the ‘variables’ being studied. The tools of\nexperimental design enable us to extract maximum information\nfor a given use of resources. For example, in producing a particular\nchemical polymer we might be able to set the temperature,\npressure, and time of the chemical reaction to any values we want.\nDifferent values of these three variables will lead to variations in\nthe quality of the final product. The question is, what is the best\nset of values?\nIn principle, this is an easy question to answer. We simply make\nmany batches of the polymer, each with different values of the\nthree variables. This allows us to estimate the ‘response surface’,\nshowing the quality of the polymer at each set of three values of\nthe variables, and we can then choose the particular triple which\nmaximizes the quality.\nBut what if the manufacturing process is such that it takes several\ndays to make each batch? Making many such batches, just to\nwork out the best way of doing so, may be infeasible. Making\n100 batches, each of which takes three days, would take the better\npart of a year. Fortunately, cleverly designed experiments allow us\nto extract the same information from far fewer carefully chosen\nsets of values. Sometimes a tiny fraction of batches can yield\nenough information for us to determine the best set of values,\nprovided those batches are properly selected.\nExample 5: Customer satisfaction\nTo run any retail organization effectively, so that it makes a profit\nand grows over time, requires paying careful attention to the\ncustomers, and giving them the product or service that they want.\nFailing to do so will mean that they go to a competitor who does\nprovidewhatiswanted.Thebottomlinehereisthatfailurewill\nbe indicated by declining revenues. We can try to avoid that by\n17\n\nStatistics\ncollecting data on how the customers feel before they begin voting\nwith their wallets. We can carry out surveys of customer\nsatisfaction, asking customers if they are happy with the product\nor service and in what ways these might be improved.\nAt first glance, it might look as if, to obtain reliable conclusions\nwhich reflect the behaviour of the entire customer base, it is\nnecessary to give questionnaires to all the customers. This could\nclearly be an expensive and time-consuming exercise. Fortunately,\nhowever, there are statistical methods which enable sufficiently\naccurate results to be obtained from just a sample of customers.\nIndeed, the results can sometimes be even more accurate than\nsurveying all customers. Needless to say, great care is needed in\nsuch an exercise. It is necessary to be wary of basing conclusions\non a distorted sample: the results would be useless as a description\nof how customers behaved in general if only those who spent large\nsums of money were interviewed. Once again, statistical methods\nhave been developed which enable us to avoid such mistakes – and\nso to draw valid conclusions.\nExample 6: Detecting credit card fraud\nNot all credit card transactions are legitimate. Fraudulent\ntransactions cost the bank money, and also cost the bank’s\ncustomers money. Detecting and preventing fraud is thus very\nimportant. Many readers of this book will have had the experience\nof their bank telephoning them to check that they made certain\ntransactions. These calls are based on the predictions made by\nstatistical models which describe how legitimate customers\nbehave. Departures from the behaviour predicted by these models\nsuggest that something suspicious is going on, deserving\ninvestigation.\nThere are various kinds of model. Some are based simply on\nintrinsically suspicious patterns of behaviour: simultaneous use of\na single card in geographically distant locations, for example.\n18\n\nSurrounded by statistics\nOthers are based on more elaborate models of the kinds of\ntransactions someone habitually makes, when they tend to make\nthem, for how much money, at what kinds of outlets, for which\nkinds of products, and so on.\nOf course, no such predictive model is perfect. Credit card\ntransactions patterns are often varied, with people suddenly\nmaking purchases of a kind they have never made before.\nMoreover, only a tiny percentage of transactions are fraudulent –\nperhaps around one in a thousand. This makes detection\nespecially difficult.\nDetecting and preventing fraud is a constant battle: when one\nfraud avenue is stopped, fraudsters tend not to abandon their\nchosen career path and take up a legitimate occupation, but switch\nto other methods of fraud, so requiring the development of further\nstatistical models.\nExample 7: Inflation\nWe are all familiar with the notion that things become more\nexpensive as time passes. But how can we compare today’s cost of\nliving with yesterday’s? To do so, we need to compare the same\nthings bought on the two dates. Unfortunately, there are\ncomplications: different shops charge different prices for the same\nthings, different people buy different things, the same people\nchange in their purchasing patterns, new products appear on the\nmarket and old ones vanish, and so on. How can we allow for\nchanges such as these in determining whether life is more\nexpensive nowadays?\nStatisticians and economists construct indicators such as the\nRetail Price Index and the Consumer Price Index to measure the\ncost of living. These are based on a notional ‘basket’ of (hundreds\nof) goods that people buy, along with surveys to discover what\nprices are being charged for each item in the basket. Sophisticated\n19\n\nStatistics\nstatistical models are used to combine the prices of the different\nitems to yield a single overall number which can be compared over\ntime. As well as serving as an indicator of inflation, such indices\nare also used to adjust tax thresholds and index-linked salaries,\npensions, and so on.\nConclusion\nIt may not always be apparent to the untutored eye, but statistics\nand statistical methods lie at the heart of scientific discovery,\ncommercial operations, government, social policy, manufacturing,\nmedicine, and most other aspects of human endeavour.\nFurthermore, as the world progresses, so this role is becoming\nmore and more important. For example, the development of new\nmedicines has long had a legal requirement for statisticians to be\ninvolved and something similar is now happening in the banking\nindustry, with new international agreements requiring statistical\nrisk models to be built. Given this pivotal role, it is clearly\nimportant that no educated citizen should be unaware of basic\nstatistical principles.\nModern statistics, with its use of sophisticated software tools to\nprobe data, permits us to make voyages of discovery paralleling\nthose of pre-20th-century explorers, investigating new and\nexciting realms. This recognition – that real statistics is about\nexploring the unknown, not about tedious arithmetic\nmanipulation – is central to an appreciation of the modern\ndiscipline.\n20\n\nChapter 2\nSimple descriptions\nData are nature’s evidence\nIntroduction\nIn this chapter, I aim to introduce some of the basic concepts and\ntools which form the foundation of statistics, and which enable it\nto play its many roles.\nIn Chapter 1, I noted that modern statistics suffered from many\nmisconceptions and misunderstandings. Yet another such\nmisunderstanding is often (probably inadvertently) propagated by\ntextbooks which describe statistical methods for experts in other\ndisciplines. This is that statistics is a bag of tools, with the role of\nthe statistician or user of statistics being to pick one tool to match\nthe question, and then to apply it.\nThe problem with this view of statistics is that it gives the\nimpression that the discipline is simply a collection of\ndisconnected methods of manipulating numbers. It fails to convey\nthe truth that statistics is a connected whole, built on deep\nphilosophical principles, so that the data analytic tools are linked\nand related: some may generalize to others, some may appear to\ndiffer simply because they work with different kinds of data, even\nthough they search for the same kind of structures, and so on. I\n21\n\nStatistics\nsuspect that this impression of a collection of isolated methods\nmay be another reason why newcomers find statistics rather\ntedious and hard to learn (apart from any fear of numbers they\nmay have). Learning a disconnected and apparently quite distinct\nset of methods is much tougher than learning about such methods\nthrough their relationship of derivation from underlying\nprinciples. It is rather like the difficulty of learning a random\ncollection of unrelated words, compared with learning words in a\nmeaningful sentence. I have endeavoured, in this chapter and\nthroughout the book, to convey the relationships between\nstatistical ideas, to show that the discipline is really an\ninterconnected whole.\nData again\nWhatever else it does, and whatever the details of the definition\nwe adopt, statistics begins with data. Data describe the universe\nwe wish to study. I am using the word ‘universe’ here in a very\ngeneral sense. It could be the physical world about us, but it\ncould be the world of credit card transactions, of microarray\nexperiments in genetics, of schools and their teaching and\nexamination performance, of trade between countries, of how\npeople behave when exposed to different advertisements, of\nsubatomic particles, and so on. There is no end to the worlds\nwhich can be studied, and therefore of the worlds represented by\ndata.\nOf course, no finite data set can tell us about all of the infinite\ncomplexities of the real world, just as no verbal description, even\nthat written by the most eloquent of authors, can convey\neverything about every facet of the world around us. That means\nwe must be specially aware of any potential shortcomings or gaps\nin our data. It means that, when collecting data, we need to take\nspecial care to ensure that they do cover the aspects we are\ninterested in, or about which we wish to draw conclusions. There\nis also a more positive way of looking at this: by collecting only a\n22\n\nSimple descriptions\nfinite set of descriptive aspects, we are forced to eliminate the\nirrelevant ones. When studying the safety of different designs of\ncars, we might decide not to record the colour of the fabric\ncovering the seats.\nBroadly speaking, it is convenient to regard data as having two\naspects. One aspect is concerned with the objects we wish to\nstudy, and the other aspect is concerned with the characteristics\nof those objects we wish to study. For example, our objects might\nbe children at school and the characteristics might be their test\nscores. Or perhaps the objects might be children, but we are\nstudying their diet and physical development, in which case the\ncharacteristics might be the children’s height and weight. Or our\nobjects might be physical materials, with the characteristics of\ninterest being their electrical and magnetic properties. In\nstatistics, it is common to call the characteristicsvariables,\nwith each object having avalueof a variable (the child’s score in a\nspelling test would be the value of the test variable, the magnitude\nof material’s electrical conductivity would be the value of the\nconductivity variable, etc.). In other data-analytic disciplines,\nalternative words are sometimes used (such as ‘feature’,\n‘characteristic’, or ‘attribute’), but when I get on to discussing the\ntechnical aspects I shall usually stick to ‘variable’.\nIn fact, in any one study we might be interested in multiple kinds\nof objects. We might want to understand and make statements not\nonly about school children, but also about the schools themselves,\nand perhaps about the teachers, the styles of teaching, and\ndifferent kinds of school management structure, all in one study.\nMoreover, we will typically not be interested in any single\ncharacteristic of the objects being studied, but in relationships\nbetween characteristics, and indeed, perhaps relationships\nbetween characteristics for objects of different kinds and at\ndifferent levels. We see that things are often really quite\ncomplicated, as we might expect, given the complexity of the\nsubjects we might be studying.\n23\n\nStatistics\nMany people are resistant to the notion that numerical data can\nconvey the beauty of the real world. They feel that somehow\nconverting things to numbers strips away the magic. In fact, they\ncould not be more wrong. Numbers have the potential to allow us\nto perceive that beauty, that magic, more clearly and more deeply,\nand to appreciate it more fully. Admittedly,ambiguitymay be\nremoved by couching things in numerical form: if I say that there\nare four people in the room, you know exactly what I mean,\nwhereas, in contrast, if I say that someone is attractive you may\nnot be entirely sure what I mean. You may even disagree with my\nview that someone is attractive, but you are unlikely to disagree\nwith my view that there are four people in the room (barring\nerrors in our counting, of course, but that’s a different matter).\nNumbers are universally understood, regardless of nationality,\nreligion, gender, age, or any other human characteristic.\nRemoving ambiguity, and with it removing the risk of\nmisunderstanding, can only be beneficial when trying to\nunderstand something – when trying to see to its heart.\nThis lack of ambiguity in the interpretation of numbers is closely\ntied to the fact thatnumbers have only one property: their value or\nmagnitude. Contrary to what fortune tellers may have us believe,\nnumbers are not lucky or unlucky – in just the same way that\nnumbers do not have a colour, or a flavour, or an odour. They have\nno properties but their intrinsic numerical value. (Admittedly,\nsome people experiencesynaesthesia, in which they do associate a\nparticular colour or sensation with particular numbers. However,\nthe associated sensations are different for different people, and\ncannot be regarded as properties of the numbers themselves.)\nNumerical data give us a more direct and immediate link to the\nphenomena we are studying than do words, because numerical\ndata are typically produced by measuring instruments with a more\ndirect link to those phenomena than are words. Numbers come\ndirectly from the things being studied, whereas words are filtered\nby a human brain. Of course, things are more complicated if our\n24\n\nSimple descriptions\ndata-collection procedure is mediated by words (as would be the\ncase if the data are collected by questionnaires), but the principle\nstill holds good. While measuring instruments may not be perfect,\nthe data are a proper representation of the results of applying\nthose instruments to the phenomenon being investigated. I\nsometimes summarize this by the comment at the start of this\nchapter:data are nature’s evidence, seen through the lens of the\nmeasuring instrument.\nOn top of all this, numbers have practical consequences in terms\nof societal advance. It is the civilized world’s facility with\nmanipulating the representations of reality provided by numbers\nthat has led to such awesome material progress in the past few\ncenturies.\nAlthough numbers have only one property, their numerical value,\nwe might choose to use that property in different ways. For\nexample, when deciding on the order of merit of students in a\nclass, we might rank them according to their examination scores.\nThat is, we might care only about whether one score is higher than\nanother, and not about the precise numerical difference. When we\nare concerned only with theorderof the values in this way we say\nwe are treating the data as lying on an ‘ordinal’ scale. On the other\nhand, when a farmer measures the amount of corn he has\nproduced, he does not simply want to know whether he has grown\nmore than he grew last year. He also wants to know how much he\nhas produced: its actual weight. It is on this basis, after all, that it\nwill be sold in the market. In this situation, the farmer is really\ncomparing the weight of corn he has produced with a standard\nweight, such as a ton, so that he can say how many tons of corn he\nhas produced. Implicit in this is the calculation of the ratio of the\nweight of the corn the farmer has produced to the weight of one\nton of corn. For this reason, when we use the values in this way,\nwe say we are treating the data as lying on a ‘ratio’ scale. Note\nthat in this case we could choose to change the basic unit of\nmeasurement: we could calculate the weight in pounds or\n25\n\nStatistics\nkilograms rather than tons. As long as we say what unit we have\nused, then it is easy for anyone else to convert back, or to convert\nto whatever unit they normally use.\nIn yet another situation, we might want to know how many\npatients have suffered from a particular side effect of a medicine.\nIf the number is large enough we might want to withdraw the\ndrug from the market as being too risky. In this case, we are simply\ncounting discrete well-defined units (patients). No rescaling by\nchanging units would be meaningful (we would not contemplate\ncounting the number of ‘half patients’!), so we say we are treating\nthe data as lying on an ‘absolute’ scale.\nSimple summary statistics\nWhilst simple numbers constitute theelementsof data, in order\nfor them to be useful we need to look at the relationships between\nthem, and perhaps combine them in some way. And this is where\nstatistics comes in. Later chapters will explore more complex\nways of comparing and combining numbers, but this chapter\nserves to introduce the ideas. Here we look at some of the most\nstraightforward ways: we will not explore relationships between\ndifferent variables in this chapter, but simply look at information\nand insights which can be extracted from relationships between\nvalues measured on the same variable. For example, we might\nhave recorded the ages of the applicants for a place at a university,\nthe luminosity of the stars in a cluster, the monthly expenditures\nof families in a town, the weights of cows in a herd at the time\nof sending them to market, and so on. In each case, a single\nnumerical value is recorded for each ‘object’ in a population\nof objects.\nThe individual values in the collection, when taken together, are\nsaid to form a ‘distribution’ of values. Summary statistics are ways\nof characterizing that distribution: of saying whether the values\n26\n\nSimple descriptions\nare very similar, whether there are some exceptionally large or\nsmall values, what a ‘typical’ value is like, and so on.\nAverages\nOne of the most basic kinds of descriptions, or summary statistics,\nof a set of numbers is an ‘average’. An average is a representative\nvalue; it is close, in some sense, to the numbers in the set. The need\nfor such a thing is most apparent when the set of numbers is large.\nFor example, suppose we had a table recording the ages of each of\nthe people in a large city – perhaps with a million inhabitants. For\nadministrative and business purposes it would obviously be useful\nto know the average age of the inhabitants. Very different services\nwould be needed and sales opportunities would arise if the average\nage was 16 instead of 60. We could try to get a ball-park feel for\nthe general size of the numbers in the table, the ages, by looking\nat each of the values. But this would clearly be a tough exercise.\nIndeed, if it took only one second to look at each number, it would\ntake over 270 hours to look through a table of a million numbers,\nand that’s ignoring the actual business of trying to remember and\ncompare them. But we can use our computer to help us.\nFirst, we need to be clear about exactly what we mean by ‘average’,\nbecause the word has several meanings. Perhaps the most widely\nused type of average is thearithmetic mean,orjustmeanfor\nshort. If people use the word ‘average’ without saying how they\ninterpret it, then they probably intend the arithmetic mean.\nBefore I show how to calculate the arithmetic mean, imagine\nanother table of a million numbers. Only, in this second table,\nsuppose that all the numbers are identical to each other. That is,\nsuppose that they all have the same value. Now add up all the\nnumbers in the first table, to find their total (this takes but a split\nsecond using a computer). And add up all the numbers in the\nsecond table, to find their total. If the two totals are the same, then\nthe number which is repeated a million times in the second table\n27\n\nStatistics\nis capturing some sort of essence of the numbers in the first table.\nThis single number, for which a million copies add up to the same\ntotal as the first table, is called the arithmetic mean (of the\nnumbers in the first table).\nIn fact, the arithmetic mean is most easily calculated simply by\ndividing the total of the million numbers in the first table by a\nmillion. In general, the arithmetic mean of a set of numbers is\nfound by adding all the numbers up and dividing by how many\nthere are. Here is a further example. In a test, the percentage\nscores for five students in a class were 78, 63, 53, 91, and 55. The\ntotal is 78 + 63 + 53 + 91 + 55 = 340. The arithmetic mean is then\nsimply given by dividing 340 by 5. It is 68. We would get the same\ntotal of 340 if all five students each scored the mean value, 68.\nThe arithmetic mean has many attractive properties. It always\ntakes a value between the largest and smallest values in the set of\nnumbers. Moreover, it balances the numbers in the set, in the\nsense that the sum of the differences between the arithmetic mean\nand those values larger than it is exactly equal to the sum of the\ndifferences between the arithmetic mean and those values smaller\nthan it. In that sense, it is a ‘central’ value. Those of a mechanical\nturn of mind might like to picture a set of 1kg weights placed at\nvarious positions along a (weightless) plank of wood. The distances\nof the weights from one end of the plank represent the values in\nthe set of numbers. The mean is the distance from the end such\nthat a pivot placed there would perfectly balance the plank.\nThe arithmetic mean is astatistic. It summarizes the entire set of\nvalues in our collection to a single value. It follows from this that it\nalso throws away information: we should not expect to represent a\nmillion (or five, or however many) different numbers by a single\nnumber without sacrificing something. We shall explore this\nsacrifice later. But since it is a central value in the sense illustrated\nabove it can be a useful summary. We can compare the average\nclass size in different schools, the average test score of different\n28\n\nSimple descriptions\nstudents, the average time it takes different people to get to work,\nthe average daily temperature in different years, and so on.\nThe arithmetic mean is one important statistic, a summary of a set\nof numbers. Another important summary is themedian.The\nmean was the pivotal value, a sort of central point balancing the\nsum of differences between it and the numbers in the set. The\nmedian balances the set in another way: it is the value such that\nhalf the numbers in the data set are larger and half are smaller.\nReturning to the class of five students illustrated above, their\nscores, in order from smallest to largest, are 53, 55, 63, 78, and 91.\nThe middle score here is 63, so this is the median.\nObviously complications arise if there are equal values in the data\nset (e.g. suppose it consists of 99 copies of the value 0 and a single\ncopy of the value 1), but these can be overcome. In any case, once\nagain the median is a representative value in some sense, although\nin a different sense from the mean. Because of this difference, we\nshould expect it to take a value different from the mean. Obviously\nthe median is easier to calculate than the mean. We do not even\nhave to add up any values to reach it, let alone divide by the\nnumber of values in the set. All we have to do is order the\nnumbers, and locate the one in the middle. But in fact this\ncomputational advantage is essentially irrelevant in the computer\nage: in real statistical analyses the computer takes over the tedium\nof arithmetic juggling.\nPresented with these two summary statistics, both providing\nrepresentative values, how should we choose which to use in any\nparticular situation? Since they are defined in different ways,\ncombining the numerical values differently, they are likely to\nproduce different values, so any conclusions based on them may\nwell be different. A full answer to the question of which to choose\nwould get us into technicalities beyond the level of this book, but a\nshort answer is that the choice will depend on the precise details\nof the question one wishes to answer.\n29\n\nStatistics\nHere is an illustration. Suppose that a small company has five\nstaff, each in a different grade and earning, respectively, $10,000,\n$10,001, $10,002, $10,003, and $99,999. The mean of these is\n$28,001, while the median is $10,002. Now suppose that the\ncompany intends to recruit five new employees, one to each grade.\nThe employer might argue that in this case, ‘on average’, she would\nhave to pay the newcomers a salary of $28,001, so that this is the\naverage salary she states in the advertisement. The employees,\nhowever, might feel that this is dishonest, since as many new\nemployees will be paid less than $10,002 as will be paid more than\n$10,002. They might feel it is more honest to put this figure in the\nadvertisement. Sometimes it requires careful thought to decide\nwhich measure is appropriate. (And in case you think this\nargument is contrived, Figure 1 shows the distribution of\nAmerican baseball players’ salaries prior to the 1994 strike.\nThe arithmetic mean was $1.2 million, but the median was only\n$0.5 million.)\nThis example also illustrates the relative impact of extreme values\non the mean and the median. In the pay example above, the mean\nis nearly three times the median. But suppose the largest value had\nbeen $10,004 instead of $99,999. Then the median would remain\nas $10,002 (half the values above and half below), but the mean\nwould shrink to $10,002. The size of just a single value can have a\ndramatic effect on the mean, but leave the median untouched.\nThis sensitivity of the mean to extreme values is one reason why\nthe median may sometimes be chosen in preference to the mean.\nThe mean and the median are not the only two representative\nvalue summaries. Another important one is themode. This is the\nvalue taken most frequently in a sample. For example, suppose\nthat I count the number of children per family for families in a\ncertain population. I might find that some families have one child,\nsome two, some three, and so on, and, in particular, I might find\nthat more families have two children than any other value. In this\ncase, the mode of the number of children per family would be two.\n30\n\nSimple descriptions\n1. Distribution of American baseball players’ salaries in 1994. The\nhorizontal axis shows salaries in millions of dollars, and the vertical\naxis the numbers in each salary range\nDispersion\nAverages, such as the mean and the median, provide single\nnumerical summaries of collections of numerical values. They are\nuseful because they can give an indication of the general size of the\nvalues in the data. But, as we have seen in the example above,\nsingle summary values can be misleading. In particular, single\nvalues might deviate substantially from individual values in a set\nof numbers. To illustrate, suppose that we have a set of a million\nandonenumbers,takingthevalues0,1,2,3,4,...,1,000,000.\nBoth the mean and the median of this set of values are 500,000.\nBut it is readily apparent that this is not a very ‘representative’\nvalue of the set. At the extremes, one value in the set is half a\n31\n\nStatistics\nmillion larger and one value is half a million smaller than the\nmean (and median).\nWhat is missing when we rely solely on an average to summarize a\nset of data is some indication of how widely dispersed the data are\naround that average. Are some data points much larger than the\naverage? Are some much smaller? Or are they all tightly bunched\nabout the average? In general, how different are the values in the\ndata set from each other? Statistical measures ofdispersion\nprovide precisely this information, and as with averages there is\nmore than one such measure.\nThe simplest measure of dispersion is therange.Thisisdefinedas\nthe difference between the largest and smallest values in the data\nset. In our data set of a million and one numbers, the range is\n1,000,000−0 = 1,000,000. In our example of five salaries, the\nrange is $99,999−$10,000 = $89,999. Both of these examples,\nwith large ranges, show that there are substantial departures from\nthe mean. For example, if the employees had been earning the\nrespective salaries of $27,999, $28,000, $28,001, $28,002,\n$28,003 then the mean would also be $28,001, but the range\nwould be only $4. This paints a very different picture, telling us\nthat the employees with these new salaries earn much the same as\neach other. The large range of the earlier example, $89,999,\nimmediately tells us that there are gross differences.\nThe range is all very well, and has many attractive properties\nas a measure of dispersion, not least its simplicity and ready\ninterpretability. However, we might feel that it is not ideal. After\nall, it ignores most of the data, being based on only the largest\nand smallest values. To illustrate, consider two data sets, each\nconsisting of a thousand values. One data set has one value of 0,\n998 values of 500, and one value of 1000. The other data set has\n500 values of 0 and 500 values of 1000. Both of these data sets\nhave a range of 1000 (and, incidentally, both also have a mean of\n32\n\nSimple descriptions\n500), but they are clearly very different in character. By focusing\nsolely on the largest and smallest values, the range has failed to\ndetect the fact that the first data set is mostly densely concentrated\naround the mean.\nThis shortcoming can be overcome by using a measure of\ndispersion which takesallof the values into account.\nOne common way to do this is to take the differences between the\n(arithmetic) mean and each number in the data set, square these\ndifferences, and then find the mean of these squared differences.\n(Squaring the differences makes the values all positive, otherwise\npositive and negative differences would cancel out when we\ncalculated the mean.) If the resulting mean of the squared\ndifferences is small, it tells us that, on average, the numbers are\nnot too different from their mean. That is, they are not widely\ndispersed. This mean squared difference measure is called the\nvarianceof the data – or, in some disciplines, simply themean\nsquared deviation. Illustrating with our five students, their test\nscores were 78, 63, 53, 91, and 55 and their mean was 68. The\nsquared differences between the first score and the mean is\n(78−68)\n2\n= 100, and so on. The sum of the squared differences\nis 100 + 25 + 225 + 529 + 169 = 1048, so that the mean of the\nsquared differences is 1048÷5=209.6. This is the variance.\nOne slight complication arises from the fact that the variance\ninvolves squared values. This implies that the variance itself is\nmeasured in ‘square units’. If we measure the productivity of farms\nin terms of tons of corn, the variance of the values is measured in\n‘tons squared’. It is not obvious what to make of this. Because of\nthis difficulty, it is common to take the square root of the variance.\nThis changes the units back to the original units, and produces\nthe measure of dispersion called thestandard deviation.Inthe\nexample above, the standard deviation of the students’ test scores\nis the square root of 209.6, or 14.5.\n33\n\nStatistics\nThe standard deviation overcomes the problem that we identified\nwith the range: it uses all of the data. If most of the data points are\nclustered very closely together, with just a few outlying points, this\nwill be recognized by the standard deviation being small. In\ncontrast, if the data points take very different values, even if they\nhave the same largest and smallest value, the standard deviation\nwill be much larger.\nSkewness\nMeasures of dispersion tell us how much the individual values\ndeviate from each other. But they do not tell us in what way they\ndeviate. In particular, they do not tell us if the larger deviations\ntend to be for the larger values or the smaller values in the data\nset. Recall our example of the five company employees, in which\nfour earned about $10,000 per year, and one earned around ten\ntimes that. A measure of dispersion (the standard deviation, for\nexample) would tell us that the values were quite widely spread\nout, but would not tell us that one of the values was much larger\nthan the others. Indeed, the standard deviation for the five values\n$90,000, $89,999, $89,998, $89,997, and $1 is exactly the same\nas for the original five values. What is different is that the\nanomalous value (the $1 value) is now very small instead of very\nlarge. To detect this difference, we need another statistic to\nsummarize the data, one which picks up on and measures the\nasymmetryin the distribution of values. One kind of asymmetry\nin distributions of values is calledskewness. Our original employee\nsalary example, with one anomalously large value of $99,999, is\nright skewedbecause the distribution of values has a long ‘tail’\nstretching out to the single very large value of $99,999. This\ndistribution has many smaller values and very few larger values. In\ncontrast, the distribution of values given above, in which $1 is the\nanomaly, isleft skewed, because the bulk of the values bunch\ntogether and there is a long tail stretching down to the single very\nsmall value.\n34\n\nSimple descriptions\nRight skewed distributions are very common. A classic example is\nthe distribution of wealth, in which there are many individuals\nwith small sums and just a few individuals with many billions of\ndollars. The distribution of baseball players’ salaries in Figure 1 is\nheavily right skewed.\nQuantiles\nAverages, measures of dispersion, and measures of skewness\nprovide overall summary statistics, condensing the values in a\ndistribution down to a few convenient numbers. We might,\nhowever, be interested in just parts of a distribution. For example,\nwe might be concerned with just the largest or smallest few – say,\nthe largest 5% – values in the data set. We have already met the\nmedian, the value which is in the middle of the data in the sense\nthat 50% of the values are larger and 50% are smaller. This idea\ncan be generalized. For example, theupper quartileof a set of\nnumbers is that value such that 25% (i.e. a quarter) of the data\nvalues are larger, and thelower quartileis that value such that\n25% of the data values are smaller.\nThis is taken further to producedeciles(dividing the data set into\ntenths, from the lowest tenth through to the highest tenth) and\npercentiles(dividing the data into 100ths). Thus someone might\nbe described as scoring above the 95th percentile, meaning that\ntheyareinthetop5%ofthesetofscores.Thegeneralterm,\nincluding quartiles, deciles, percentiles, etc., as special cases, is\nquantile.\n35\n\nChapter 3\nCollecting good data\nRaw data, like raw potatoes, usually require cleaning before use.\nRonald A. Thisted\nData provide a window to the world, but it is important that they\ngive us a clear view. A window with scratches, distortions, or with\nmarks on the glass is likely to mislead us about what lies beyond,\nand it is the same with data. If data are distorted or corrupted in\nsome way then mistaken conclusions can easily arise. In general,\nnot all data are of high quality. Indeed, I might go further than this\nand suggest that it is rare to meet a data set which does not have\nquality problems of some kind, perhaps to the extent that if you\nencounter such a ‘perfect’ data set you should be suspicious.\nPerhaps you should ask what preprocessing the data set has been\nsubjected to which makes it look so perfect. We will return to the\nquestion of preprocessing later.\nStandard textbook descriptions of statistical ideas and methods\ntend to assume that the data have no problems (statisticians say\nthe data are ‘clean’, as opposed to ‘dirty’ or ‘messy’). This is\nunderstandable, since the aim in such books is to describe the\nmethods, and it detracts from the clarity of the description to say\nwhat to do if the data are not what they should be. However, this\nbook is rather different. The aim here is not to teach the\nmechanics of statistical methods, but rather to introduce and\n36\n\nCollecting good data\nconvey the flavour of the real discipline. And the real discipline of\nstatistics has to cope with dirty data.\nIn order to develop our discussion, we need to understand what\ncould be meant by ‘bad data’, how to recognize them, and what to\ndo about them. Unfortunately, data are like people: they can ‘go\nbad’ in an unlimited number of different ways. However, many of\nthose ways can be classified as eitherincompleteorincorrect.\nIncomplete data\nA data set is incomplete if some of the observations are missing.\nData may be randomly missing, for reasons entirely unrelated to\nthe study. For example, perhaps a chemist dropped a test tube, or a\npatient in a clinical trial of a skin cream missed an appointment\nbecause of a delayed plane, or someone moved house and so could\nnot be contacted for a follow-up questionnaire. But the fact that a\ndata item is missing can also in itself be informative. For example,\npeople completing an application form or questionnaire may wish\nto conceal something, and, rather than lie outright, may simply\nnot answer that question. Or perhaps only people with a particular\nview bother to complete a questionnaire. For example, if\ncustomers are asked to complete forms evaluating the service they\nhave received, those with axes to grind may be more inclined to\ncomplete them. If this is not recognized in the analysis, a distorted\nview of customers’ opinions will result. Internet surveys are\nespecially vulnerable to this kind of thing, with people often\nsimply being invited to respond. There is no control over how\nrepresentative the respondents are of the overall population, or\neven if the same people respond multiple times.\nOther examples of this sort of ‘selection bias’ abound, and can be\nquite subtle. For example, it is not uncommon for patients to drop\nout of clinical trials of medicines. Suppose that patients who\nrecovered while using the medicine failed to return for their next\nappointment, because they felt it was unnecessary (since they had\n37\n\nStatistics\nrecovered). Then we could easily draw the conclusion that the\nmedicine did not work, since we would see only patients who were\nstill sick.\nA classic case of this sort of bias arose when theLiterary Digest\nincorrectly predicted that Landon would overwhelmingly defeat\nRoosevelt in the 1936 US presidential election. Unfortunately,\nthe questionnaires were mailed only to people who had both\ntelephones and cars, and in 1936 these people were wealthier\non average than the overall population. The people sent\nquestionnaires were not properly representative of the overall\npopulation. As it turned out, the bulk of the others supported\nRoosevelt.\nAnother, rather different kind of case of incorrect conclusions\narising from failure to take account of missing data has become\na minor statistical classic. This is the case of theChallengerspace\nshuttle, which blew up on launch in 1986, killing everyone on\nboard. The night before the launch, a meeting was held to\ndiscuss whether to go ahead, since the forecast temperature\nfor the launch date was exceptionally low. Data were produced\nshowing that there was apparently no relationship between air\ntemperature and damage to certain seals on the booster rockets.\nHowever, the data were incomplete, and did not include all those\nlaunches involvingnodamage. This was unfortunate because the\nlaunches when no damage occurred were predominantly made\nat higher temperatures. A plot ofallof the data shows a clear\nrelationship, with damage being more likely at lower\ntemperatures.\nAs a final example, people applying for bank loans, credit cards,\nand so on, have a ‘credit score’ calculated, which is essentially an\nestimate of the probability that they will fail to repay. These\nestimates are derived from statistical models built (as described in\nChapter 6) using data from previous customers who have already\n38\n\nCollecting good data\nrepaid or failed to repay. But there is a problem. Previous\ncustomers are not representative of all people who applied for a\nloan. After all, previous customers were chosen because they\nwere thought to be good risks. Those applicants thought to be\nintrinsically poor risks and likely to default would not have been\naccepted in the first place, and would therefore not be included in\nthe data. Any statistical model which fails to take account of this\ndistortion of the data set is likely to lead to mistaken conclusions.\nIn this case, it could well mean the bank collapsing.\nIf only some values are missing for each record (e.g. some of the\nanswers to a questionnaire), then there are two common\nelementary approaches to analysis. One is simply to discard any\nincomplete records. This has two potentially serious weaknesses.\nThe first is that it can lead to selection bias distortions of the kind\ndiscussed above. If records of a particular kind are more likely to\nhave some values missing, then deleting these records will leave\na distorted data set. The second serious weakness is that it can\nlead to a dramatic reduction in the size of the data set available\nfor analysis. For example, suppose a questionnaire contains\n100 questions. It is entirely possible thatnorespondent answered\neveryquestion, so thatallrecords may have something missing.\nThis means that dropping incomplete responses would lead to\ndropping all of the data.\nThe second popular approach to handling missing values is to\ninsert substitute values. For example, suppose age is missing from\nsome records. Then we could replace the missing values by the\naverage of the ages which had been recorded. Although this results\nin a complete(d) data set, it also has disadvantages. Essentially we\nwould be making up data.\nIf there is reason to suspect that the fact that a number is missing\nis related to the value it would have had (for example, if older\npeople are less likely to give their age) then more elaborate\n39\n\nStatistics\nstatistical techniques are needed. We need to construct a statistical\nmodel, perhaps of the kind discussed in Chapter 6, of the\nprobability of being missing, as well as for the other relationships\nin the data.\nIt is also worth mentioning that it is necessary to allow for the fact\nthat not all values have been recorded. It is common practice to\nuse a special symbol to indicate that a value is missing. For\nexample, N/A, for ‘not available’. But sometimes numerical codes\nare used, such as 9999 for age. In this case, failure to let the\ncomputer know that 9999 represents missing values can lead to a\nwildly inaccurate result. Imagine the estimated average age when\nthere are many values of 9999 included in the calculation . . .\nIn general, and perhaps this should be expected, there is no perfect\nsolution to missing data. All methods to handle it require some\nkind of additional assumptions to be made. The best solution is to\nminimize the problem during the data collection phase.\nIncorrect data\nIncomplete data is one kind of data problem, but data may be\nincorrectin any number of ways and for any number of reasons.\nThere are both high and low level reasons for such problems.\nOne high level reason is the difficulty of deciding on suitable\n(and universally agreed) definitions. Crime rate, referred to in\nChapter 1, provides an example of this. Suicide rate provides\nanother. Typically, suicide is a solitary activity, so that no one else\ncan know for certain that it was suicide. Often a note is left, but\nnot in all cases, and then evidence must be adduced that the death\nwas in fact suicide. This moves us to murky ground, since it raises\nthe question of what evidence is relevant and how much is needed.\nMoreover, many suicides disguise the fact that they took their own\nlife; for example so that the family can collect on the life\ninsurance.\n40\n\nCollecting good data\nIn a different, but even more complicated situation, the National\nPatient Safety Agency in the UK is responsible for collating\nreports of accidents which have occurred in hospitals. The Agency\nthen tries to classify them to identify commonalities, so that steps\ncan be taken to prevent accidents happening in the future. The\ndifficulty is that accidents are reported by many thousands of\ndifferent people, and described in different ways. Even the same\nincident can be described very differently.\nAt a lower level, mistakes are often made in reading instruments\nor recording values. For example, a common tendency in reading\ninstruments is to subconsciously round to the nearest whole\nnumber. Distributions of blood pressure measurements recorded\nusing old-fashioned (non-electronic) sphygmomanometers show a\nclear tendency for more values to be recorded at 60, 70, and\n80mm of mercury than at neighbouring values, such as 69 or 72.\nAs far as recording errors go, digits may be transposed (28, instead\nof 82); the handwritten digit 7 may be mistaken for 1 (less likely in\ncontinental Europe, where 7 is written\n7);datamaybeputinthe\nwrong column on a form, so accidentally multiplying values by 10;\nthe US style of date (month/day/year) might be confused with the\nUK style (day/month/year) or vice versa; and so on. In 1796, the\nAstronomer Royal Nevil Maskelyne dismissed his assistant, David\nKinnebrook, on the grounds that the latter’s observations of the\ntimes at which a chosen star crossed the meridian wire in a\ntelescope at Greenwich were too inaccurate. This mattered,\nbecause the accuracy of the clock at Greenwich hinged on accurate\nmeasurements of the transit times, estimates of the longitude of\nthe nation’s ships depended on the clock, and the British Empire\ndepended on its ships. However, later investigators have explained\nthe inaccuracies in terms of psychological reaction time delays and\nthe subconscious rounding phenomenon mentioned above. And,\nas a final example from the many I could have chosen, the 1970 US\nCensus said there were 289 girls who had been both widowed and\ndivorced by the age of 14. We should also note the general point\nthat the larger the data set, the more hands involved in its\n41\n\nStatistics\ncompilation, and the more stages involved in its processing, the\nmore likely it is to contain errors.\nOther low level examples of data errors often arise with units of\nmeasurement, such as recording height in metres rather than feet,\nor weight in pounds rather than kilograms. In 1999, theClimate\nOrbiterMars probe was lost when it failed to enter the Martian\natmosphere at the correct angle because of confusion between\npressure measurements based on pounds and on newtons. In\nanother example of confusion of units, this time in a medical\ncontext, an elderly lady usually had normal blood calcium levels,\nin the range 8.6 to 9.1, which suddenly appeared to drop to a much\nlower value of 4.8. The nurse in charge was about to begin infusing\ncalcium, when Dr Salvatore Benvenga discovered that the\napparent drop was simply because the laboratory had changed the\nunits in which it reported its results (from milligrams per decilitre\nto milliequivalents per litre).\nError propagation\nOnce made, errors can propagate with serious consequences. For\nexample, budget shortfalls and possible job layoffs in Northwest\nIndiana in 2006 were attributed to the effect of a mistake in just\none number working its way up through the system. A house that\nshould have been valued at $121,900 had its value accidentally\nchanged to $400 million. Unfortunately, this mistaken value was\nused in calculating tax rates.\nIn another case, theTimesof 2 December 2004 reported how\n66,500 of around 170,000 firms were accidentally removed from a\nlist used to compile official estimates of construction output in the\nUK. This led to a reported fall of 2.6% in construction growth in\nthe first quarter, rather than the correct value of an increase of\n0.5%, followed by a reported growth of 5.3% rather than the\ncorrect 2.1% in the second quarter.\n42\n\nCollecting good data\nPreprocessing\nAs must be obvious from the examples above, an essential initial\ncomponent of any statistical analysis is a close examination of the\ndata, checking for errors, and correcting them if possible. In some\ncontexts, this initial stage can take longer than the later analysis\nstages.\nA key concept in data cleaning is that of anoutlier. An outlier is a\nvalue that is very different from the others, or from what is\nexpected. It is way out in the tail of a distribution. Sometimes such\nextreme values occur by chance. For example, although most\nweather is fairly mild, we do get occasional severe storms. But in\nother instances anomalies arise because of the sorts of errors\nillustrated above, such as the anemometer which apparently\nreported a sudden huge gust of wind every midnight,\ncoincidentally at the same time that it automatically reset its\ncalibration. So one good general strategy for detecting errors in\ndata is to look for outliers, which can then be checked by a human.\nThese might be outliers on single variables (e.g. the man with a\nreported age of 210), or on multiple variables, neither of which is\nanomalous in itself (e.g. the 5-year-old girl with 3 children).\nOf course, outlier detection is not a universal solution to detecting\ndata errors. After all, errors can be made that lead to values which\nappear perfectly normal. Someone’s sex may mistakenly be coded\nas male instead of female. The best answer is to adopt data-entry\npractices that minimize the number of errors. I say a little more\nabout this below.\nIf an apparent error is detected, there is then the problem of what\nto do about it. We could drop the value, regarding it as missing,\nand then try to use one of the missing value procedures mentioned\nabove. Sometimes we can make an intelligent guess as to what the\nvalue should have been. For example, suppose that, in recording\nthe ages of a group of students, one had obtained the string of\n43\n\nStatistics\nvalues 18, 19, 17, 21, 23, 19, 210, 18, 18, 23. Studying these, we\nmight think it likely that the 210 had been entered into a wrong\ncolumn, and that it should be 21. By the way, note the phrase\n‘intelligent guess’ used above. As with all statistical data analysis,\ncareful thought is crucial. It is not simply a question of choosing\na particular statistical method and letting the computer do the\nwork. The computer only does the arithmetic.\nThe example of student ages in the previous paragraph was very\nsmall, just involving ten numbers, so it was easy to look through\nthem, identify the outlier, and make an intelligent guess about\nwhat it should have been. But we are increasingly faced with larger\nand larger data sets. Data sets of many billions of values are\ncommonplace nowadays in scientific applications (e.g. particle\nexperiments), commercial applications (e.g. telecommunications),\nand other areas. It will often be quite infeasible to explore all the\nvalues manually. We have to rely on the computer. Statisticians\nhave developed automatic procedures for detecting outliers, but\nthese do not completely solve the problem. Automatic procedures\nmay raise flags about certain kinds of strange values, but they will\nignore peculiarities they have not been told about. And then there\nis the question of what to do about an apparent anomaly detected\nby the computer. This is fine if only 1 in those billion numbers is\nflagged as suspicious, but what if 100,000 are so flagged? Again,\nhuman examination and correction is impracticable. To cope with\nsuch situations, statisticians have again developed automated\nprocedures. Some of the earliest such automated editing and\ncorrecting methods were developed in the context of censuses and\nlarge surveys. But they are not foolproof. The bottom line is,\nI am afraid, once again, that statisticians cannot work miracles.\nPoor data risk yielding poor (meaning inaccurate, mistaken,\nerror-prone) results. The best strategy for avoiding this is to\nensure good-quality data from the start.\nMany strategies have been developed for avoiding errors in data in\nthe first place. They vary according to the application domain and\n44\n\nCollecting good data\nthe mode of data capture. For example, when clinical trial data are\ncopied from hand-completed case record forms, there is a danger\nof introducing errors in the transcription phase. This is reduced by\narranging for the exercise to be repeated twice, by different people\nworking independently, and then checking any differences. When\napplying for a loan, the application data (e.g. age, income, other\ndebts, and so on) may be entered directly into a computer, and\ninteractive computer software can cross-check the answers as they\nare given (e.g. if a house owner, do the debts include a mortgage?).\nIn general, forms should be designed so as to minimize errors.\nThey should not be excessively complicated, and all questions\nshould be unambiguous. It is obviously a good idea to conduct a\nsmall pilot survey to pick up any problems with the data capture\nexercise before going live.\nIncidentally, the phrase ‘computer error’ is a familiar one, and the\ncomputer is a popular scapegoat when data mistakes are made.\nBut the computer is just doing what it is told, using the data\nprovided. When errors are made, it is not the computer’s fault.\nObservational versus experimental data\nIt is often useful to distinguish betweenobservationaland\nexperimentalstudies, and similarly between observational and\nexperimental data. The word ‘observational’ refers to situations\nin which one cannot interfere or intervene in the process of\ncapturing the data. Thus, for example, in a survey (see below) of\npeople’s attitudes to politicians, an appropriate sample of people\nwould be asked how they felt. Or, in a study of the properties of\ndistant galaxies, those properties would be observed and recorded.\nIn both of these examples, the researchers simply chose who or\nwhat to study and then recorded the properties of those people or\nobjects. There is no notion of doing something to the people or\ngalaxies before measuring them. In contrast, in an experimental\nstudy the researchers would actually manipulate the objects in\nsome way. For example, in a clinical trial they might expose\n45\n\nStatistics\nvolunteers to a particular medication, before taking the\nmeasurements. In a manufacturing experiment to find the\nconditions which yield the strongest finished product, they would\ntry different conditions.\nOne fundamental difference between observational and\nexperimental studies is that experimental studies are much\nmore effective at sorting out what causes what. For example,\nwe might conjecture that a particular way of teaching children\nto read (method A, say) is much more effective than another\n(method B). In an observational study, we will look at children\nwho have been taught by each method, and compare their reading\nability. But we will not be able to influence who is taught by\nmethod A and who by method B; this is determined by someone\nelse. This raises a potential problem. It means that it is possible\nthat there are other differences between the two reading groups,\nas well as teaching method. For example, to take an extreme\nillustration, a teacher may have assigned all the faster learners\nto method A. Or perhaps the children themselves were allowed to\nchoose, and those already more advanced in reading tended to\nchoose method A. If we are a little more sophisticated in statistics,\nwe might use statistical methods to try to control for any\npre-existing differences between the children, as well as other\nfactors we think are likely to influence how quickly they would\nlearn to read. But there will always remain the possibility that\nthere are other influences we have not thought of which cause\nthe difference.\nExperimental studies overcome this possibility by deliberately\nchoosing which child is taught by each method. If we did know all\nthe possible factors, in addition to teaching method, which could\ninfluence reading ability, we could make sure that the assignment\nto teaching method was ‘balanced’. For example, if we thought that\nreading ability was influenced by age, we could assign the same\nnumber of young children to each method. By this means, any\ndifferences in reading ability arising from age would have no\n46\n\nCollecting good data\nimpact on the difference between our two groups: if age did\ninfluence reading ability, the impact would be the same in each\ngroup. However, as it happens, experimental studies have an even\nmore powerful way of choosing which child receives which\nmethod, calledrandomization. I discuss this below.\nThe upshot of this is that, in an experimental study we can be\nmore confident of the cause of any observed effect. In the\nexperiment comparing teaching reading, we can be more\nconfident that any difference between the reading ability in the\ntwo groups is a consequence of the teaching method, rather than\nof some other factor.\nUnfortunately it is not always possible to conduct experiments\nrather than observational studies. We do not have much\nopportunity to expose different galaxies to different treatments!\nIn any case, sometimes it would be misleading to use an\nexperimental approach: in many social surveys, the aim is to find\nout what the population is actually like, not ‘what would be the\neffect if we did such and such’. However, if we do want to know\nwhat would be the effect of a potential intervention, then\nexperimental studies are the better strategy. They are universal in\nthe pharmaceutical sector, very widespread in medicine and\npsychology, ubiquitous in industry and manufacturing, and\nincreasingly used to evaluate social policy and in areas such as\ncustomer value management.\nIn general, when collecting data with the aim of answering or\nexploring certain questions, the more data that are collected, the\nmore accurate an answer that can be obtained. This is a\nconsequence ofthe law of large numbers, discussed in Chapter 4.\nBut collecting more data incurs greater cost. It is therefore\nnecessary to strike a suitable compromise between the amount of\ndata collected and the cost of collecting it. Various subdisciplines\nof statistics are central to this exercise. In particular,experimental\ndesignandsurvey samplingare two key disciplines.\n47\n\nStatistics\nExperimental design\nWe have already seen examples of very simple experiments. One of\nthe simplest is a two-group randomized clinical trial. Here the aim\nis to compare two alternative treatments (A and B, say) so that we\ncan say which of the two should be given to a new patient. To\nexplore this, we give treatment A to one sample of patients,\ntreatment B to another sample of patients, and evaluate the\ntreatments’ effectiveness. If, on average, A beats B, then we will\nrecommend that the new patient receives treatment A. The\nmeaning of the word ‘beats’ in the previous sentence will depend\non the precise study. It could mean ‘cures more patients’, ‘extends\naverage lifespan’, ‘yields greater average reduction in pain’, and\nso on.\nNow, as we have already noted above, if the two groups of patients\ndiffer in some way, then the conclusions we can draw are limited.\nIf those who received treatment A were all male, and those who\nreceived treatment B were all female, then we would not know if\nany difference between the groups that we observed was due to the\ntreatment or to the sex difference: maybe females get better faster,\nregardless of treatment. The same point applies to any other\nfactor – age, height, weight, duration of illness, previous treatment\nhistory, and so on.\nOne strategy to alleviate this difficulty is to randomly allocate\npatients to the two treatment groups. The strength of this\napproach is that, while it does not guarantee balance (e.g., it is\npossible that this random allocation procedure might lead to a\nsubstantially higher proportion of males in one group than the\nother), basic rules of probability (discussed in Chapter 4) tell us\nthat large imbalances are extremely unlikely. In fact, it is possible\nto go further than this and work out just how likely different\ndegrees of imbalance are. This in turn enables us to calculate how\nconfident we should be in our conclusions.\n48\n\nCollecting good data\nMoreover, if the random allocation isdouble blind,thereisno\nrisk of subconscious bias creeping into the allocation or the\nmeasurement of patients. A study is double blind if neither the\npatient nor the doctor conducting the trial knows which treatment\nthe patient is receiving. This can be achieved by making the tablets\nor medicines look identical, and simply coding them as X or Y\nwithout indicating which of the treatments is which. Only later,\nafter the analysis has revealed that X is better than Y, is the coding\nbroken, to show that X is really treatment A or B as the case\nmay be.\nThe two-group randomized clinical trial is very simple, and has\nobvious extensions: for example, we can immediately extend it to\nmore than two treatment groups. However, for the sake of variety,\nI shall switch examples. A market gardener might want to know\nwhich of low and high levels of water is better, in terms of\nproducing greater crop yield. He could conduct a simple\ntwo-group experiment, of the kind described above, to determine\nthis. Since we know that outcomes are not totally predictable, he\nwill want to expose more than one greenhouse to the low level of\nwater, and more than one to the high level, and then calculate the\naverage yields at each level. He might, for example, decide to use\nfour greenhouses for each level. This is precisely the same sort of\ndesign as in the teaching methods study above.\nBut now suppose that the farmer also wants to know which of low\nand high levels of fertilizer is more effective. The obvious thing to\ndo is to conduct another two-group experiment, this time with\nfour greenhouses receiving the low level of fertilizer and four\nreceiving the high level. This is all very well, but to answer both of\nthe questions, the water one and the fertilizer one, requires a total\nof sixteen greenhouses. If the farmer is also interested in the\neffectiveness of low and high levels of humidity, temperature,\nhours of sunlight, and so on, we see that we will soon run out of\ngreenhouses.\n49\n\nStatistics\nNow, there is a very clever way round this, using the notion of a\nfactorialexperimental design. Instead of carrying out two separate\nexperiments, one for water and one for fertilizer, the farmer can\ntreat two greenhouses with (fertilizer = low, water = low), two with\n(low, high), two with (high, low), and two with (high, high). This\nrequires just eight greenhouses, and yet we are still treating four of\nthem with the low water level and four with the high water level,\nas well as four with the low fertilizer level and four with the high\nfertilizer level, so that the results of the analysis will be just as\naccurate as when we did two separate experiments.\nIn fact, this factorial design (each of water and fertilizer is a\n‘factor’) has an additional attractive feature. It allows us to see if\nthe impact of the level of fertilizer is different at the two levels of\nwater: perhaps the difference between yields with the low and\nhigh levels of fertilizer varies between the two levels of water. This\nso-calledinteractioneffect cannot be examined in the two\nseparate experiments approach.\nThis basic idea has been extended in many ways to yield very\npowerful tools for obtaining accurate information for the\nminimum cost. When combined with other experimental design\ntools, such as balance, randomization, and controlling for known\ninfluences, some highly sophisticated experimental designs have\nbeen developed.\nSometimes, in experiments, non-statistical issues are important.\nFor example, in clinical trials and other medical and social policy\ninvestigations, ethical issues may be relevant. In a clinical trial\ncomparing a proposed new treatment against an (inactive)\nplacebo, we will know that half of the volunteer patients will\nreceive something which has no biological impact. Is that\nappropriate? Is there a danger that those exposed to the proposed\nnew treatment might suffer from side effects? Such things have\nto be balanced against the fact that untold numbers of future\npatients will benefit from what is learned in the trial.\n50\n\nCollecting good data\nSurvey sampling\nImagine that, in order to run the country effectively, we wish to\nknow the average income of the one million employed men and\nwomen in a certain town. In principle, we could determine this by\nasking each of them what their income was, and averaging the\nresults. In practice, this would be extremely difficult, verging on\nthe impossible. Apart from anything else, over the course of the\ntime taken to collect the data it is likely that incomes would\nchange: some people would have left or changed their jobs, others\nwould have received raises, and so on. Furthermore, it would be\nextremely costly tracking down each person. We might try to\nreduce costs by relying on the telephone, rather than face to face\ninterviews. However, as we have already seen, in the extreme case\nof the 1936 US presidential election, there is a great risk that we\nwould miss important parts of the population.\nWhat we need is some way to reduce the cost of collecting the data\nwhile at the same time making the process quicker and, if possible,\nalso more accurate. Put this way, it probably sounds like a tall\norder, but statistical ideas and tools that have these properties do\nexist. The key idea is one we have met several times before: the\nnotion of a sample.\nSuppose that, instead of finding out what each of the one million\nemployees earned, we simply asked a thousand of them. Now\nclearly we have to be careful about exactly which thousand we ask.\nThe reasons are essentially the same as when we were designing a\nsimple two-group experiment and had to take steps to ensure that\nthe only difference between the groups was that one received\ntreatment A and one received treatment B. Now we have to\nensure that the particular thousand people we approach are\nrepresentativeof the full population of a million.\nWhat do we mean by ‘representative’? Ideally, our sample of a\nthousand should have the same proportion of men in it as the\n51\n\nStatistics\nentire population, the same number of young people, the same\nnumber of part-time workers, and so on. To some extent we can\nensure this, choosing the thousand so that the proportion of men\nis correct, for example. But there is obviously a practical limit to\nwhat we can deliberately balance in this way.\nWe saw how to handle this when we looked at experimental\ndesign. There we tackled the difficulty byrandomly allocating\npatients to each group. Here we tackle it byrandomly sampling\nthe thousand people from the total population. Once again, while\nthis does not guarantee that the sample will be similar in\ncomposition to the entire population, basic probability tells us that\nthe chance of obtaining a seriously dissimilar sample is very small.\nIn particular, it follows that the probability that our estimate of\nthe average income, derived from the sample, will be very different\nfrom the average income in the entire population is very small.\nIndeed, two properties of probability which we will explore later,\nthelaw of large numbersand theCentral Limit Theoremalso tell\nus that we can make this probability as small as we like by\nincreasing the sample size. It turns out that what matters is not\nhow large a fraction of the population is included in the sample,\nbut simply how large the sample is. Our estimate, based on a\nsample size of one thousand, would essentially be just as accurate\nif the entire population consisted of ten million or ten billion\npeople. Since sample size is directly related to the cost of collecting\nthe data, we now have an immediate relationship between\naccuracy and cost: the larger our sample the greater the cost but\nthe smaller the probability of significant deviation between the\nsample estimate and the overall population average.\nWhile ‘randomly sampling a thousand people from the population’\nof employed people in the town may sound like a simple exercise,\nin fact it takes considerable care. We cannot, for example, simply\nchoose the thousand people from the largest employer in the town,\nsince these may not be representative of the overall million.\nLikewise, we cannot call at a random sample of people’s homes at\n52\n\nCollecting good data\n8pm in the evening, since we would miss those who worked late,\nand these workers may differ in average income from the others.\nIn general, to ensure that our sample of a thousand is properly\nrepresentative we need asampling frame, a list of all the one\nmillion employed people in our population, from which we can\nrandomly choose a thousand. Having such a list ensures that\neveryone is equally likely to be included.\nThis notion ofsimple random samplingis the basic idea behind\nsurvey sampling. We draw up a sampling frame and from it\nrandomly choose the people to be included in our sample. We\nthen track them down (interview, phone, letter, email, or\nwhatever) and record the data we want. This basic idea has been\nelaborated in many very sophisticated and advanced ways,\nyielding more accurate and cheaper approaches. For example,\nif we intended to interview each of the thousand respondents it\ncould be quite costly in terms of time and travel expenses. It\nwould be better, from this perspective, to choose respondents from\nsmall geographically local clusters.Cluster samplingextends\nsimple random sampling by allowing this. Instead of randomly\nchoosing a thousand people from the entire population, it selects\n(say) ten groups of a hundred people each, with the people in\neach group located near to each other. Likewise, we can be certain\nthat balance is achieved on some factors, rather than simply\nrelying on the random sampling procedure, if we enforce the\nbalance in the way we choose the sample. For example, we could\nrandomly choose a number of women from the population, and\nseparately randomly choose a number of men from the\npopulation, where the numbers are chosen so that the proportions\nof males and females are the same as in the population. This\nprocedure is known asstratified sampling, since it divides the\noverall population listed in the sampling frame into strata (men\nand women in this case). If the variable used for the stratification\n(sex in this example) is strongly related to the variable we are\ninterested in (here, income), then this can yield improved accuracy\nfor the same sample size.\n53\n\nStatistics\nIn general, in survey sampling, we are very lucky if we obtain\nresponses from everyone approached. Almost always there is some\nnon-response. We are back to the missing data problem discussed\nearlier, and, as we have seen, missing data can lead to a biased\nsample and incorrect conclusions. If those earning large salaries\nrefused to reply, then we would underestimate the average income\nin the population. Because of this, survey experts have developed\na wide range of methods of minimizing and adjusting for\nnon-response, including repeated call-backs to non-responders\nand statistical reweighting procedures.\nConclusion\nThis chapter has described the raw material of statistics, the data.\nSophisticated data collection technologies have been developed\nby statisticians to maximize the information obtained for the\nminimum cost. But it would be naive to believe that perfect data\ncan usually be obtained. Data are a reflection of the real world,\nand the real world is complicated. Recognizing this, statisticians\nhave also developed tools to cope with poor-quality data. But it is\nimportant to recognize that statisticians are not magicians. The\nold adage of ‘garbage in, garbage out’ is just as true in statistics as\nelsewhere.\n54\n\nChapter 4\nProbability\nBeing a statistician means never having to say you are certain.\nAnon\nThe essence of chance\nOne of the definitions of statistics given in Chapter 1 was that it is\nthe science of handling uncertainty. Since it is abundantly clear\nthat the world is full of uncertainty, this is one reason for the\nubiquity of statistical ideas and methods. The future is an\nunknown land and we cannot be certain about what will happen.\nThe unexpected does occur: cars break down, we have accidents,\nlightning does strike, and, lest I am giving the impression that\nsuch things are always bad, people do even win lotteries. More\nprosaically, it is uncertain which horse will win the race or which\nnumber will come up on the throw of a die. And, at the end of it\nall, we cannot predict exactly how long our lives will be.\nHowever, notwithstanding all that, one of the greatest discoveries\nmankind has made is that there are certain principles covering\nchance and uncertainty. Perhaps this seems like a contradiction in\nterms. Uncertain events are, by their very nature, uncertain. How,\nthen, can there be natural laws governing such things?\n55\n\nStatistics\nOne answer is that while an individual event may be uncertain\nand unpredictable, it is often possible to say something about\ncollections of events. A classic example is the tossing of a coin.\nWhile I cannot say whether a coin will come up heads or tails on a\nparticular toss, I can say with considerable confidence that if I toss\nthe coin many times then around half of those times it will show\nheads and around half tails. (I am assuming here that the coin is\n‘fair’, and that no sleight of hand is being used when tossing it.)\nAnother example in the same vein is whether a baby will be male\nor female. It is, on conception, a purely chance and unpredictable\nevent which gender the child will become. But we know that over\nmany births just over a half will be male.\nThis observable property of nature is an example of one of the laws\ngoverning uncertainty. It is called thelaw of large numbers\nbecause of the fact that the proportion gets closer and closer to a\nparticular value (a half in the cases of the fair coin and of babies’\ngender) the more cases we consider. This law has all sorts of\nimplications, and is one of the most powerful of statistical tools\nin taming, controlling, and allowing us to take advantage of\nuncertainty. We return to it later in this chapter, and repeatedly\nthroughout the book.\nUnderstanding probability\nSo that we can discuss matters of uncertainty and unpredictability\nwithout ambiguity, statistics, like any other scientific discipline,\nuses a precise language: the language ofprobability.Ifthisisyour\nfirst exposure to the language of probability, then you should be\nwarned that, as with one’s first exposure to any new language,\nsome effort will be required to understand it. Indeed, bearing that\nin mind, you might find that this chapter requires more than one\nreading: you might like to reread this chapter once you have\nreached the end of the book.\n56\n\nProbability\nDevelopment of the language of probability blossomed in the 17th\ncentury. Mathematicians such as Blaise Pascal, Pierre de Fermat,\nChristiaan Huygens, Jacob Bernoulli, and later Pierre Simon\nLaplace, Abraham De Moivre, Siméon-Denis Poisson, Antoine\nCournot, John Venn, and others laid its foundations. By the early\n20th century, all the ideas for a solid science of probability were in\nplace, and in 1933 the Russian mathematician Andrei Kolmogorov\npresented a set of axioms which provided a complete formal\nmathematicalcalculusof probability. Since then, this axiom\nsystem has been almost universally adopted.\nKolmogorov’s axioms provide the machinery by which to\nmanipulate probabilities, but they are a mathematical\nconstruction. To use this construction to make statements about\nthe real world, it is necessary to say what the symbols in the\nmathematical machinery represent in that world. That is, we need\nto say what the mathematics ‘means’.\nThe probability calculus assigns numbers between 0 and 1 to\nuncertain events to represent the probability that they will\nhappen. A probability of 1 means that an event is certain (e.g. the\nprobability that, if someone looked through my study window\nwhile I was writing this book, they would have seen me seated at\nmy desk). A probability of 0 means that an event is impossible\n(e.g., the probability that someone will run a marathon in ten\nminutes). For an event thatcanhappen but is neither certain nor\nimpossible, a number between 0 and 1 represents its ‘probability’\nof happening.\nOne way of looking at this number is that it represents the\ndegree of beliefan individual has that the event will happen.\nNow, different people will have more or less information relating\nto whether the event will happen, so different people might be\nexpected to have different degrees of belief, that is different\nprobabilities for the event. For this reason, this view of probability\n57\n\nStatistics\nis calledsubjectiveorpersonalprobability: it depends on who is\nassessing the probability. It is also clear that someone’s probability\nmight change as more information becomes available. You might\nstart with a probability, a degree of belief, of 1/2 that a particular\ncoin will come up heads (based on your previous experience with\nother tossed coins), but after observing 100 consecutive heads and\nno tails appear you might become suspicious and change your\nsubjective probability that this coin will come up heads.\nTools have been developed to estimate individuals’ subjective\nprobabilities based on betting strategies, but, as with any\nmeasurement procedure, there are practical limitations on how\naccurately probabilities can be estimated.\nA different view of the probability of an event is that it is the\nproportion of times the event would happen if identical\ncircumstances were repeated an infinite number of times.\nThe fair coin tossing example above is an illustration. We have\nseen that, as the coin is tossed, so the proportion of heads gets\ncloser and closer to some specific value. This value is defined as\nthe probability that the coin will come up heads on any single toss.\nBecause of the role of frequencies, or counts, in defining this\ninterpretation of probability, it is called thefrequentist\ninterpretation.\nJust as with the subjective approach, there are practical\nlimitations preventing us from finding the exact frequentist\nprobability. Two tosses of a coin cannot really havecompletely\nidentical circumstances. Some molecules will have worn from the\ncoin in the first toss, air currents will differ, the coin will have been\nslightly warmed by contact with the fingers the first time. And in\nany case we have to stop tossing the coin sometime, so we cannot\nactually toss it an infinite number of times.\nThese two different interpretations of what is meant by probability\nhave different properties. The subjective approach can be used to\n58\n\nProbability\nassign a probability to a unique event, something about which it\nmakes no sense to contemplate an infinite, or even a large number\nof repetitions under identical circumstances. For example, it is\ndifficult to know what to make of the suggestion of an infinite\nsequence of identical attempts to assassinate the next president of\nthe USA, with some having one outcome and some another. So it\nseems difficult to apply the frequentist interpretation to such an\nevent. On the other hand, the subjective approach shifts\nprobability from being an objective property of the external world\n(like mass or length) to being a property of the interaction\nbetween the observer and the world. Subjective probability is, like\nbeauty, in the eye of the beholder. Some might feel that this is a\nweakness: it means that different people could draw different\nconclusions from the same analysis of the same data. Others\nmight regard it as a strength: the conclusions would have been\ninfluenced by your prior knowledge.\nThere are yet other interpretations of probability. The ‘classical’\napproach, for example, assumes that all events are composed of a\ncollection of equally likely elementary events. For example, a\nthrow of a die might produce a 1, 2, 3, 4, 5, or 6 and the symmetry\nof the die suggests these six outcomes are equally likely, so each\nhas a probability of 1/6 (they must sum to 1, since it iscertainthat\noneof1,2,3,4,5,or6willcomeup).Then,forexample,the\nprobability of getting an even number is the sum of the\nprobabilities of each of the equally likely events of getting a 2, a 4,\nor a 6, and is therefore equal to 1/2. In less artificial circumstances,\nhowever, there are difficulties in deciding what these ‘equally\nlikely’ events are. For example, if I want to know the probability\nthat my morning journey to work will take less than one hour, it is\nnot at all clear what the equally likely elementary events should\nbe. There is no obvious symmetry in the situation, analogous to\nthat of the die. Moreover, there is the problem of the circular\ncontent of the definition in requiring the elementary events to be\n‘equally likely’. We seem to be defining probability in terms of\nprobability.\n59\n\nStatistics\nIt is worth emphasizing here that all of these different\ninterpretations of probability conform to the same axioms and are\nmanipulated by the same mathematical machinery. It is simply the\nmapping to the real world which differs; the definition of what the\nmathematical objectmeans.I sometimes say that thecalculusis\nthe same, but thetheoryis different. In statistical applications,\nas we will see in Chapter 5, the different interpretations can\nsometimes lead to different conclusions being drawn.\nThe laws of chance\nWe have already noted one law of probability, the law of large\nnumbers. This is a law linking the mathematics of probability to\nempirical observations in the real world. Other laws of probability\nare implicit in the axioms of probability. Some very important laws\ninvolve the concept ofindependence.\nTwo events are said to be independent if the occurrence of one\ndoes not affect the probability that the other will occur. The fact\nthat a coin tossed with my left hand comes up tails rather than\nheads does not influence the outcome of a coin tossed with my\nright hand. These two coin tosses are independent. If the\nprobability is 1/2 that the coin in my left hand will come up heads,\nand the probability is 1/2 that the coin in my right hand will come\nup heads, then the probability that both will come up heads is\n1/2×1/2 = 1/4. This is easy to see since we would expect that in\nmany repetitions of the double tossing experiment we would\nobtain about half of the left hand coins showing heads, and,\namongst those, about half of the right hand coins would show\nheads because the outcome of the first toss does not influence the\nsecond. Overall, then, about 1/4 of the double tosses would show\ntwo heads. Similarly, about 1/4 would show left tails, right heads,\nabout 1/4 would show left heads, right tails, and about 1/4 would\nshow both left and right tails.\n60\n\nProbability\nIn contrast, the probability of falling over in the street is certainly\nnot independent of whether it has snowed; these events are\ndependent. We saw another example of dependent events in\nChapter 1: the tragic Sally Clark case of two cot deaths in the same\nfamily. When events are not independent, we cannot calculate the\nprobability that both will happen simply by multiplying together\ntheir separate probabilities. Indeed, this was the mistake which lay\nat the root of the Sally Clark case. To see this, let us take the most\nextreme situation of events which are completely dependent: that\nis, when the outcome of onecompletely determinesthe outcome of\nthe other. For example, consider a single toss of a coin, and the two\nevents ‘the coin faces heads up’ and ‘the coin faces tails down’.\nEach of these events has a probability of a half: the probability\nthat the coin will show heads up is 1/2, and the probability that\nthe coin will show tails down is 1/2. But they are clearly not\nindependent events. In fact, they are completely dependent. After\nall, if the first event is true (heads up) the secondmust betrue\n(tails down). Because they are completely dependent, the\nprobability that they will both occur is simply the probability that\nthe first will occur – a probability of a half. This is not what we get\nif we multiply the two separate probabilities of a half together.\nIn general, dependence between two events means that the\nprobability that one will occur depends on whether or not the\nother has occurred.\nStatisticians call the probability that two events willbothoccur the\njoint probabilityof those two events. For example, we can speak of\nthe joint probability that I will slip overandthat it snowed. The\njoint probability of two events is closely related to the probability\nthat an event will occurifanother one has occurred. This is called\ntheconditional probability– the probability that one event will\noccur given that we know that the other one has occurred. Thus\nwe can talk of the conditional probability that I will slip over,\ngiven thatit snowed.\n61\n\nStatistics\nThe (joint) probability that both events A and B occur is simply\nthe probability that A occurs times the (conditional) probability\nthat B occurs given that A occurs. The (joint) probability that it\nsnows and I slip over is the probability that it snows times the\n(conditional) probability that I slip over if it has snowed.\nTo illustrate, consider a single throw of a die, and two events.\nEvent A is that the number showing is divisible by 2, and Event B\nis that the number showing is divisible by 3. The joint probability\nof these two events A and B is the probability that I get a number\nwhich is both divisible by 2 and is divisible by 3. This is just 1/6,\nsince only one of the numbers 1, 2, 3, 4, 5, and 6 is divisible by\nboth 2 and 3. Now, the conditional probability of B given A is the\nprobability that I get a number which is divisible by 3amongst\nthose that are divisible by 2. Well, amongst all the numbers which\nare divisible by 2 (that is, amongst 2, 4, or 6) only one is divisible\nby 3, so this conditional probability is 1/3. Finally, the probability\nof event A is 1/2 (half of the numbers 1, 2, 3, 4, 5, and 6 are\ndivisible by 2). We therefore find that the probability of A (1/2)\ntimes the (conditional) probability of B given A (1/3) is 1/6. This is\nthe same as the joint probability of obtaining a number divisible\nby both 2 and 3; that is, the joint probability of events A and B\nboth occurring.\nIn fact, we previously met the concept of conditional probability in\nChapter 1, in the form of the Prosecutor’s Fallacy. This pointed out\nthat the probability of event A occurring given that event B had\noccurred was not the same as the probability of event B occurring\ngiven that event A had occurred. For example, the probability that\nsomeone who runs a major corporation can drive a car is not the\nsame as the probability that someone who can drive a car runs a\nmajor corporation. This leads us to another very important law of\nprobability:Bayes’s theorem(orBayes’s rule). Bayes’s theorem\nallows us to relate these two conditional probabilities, the\nconditional probability of A given B and the conditional\nprobability of B given A.\n62\n\nProbability\nWe have just seen that the probability that both events A and B\nwill occur is equal to the probability that A will occur, times the\n(conditional) probability that B will occur given that A has\noccurred. But this can also be written the other way round: the\nprobability that both events A and B will occur is also equal to the\nprobability that B will occur times the probability that A will occur\ngiven that B has occurred. All Bayes’s theorem says (though it is\nusually expressed in a different way) is that these are simply two\nalternative ways of writing the joint probability of A and B. That\nis, the probability of A times the probability of B given A is equal\nto the probability of B times the probability of A given B. Both are\nequal to the joint probability of A and B. In our ‘car-driving\ncorporate head’ example, Bayes’s theorem is equivalent to saying\nthat the probability of running a major corporation given that you\ncan drive a car, times the probability that you can drive a car, is\nequal to the probability that you can drive a car given that you are\na corporate head, times the probability of being a corporate head.\nBoth equal the joint probability of being a corporate headand\nbeing able to drive a car.\nAnother law of probability says that if either one of two\nevents can occur, but not both together, then the probability\nthat oneorthe other will occur is the sum of the separate\nprobabilities that each will occur. If I toss a coin, which obviously\ncannot show heads and tails simultaneously, then the probability\nthat a headortail will show is the sum of the probability that a\nhead will show and the probability that a tail will show. If the coin\nis fair, each of these separate probabilities is a half, so that the\noverall probability of a head or a tail is 1. This makes sense: 1\ncorresponds to certainty and it is certain that a head or a tail must\nshow (I am assuming the coin cannot end up on its edge!).\nReturning to our die-throwing example: the probability of getting\nan even number was the sum of the probabilities of getting one of\n2, or 4, or 6, because none of these can occur together (and there\nare no other ways of getting an even number on a single throw of\nthe die).\n63\n\nStatistics\nRandom variables and their distributions\nWe saw, in Chapter 2, how simple summary statistics may be used\nto extract information from a large collection of values of some\nvariable, condensing the collection down so that a distribution of\nvalues could be easily understood. Now, any real data set is limited\nin length – it can contain only a finite number of values. This finite\nset might be the values ofallobjects of the type we are considering\n(e.g. the scores of all major league football players in a certain\nyear) or it might be the values of just some, asample,ofthe\nobjects. We saw examples of this when we looked at survey\nsampling.\nA sample is a subset of the complete ‘population’ of values. In\nsome cases, the complete population is ill-defined, and possibly\nhuge or even infinite, so we have no choice but to work with a\nsample. For example, in experiments to measure the speed of light,\neach time I take a measurement I expect to get a slightly different\nvalue, simply due to the inaccuracies of the measurement process.\nAnd I could, at least in principle, go on taking measurements for\never; that is, the potential population of measurements is infinite.\nSince this is impossible, I must be content with a finite sample of\nmeasurements. Each of these measurements will be drawn from\nthe population of values I could possibly have obtained. In other\ncases, the complete population is finite. For example, in a study of\nobesity amongst males in a certain town, the population is finite\nand, while in principle I might be able to weigh every man in the\ntown, in practice I would probably not want to, and would work\nwith a sample. Once again, each value in my sample is drawn from\nthe population of possible values.\nIn both of these examples, all I know before I take each\nmeasurement is that it will have some value from the population\nof possible values. Each value will occur with some probability, but\nI cannot pin it down more than that, and I may not know what\nthat probability is. I certainly cannot say exactly what value I will\n64\n\nProbability\nget in the next speed of light measurement or what will be the\nweight of the next man I measure. Similarly, in a throw of a die, I\nknow that the outcome can be 1, 2, 3, 4, 5, or 6, and here I know\nthat these are equally likely (my die is a perfect cube), but beyond\nthat I cannot say which will come up. Like the speed and weight\nmeasurements, the outcome is random. For this reason such\nvariables are calledrandom variables.\nWe have already met the concept of quantiles. For example, in the\ncase of percentiles, the 20thpercentile of a distribution is the\nvalue such that 20% of the data values are smaller, the 8th\npercentile the value such that 8% of the data values are smaller,\nand so on. In general, thekth percentile hask%ofthesample\nvalues smaller than it. And we can imagine similar percentiles\ndefined, not merely for the sample we have observed, but for the\ncomplete population of values we could have observed. If we knew\nthe 20thpercentile for the complete population of values, then we\nwould know that a value randomly taken from that population had\na probability of 0.20 of being smaller than this percentile. In\ngeneral, if we knewallthe percentiles of a population, we would\nknow the probability of drawing a value in the bottom 10%, or\n25%, or 16%, or 98%, or any other percentage we cared to choose.\nIn a sense, then, we would know everything about the distribution\nof possible values which we could draw. We would not know what\nvalue would be drawn next, but we would know the probability\nthat it would be in the smallest 1% of the values in the population,\nin the smallest 2%, and so on.\nThere is a name for the complete set of quantiles of a distribution.\nIt is called thecumulative probability distribution.Itisa\n‘probability distribution’ because it tells us theprobabilityof\ndrawing a value lower than any value we care to choose. And it is\n‘cumulative’ because, obviously, the probability of drawing a value\nless than some valuexgets larger the largerxis. In the example of\nthe weights of males, if I know that the probability of choosing\na man weighing less than 70kg is 1/2, then I know that the\n65\n\nStatistics\nprobability of choosing a man weighing less than 80kg is more\nthan 1/2 because I can choose from all those weighing less than\n70kg as well as those weighing between 70kg and 80kg. At the\nlimit, the probability of drawing a value less than or equal to the\nlargest value in the population is 1; it is a certain event.\nThis idea is illustrated in Figure 2. In this figure, the values of the\nrandom variable (think of weight) are plotted on the horizontal\naxis, and the probability of drawing smaller values is plotted on\nthe vertical axis. The curve shows, for any given value of the\nrandom variable, the probability that a randomly chosen value will\nbe smaller than this given value.\nThe cumulative probability distribution of a random variable tells\nus the probability that a randomly chosen value will belessthan\nany given value. An alternative way to look at things is to look at\nthe probability that a randomly chosen value will liebetweenany\ntwo given values. Such probabilities are conveniently represented\nin terms of areas between two values under a curve of thedensity\np\nx\nValue of random variable\nProbability\n2. A cumulative probability distribution\n66\n\nProbability\nValue of random variable\nab\nProbability density\n3. A probability density function\nof the probability. For example, Figure 3, shows such aprobability\ndensitycurve, with the (shaded) area under the curve between\npointsaandbgiving the probability that a randomly chosen value\nwill fall betweenaandb. Using such a curve for the distribution\nof weights of men in our town, for example, we could find the\nprobability that a randomly chosen man would lie between 70kg\nand 80kg, or any other pair of values, or above or below any value\nwe wanted. In general, randomly chosen values are more likely to\noccur in regions where the probability is most dense; that is,\nwhere the probability density curve is highest.\nNote that the total area under the curve in Figure 3 must be 1,\ncorresponding to certainty: a randomly chosen value must have\nsomevalue.\nDistribution curves for random variables have various shapes. The\nprobability that a randomly chosen woman will have a weight\nbetween 70kg and 80kg will typically not be the same as the\nprobability that a randomly chosen man will have a weight\n67\n\nStatistics\nbetween these two values. We might expect the curve of the\ndistribution of women’s weights to take larger values at smaller\nweights than does the men’s curve.\nCertain shapes have particular importance. There are various\nreasons for this. In some cases, the particular shapes, or very close\napproximations to them, arise in natural phenomena. In other\ncases, the distributions arise as consequences of the laws of\nprobability.\nPerhaps the simplest of all distributions is theBernoulli\ndistribution. This can take only two values, one with probabilityp,\nsay, and the other with probability 1−p. Since it can take only two\nvalues, it iscertainthat one or the other value will come up, so the\nprobabilities of these two outcomes have to sum to 1. We have\nalready seen examples illustrating why this distribution is useful:\nsituations with only two outcomes are very common – the coin\ntoss, with outcomes head or tail, and births, with outcomes male\nor female. In these two cases,phad the value 1/2 or nearly 1/2.\nBut a huge number of other situations arise in which there are\nonly two possible outcomes: yes/no, good/bad, default or not,\nbreak or not, stop/go, and so on.\nThebinomial distributionextends the Bernoulli distribution. If\nwe toss a coin three times, then we may obtain no, one, two, or\nthree heads. If we have three operators in a call centre, responding\nindependently to calls as they come in, then none, one, two, or all\nthree may be busy at any particular moment. The binomial\ndistribution tells us the probability that we will obtain each of\nthosenumbers,0,1,2,or3.Ofcourse,itappliesmoregenerally,\nnot just to the total from three events. If we toss a coin 100 times,\nthen the binomial distribution also tells us the probabilities that\nwewillobtaineachof0,1,2,...,100heads.\nEmails arrive at my computer at random. On average, during a\nworking morning, about (say) five an hour arrive, but the number\n68\n\nProbability\narriving in each hour can deviate from this very substantially:\nsometimes ten arrive, occasionally none do. ThePoisson\ndistributioncan be used to describe the probability distribution of\nthe number of emails arriving in each hour. It can tell us the\nprobability (if emails arrive independently and the overall rate at\nwhich they arrive is constant) that none will arrive, that one will,\nthat two will, and so on. This differs from the binomial\ndistribution because, at least in principle, there is no upper limit\non the number which could arrive in any hour. With the 100 coin\ntosses, we could not observe more than 100 heads, but I could\n(on a very bad day!) receive more than 100 emails in one hour.\nSo far, all the probability distributions I have described are for\ndiscreterandom variables. That is, the random variables can take\nonly certain values (two values in the Bernoulli case, counts up to\nthe number of coin tosses/operators in the binomial case, the\nintegers0,1,2,3,...inthePoisson case). Other random variables\narecontinuous, and can take any value from some range. Height,\nfor example, can (subject to the accuracy of the measuring\ninstrument) take any value within a certain range, and is not\nrestricted to, for example, 4\n\u0002\n,5\n\u0002\n,or6\n\u0002\n.\nIf a random variable can take values only within some finite\ninterval (e.g. between 0 and 1) and if it isequally likelythat it will\ntake any of the values in that interval, then it is said to follow a\nuniform distribution. For example, if the postman always arrives\nbetween 10am and 11am, but in a totally unpredictable way (he is\nas likely to arrive between 10:05 and 10:10 as in any other five\nminute interval, for example), the distribution of his arrival time\nwithin this interval would be uniform.\nSome random variables can take any positive value; perhaps, for\nexample, the time duration of some phenomenon. As an\nillustration, consider how long glass vases survive before getting\nbroken. Glass vases do not age, so it is no more likely that a\nparticular favourite vase will be broken in the next year, if it is\n69\n\nStatistics\n80 years old, than that it will be broken in the next year, if it is only\n10 years old (all other things being equal). Contrast this with the\nprobability that an 80-year-old human will die next year\ncompared with the probability that a 10-year-old human will die\nnext year. For a glass vase, if it has not been smashed by timet,\nthen the probability that it will be smashed in the next instant is\nthe same, whatever the value oft(again, all other things being\nequal). Lifetimes of glass vases are said to follow anexponential\ndistribution. In fact, there are huge numbers of applications\nof exponential distributions, not merely to the lifetimes of\nglass vases!\nPerhaps the most famous of continuous distributions is the\nnormalorGaussian distribution. It is often loosely described in\nterms of its general shape: ‘bell-shaped’, as shown in Figure 4.\n4. The normal distribution\n70\n\nProbability\nThat means that values in the middle are much more likely to\noccur than are values in the tails, far from the middle. The normal\ndistribution provides a good approximation to many naturally\noccurring distributions. For example, the distribution of the\nheights of a random sample of adult men follows a roughly normal\ndistribution.\nThe normal distribution also often crops up as a good model for\nthe shape of the distribution of sample statistics (like the summary\nstatistics described in Chapter 2) when large samples are involved.\nFor example, suppose we repeatedly took random samples from\nsome distribution, and calculated the means of each of these\nsamples. Since each sample is different, we would expect each\nmean to be different. That is, we would have a distribution of\nmeans. If each sample is large enough, it turns out that this\ndistribution of the means is roughly normal.\nIn Chapter 2, I made the point that statistics was not simply a\ncollection of isolated tools, but was a connected language. A\nsimilar point applies to probability distributions. Although I have\nintroduced them individually above, the fact is that the Bernoulli\ndistribution can be seen as a special case of the binomial\ndistribution (it is the binomial distribution when there are only\ntwo possible outcomes). Likewise, although the mathematics\nshowing this is beyond this book, the Poisson distribution is an\nextreme case of the binomial distribution, the Poisson distribution\nand exponential distribution form a natural pair, the binomial\ndistribution becomes more and more similar to the normal\ndistribution the larger the maximum number of events, and so on.\nThey are really all part of an integrated mathematical whole.\nI have described the distributions above by saying that they have\ndifferent shapes. In fact, these shapes can be conveniently\ndescribed. We saw that the Bernoulli distribution was\ncharacterized by a valuep. This told us the probability that we\nwould get a certain outcome. Different values ofpcorrespond to\n71\n\nStatistics\ndifferent Bernoulli distributions. We might model the outcome of\na coin toss by a Bernoulli distribution with probability of heads,p,\nequal to a half, and model the probability of a car crash on a single\njourney by a Bernoulli distribution withpequal to some very\nsmall value (I hope!). In such a situation,pis called aparameter.\nOther distributions are also characterized by parameters, serving\nthe same role of telling us exactly which member of a family of\ndistributions we are talking about. To see how, let us take a step\nback and recall the law of large numbers. This says that if we make\nrepeated independent observations of an event which has outcome\nA with probabilitypand outcome B with probability 1−p,then\nwe should expect the proportion of times outcome A is observed to\nget closer and closer topthe more observations we make. This\nproperty generalizes in important ways. In particular, suppose\nthat, instead of observing an event which had only two possible\noutcomes, we observed an event which could take any value from a\ndistribution on a range of values; perhaps any value in the interval\n[0,1], for example. Suppose that we repeatedly took sets ofn\nmeasurements from such a distribution. Then the law of large\nnumbers also tells us that we should expect the mean of then\nmeasurements to get closer to some fixed value, the largernis.\nIndeed, we can picture increasingnwithout limit, and in that case\nit makes sense to talk about the mean of an unlimited sample\ndrawn from the distribution – and even the mean of the\ndistribution itself. For example, using this idea we can talk about\nnot simply the mean of ‘a sample drawn from an exponential\ndistribution’, but the mean of the exponential distribution itself.\nAnd, just as different Bernoulli distributions will have different\nparametersp, so different exponential distributions will have\ndifferent means. The mean, then, is a parameter for the\nexponential distribution.\nIn an earlier example, we saw that the exponential distribution\nwas a reasonable model for the ‘lifetimes’ of glass vases (under\ncertain circumstances). Now we can imagine that we have two\n72\n\nProbability\npopulations of such vases: one consisting of solid vases made of\nvery thick glass, and the other consisting of delicate vases made\nof wafer-thin glass. Clearly, on average, glasses from the former\npopulation are likely to survive longer than those from the latter\npopulation. The two populations have different parameters.\nWe can define parameters for other distributions in a similar way:\nwe imagine calculating the summary statistics for samples of\ninfinite size drawn from the distributions. For example, we could\nimagine calculating the means of infinitely large samples drawn\nfrom members of the normal family of distributions. Things are a\nlittle more complicated here, however, because the members of\nthis family of distributions are not uniquely identified by a single\nparameter. They require two parameters. In fact, the mean and\nstandard deviation of the distributions will do. Together they serve\nto uniquely identify which member of the family we are talking\nabout.\nThe law of large numbers has been refined even further. Imagine\ndrawing many sets of values from some distribution, each set\nbeing of sizen. For each set calculate its mean. Then the calculated\nmeans themselves are a sample from a distribution – the\ndistribution of possible values for the mean of a sample of sizen.\nTheCentral Limit Theoremthen tells us that the distribution of\nthese means itself approximately follows a normal distribution,\nand that the approximation gets better and better the larger the\nvalue ofn. In fact, more than this, it also tells us that the mean of\nthis distribution of means is identical to the mean of the overall\npopulation of values, and that the variance of the distribution of\nmeans is only 1/ntimes the size of the variance of the distribution\nof the overall population. This turns out to be extremely useful in\nstatistics, because it implies that we can estimate a population\nmean as accurately as we like, just by taking a large enough sample\n(takingnlarge enough), with the Central Limit Theorem telling us\nhow large a sample we must take to achieve a high probability of\nbeing that accurate. More generally, the principle that we can get\n73\n\nStatistics\nbetter and better estimates by taking larger samples is an\nimmensely powerful one. We already saw one way that this idea is\nused in practice when we looked at survey sampling in Chapter 3.\nHere is another example. In astronomy, distant objects are very\nfaint, and observations are complicated by random fluctuations\nin the signals. However, if we take many pictures of the same\nobject and superimpose them, it is as if we are averaging many\nmeasurements of the same thing, each measurement drawn from\nthe same distribution but with some extra random component.\nThe laws of probability outlined above mean that the randomness\nis averaged away, leaving a clear view of the underlying signal – the\nastronomical object.\n74\n\nChapter 5\nEstimation and inference\nStatistics is applied philosophy of science.\nA. P. Dawid\nIn Chapter 1, we saw that statistics served the dual roles of\nsummarizing data and making inferences from data. We explored\nsome simple tools for summarizing data in Chapter 2. In this\nchapter, using the concepts of probability covered in Chapter 4, we\nlook at estimation and inference. That is, we look at methods for\ndetermining the value of quantities we cannot actually observe,\nand making statements about them. Here are some examples.\nExample 1:To determine the speed of light, we will carry out some\nmeasurement procedure. Now, no measurement procedure is\nperfect, and if we were to repeat the exercise we would probably\nobtain a slightly different value. Repeating the measurement\n100 times is likely to give us 100 slightly different values. Our aim,\nthen, is to use this sample of values to estimate the true speed of\nlight, untarnished by measurement error.\nExample 2:In a simple randomized clinical trial, we might give a\nnew drug to one sample of patients and a standard drug to\nanother sample. Based on observations of the effects in these two\npatient groups we will want to make some statement, or inference,\nabout the relative effectiveness of the new drug. Put another way,\n75\n\nStatistics\nwe would want to estimate how large a difference in the\neffectiveness of the two drugs we might expect if we prescribed\neach of the drugs to the general population of patients. We would\nalso ideally like some indication of how confident we were in the\nsize of the estimate.\nExample 3:In studying unemployment in London, it would be\ninfeasible to interview everyone, so a sample of people would be\ninterviewed, with the aim of using the responses from this sample\nto make some general statement about the whole of London.\nThat is, using the sample data, we would like to estimate\nunemployment in the whole of London.\nExample 4:More abstractly, in Chapter 4 I introduced the notion\nof a ‘parameter’ of a distribution. We saw the example of the\nBernoulli family of distributions, where a random variable could\ntake values 0 or 1, and wherepwas a parameter giving the\nprobability of observing a 1. We also saw the example of a normal\ndistribution, which had two parameters, its mean and standard\ndeviation. Our aim might be to estimate the value of such a\nparameter. For example, an anthropologist might be studying the\nheights of a particular group of people. She might be prepared\nto assume that the heights were normally distributed, but to\ncharacterize the distribution fully she will need to know the mean\nand standard deviation of this distribution. She would like to use\nthe heights of a sample of people from the group to estimate the\nmean and standard deviation of the entire population.\nPoint estimation\nA friend offers me the following deal. He will repeatedly toss a\ncoin, and whenever it comes up heads he will give me £10, but\nwhenever it comes up tails I will give him £5.\nAt first glance, this looks like a good deal for me. After all, it is well\nknown that coins are equally likely to come up heads and tails\n76\n\nEstimation and inference\n(probability of heads equals 1/2), so I am just as likely to win £10\nas lose £5 on each toss. On average, I will be a winner.\nBut then I become suspicious. Why would he be offering me a deal\nwhich appears to be so much in my favour? I begin to suspect that\nperhaps the coin has been tampered with, so that the probability\nthat it will show heads is in fact less than a half. After all, if the\nprobability of it showing heads is really very small, so that it rarely\ncomes up heads, the deal could be a poor one for me. To sort this\nout, what I would like is an estimate of this probability. My friend,\nwho is very obliging but knows no statistics, offers to flip the coin\nsix times, so I can see how it falls on each of those times. My aim,\nthen, is to use these data to estimate the probability that the coin\nwill come up heads in future tosses.\nSuppose that the coinhadbeen tampered with, and that the\nprobability of it showing heads on any one toss was only 1/3. Since\ntosses of the coin are independent (the outcome of one toss does\nnot affect the outcome on any other), we know that the probability\nof getting heads in two tosses is simply the product of the\nprobability of getting heads on each toss: 1/3×1/3 = 1/9.\nSimilarly, since the probability of a tail is 1−1/3=2/3,the\nprobability of getting a head followed by a tail would be the\nproduct of 1/3 and 2/3, that is 2/9. In general, assuming that the\nprobability of getting a head on each toss is 1/3, we can calculate\nthe probability of getting any sequence of heads and tails – and, in\nparticular, a sequence identical to that observed in the six tosses\nwe actually saw. For example, if the six tosses showed HTHTTT,\nthe probability of obtaining an identical sequence by chance\nwould be 1/3×2/3×1/3×2/3×2/3×2/3 = 16/729, which is\napproximately 0.022.\nIn the same way, we can calculate the probability of getting the\nHTHTTT sequence if the probability of heads on each toss really\nhad any other value. For example, if the probability of heads is 1/2\n(so the probability of tails is 1−1/2 = 1/2), the probability of\n77\n\nStatistics\nobtaining such a sequence is 1/2×1/2×1/2×1/2×1/2×1/2 =\n1/64, which is approximately 0.016. And if the probability of heads\nis 1/10, the probability of obtaining such a sequence is\napproximately 0.007. And so on.\nNow, our aim is to estimate the probability that the coin will come\nup heads in any future toss. That is, we want to pick a single\nvalue – 1/3 or 1/2 or 1/10, or whatever – as an estimate of this\nprobability. Looking at the calculations above, we see that the\nprobability of obtaining the observed outcome for the six tosses is\n0.022 if the true probability of heads is 1/3, whereas it is only\n0.016 if the true probability of heads is really 1/2, and it is lower\nstill, only 0.007 if the true probability of heads is really 1/10. What\nthis means is that we are more likely to get the observed six tosses\nif the true probability is 1/3 than if it is 1/2 or 1/10. It thus seems\nsensible to pick the value of 1/3 as our single estimate of the\nprobability that heads will show. This is the value most likely to\nyield the data we actually obtained.\nThis example illustrates themaximum likelihoodapproach to\nestimation: we choose that value of the parameter which has the\nhighest probability of yielding the observed data. In the example,\nI only calculated this probability for three values of the probability\nof heads coming up (1/3, 1/2, 1/10), but in principle we could\ncalculate it for all possible values. The function showing the\nprobability of the observed data for each possible choice of the\nprobability of heads is called thelikelihood function. This function\nplays a central role in statistical inference.\nThe same sort of principle can be applied to obtain estimates of\nthe parameters of the normal distribution, or any other\ndistribution. For different choices for the possible values of the\nparameter, we simply calculate what would be the probability of\nobtaining a data set like that actually obtained. Then the\nmaximum likelihood estimator is that parameter value which\nyields the greatest probability. Note that this procedure yields a\n78\n\nEstimation and inference\nsingle value, an estimate which is best in the maximum likelihood\nsense. Because it is just a single value, it is called apoint\nestimate.\nAn alternative way of thinking about this approach to estimation\nis to regard the likelihood function as a measure of agreement\nbetween the observed data (our sequence of six coin toss results)\nand what our theory predicts (where ‘theory’ here means a\nsuggested value for the probability of being heads; for example,\n1/3 or 1/2). Choosing the theory (the probability of getting heads)\nto maximize agreement, or, equivalently, to minimize discrepancy,\nis clearly sensible. Thinking of it in this way allows us to\ngeneralize: we can consider other measures of discrepancy. For\nexample, in many situations a good measure of discrepancy is the\nsum of squared differences between the proposed parameter\nvalue and individual sample values. Choosing the parameter to\nminimize this measure means that a ‘best’ estimate is obtained, in\nthe sense of smallest sum-of-squared-differences. In fact, this is a\nvery common approach to estimation. It is called, for obvious\nreasons,least squares estimation.\nSometimes we might have ideas, before analysing the data, of the\nsort of value we expect the parameter to have. Such ideas might\nhave come from previous experience or earlier experiments. For\nexample, based on our previous experience in tossing coins, we\nmight believe that the parameterp, giving the probability that a\ntossed coin will show heads, is near to 1/2, and that it is very\nunlikely to be far from 1/2. We say that we have aprior\ndistributionof our belief that the unknown parameter takes\ndifferent values. This distribution represents a subjective belief\nabout the value of the parameter – as with the subjective\ninterpretation of probability discussed in Chapter 4. In such cases,\nrather than analysing the data in isolation to yield an estimate for\nthe value of the parameter, it makes sense to combine the data\nwith our prior belief to yield aposterior distributionof our beliefs\nabout the likely values of the parameter. That is, we start out with\n79\n\nStatistics\na distribution describing our beliefs about the possible values of\nthe parameter, and we adjust this according to what we observe in\nthe data. For example, our prior distribution for the probability\nthat a coin will come up heads might be heavily concentrated\naround the value of 1/2: we think it is highly likely to be near 1/2.\nHowever, if 100 coin tosses show heads only 3 out of the 100\ntimes, we might want to adjust that distribution, so that smaller\nvalues of the probability are regarded as more likely and values\nnear 1/2 less likely.\nIn fact, it is Bayes’s theorem, described in Chapter 4, which\nenables us to combine prior beliefs with observed data to give\nposterior beliefs. For this reason, this approach to estimation is\ntermed theBayesianapproach. Recall that Bayes’s theorem relates\ntwo conditional probabilities: the probability of A happening\ngiven that B has occurred, and the probability of B happening\ngiven that A has occurred. In the present case, we use the theorem\nto relate the probability that the parameter has some value, given\nthe data we observe, to the probability of observing such data,\ngiven a particular value of the parameter. Now, the second of\nthese, the probability of observing such data given a particular\nvalue of the parameter, is just the likelihood function. Bayes’s\ntheorem thus uses the likelihood of the data to adjust our prior\nbeliefs, to yield our posterior beliefs.\nNote that there is a subtle but important difference between this\napproach and the other approaches described above (often termed\nfrequentistorclassicalapproaches). There we assumed that the\nunknown parameter had some fixed but unknown value. For the\nBayesian approach, however, we have assumed that the unknown\nparameter has a distribution over a set of possible values, initially\ngiven by the prior distribution, and then, when updated by the\ninformation in the data, by the posterior distribution. The\nresearcher is acknowledging that the parameter could have\ndifferent values, and using the probability distribution to express\ntheir belief about each value.\n80\n\nEstimation and inference\nThe notion of a prior distribution is not without its controversial\naspects. At the very least, different people, with different\nbackground experience, might be expected to have different prior\ndistributions. These would be combined with the data to yield\ndifferent posterior distributions, and possibly different\nconclusions. Any pretence to objectivity has thus been sacrificed.\nThere is also a practical difficulty. While the mean of a normal\ndistribution and the parameterpin a Bernoulli distribution have\nclear and straightforward interpretations, it is not always the case\nthat the parameters of distributions have straightforward\ninterpretations. It can sometimes be very difficult coming up with\nsensible prior distributions reflecting our prior knowledge.\nAt this point in our description of the Bayesian approach we have\narrived at the posterior distribution, a distribution summarizing\nthe researcher’s belief that the parameter takes each value, after\nhaving seen the data. If we wish, we can reduce that entire\ndistribution to a single point estimate by using some summary\nstatistic of the distribution. For example, we could use its mean or\nits mode.\nWhich estimate is best?\nHow can we tell if a method of point estimation is effective, and\nwhich of several estimators is best? For example, while I might\nchoose to estimate the mean of a distribution using the mean of a\nsample drawn from that distribution, an alternative would be\nto drop the largest and smallest values of the sample before\ncalculating the mean. In general, the largest and smallest values\nhave greatest variability from sample to sample, so perhaps a more\nreliable and less variable estimate would result from dropping\nthem.\nFor the frequentist approach to estimation, which assumes that\nthere is some fixed, but unknown, true value for the parameter\nbeing estimated, we would ideally like to know which of these two\n81\n\nStatistics\napproaches yields an estimate closer to the true value.\nUnfortunately, since the true value is unknown (the whole point is\nto estimate it!), we can never know this. On the other hand, what\nwecanhope to know is how often we might expect the estimated\nvalue to be close to the true value if we were to repeat the exercise\nof taking a sample of measurements and calculating an estimate.\nAfter all, since the estimated value is based on a sample, it is likely\nthat the estimated value would be different if a different sample\nwas drawn. This means that the estimate is itself a random\nvariable, varying from sample to sample. As a random variable, it\nhas a distribution. If we know that this distribution is tightly\nclustered about the true value, we might regard the estimation\nmethod as a good one. Put another way, if we knew that a method\nusuallyyielded an estimate which was very near to the true value\nof a parameter, we might regard that as a good method of\nestimation. Whilst this tells us nothing about our particular case,\nwe would justifiably have confidence in the method. After all, if\nyou knew that 999 out of 1000 times someone made a correct\nprediction, you would surely be inclined to trust them in any\nparticular case. You do this with train drivers, pilots, restaurants,\netc: you know that the driver and pilot rarely crash, and the\nrestaurant rarely serves contaminated food, so you are happy to\ntake the risk thatthis timethings will be OK.\nUsing this principle, several different measures have been\ndeveloped to evaluate alternative frequentist estimation methods.\nOne such measure isbias. This tells us how large the difference is\nbetween the true value of a parameter and the mean value of the\ndistribution of estimated values. In particular, if this difference is\nzero (that is, if the mean of the distribution of estimated values is\nequal to the true value) then the estimator is said to beunbiased.\nFor example, the proportion of heads obtained when a coin is\ntossed several times is an unbiased estimator of the probability\nthat the coin will come up heads: the mean value of the\ndistribution of this proportion in repeated experiments is equal to\n82\n\nEstimation and inference\nthe true probability that it will come up heads. To illustrate,\nsuppose that, unknown to us, the true probability that a coin will\ncome up heads is 0.55. We toss a coin ten times, and estimate this\nprobability by the proportion of heads. Our ten tosses might yield\nsix heads; that is a proportion of 0.6. Or three heads; a proportion\nof 0.3. Or five heads; a proportion of 0.5. And so on. On average\n(averaged over imaginary repetitions of the ten tosses) the\nproportion will be 0.55 because the proportion of heads is an\nunbiased estimator of the probability that the coin will show\nheads.\nIn general, an estimator which has a large bias will not be\nregarded as favourably as one which is unbiased. On average, over\nrepetitions of the experiment, an estimator with large bias would\nyield a value very different from the truth.\nThemean squared erroris another measure of how good an\nestimator is. For any particular estimated value we could, if we\nknew the true parameter value, calculate the squared difference\n(the ‘squared error’) between the estimate and the true value.\nSquaring is useful, for one reason because it makes everything\npositive. Now, since the estimate itself is a random variable,\nvarying from sample to sample, so also is this squared error. As a\nrandom variable, it has a distribution. Themeansquared error is\nsimply the mean of this distribution. A small mean squared error\nmeans that, on average, the squared difference between the\nestimated value and the true value is small. An estimator which is\nknown to have a large mean squared error would not be regarded\nas favourably as one which had a small mean squared error: one\nwould not have much confidence that its value was near to the\ntruth.\nInterval estimation\nWhen we considered some basic summary statistics in Chapter 2,\nwe saw that it was all very well summarizing a sample of values by\n83\n\nStatistics\ntheir mean or some other single summary, but that this left a lot to\nbe desired. In particular, it failed to show how widely the sample\nvalues were spread about this mean. We tackled that problem by\nintroducing further summary statistics, such as the range and\nstandard deviation, which indicated how widely dispersed the\nsample values were.\nThe same sort of principle applies in estimation. So far we have\nlooked at point estimates, that is estimates which aresinglebest\nestimated values in some sense. An alternative is to give a range of\nvalues, aninterval, which we are confident includes the true value.\nLet us return to the £10/£5 deal offered by my friend. Previously\nwe sought the single best estimate for the probability that a toss of\nthe coin would produce heads. Instead, we could seek a range of\nvalues which we are confident will include the true probability.\nPerhaps we can be very confident that the true probability lies\nbetween 1/4 and 2/5, for example. This is an example of an\ninterval estimate.\nNow, since the true value is unknown, we cannot say for certain\nwhether any particular interval will actually include the true value.\nBut imagine repeating the exercise again and again with different\nrandom samples (just as we imagined when we defined bias\nabove). For each of these samples we could calculate an interval\nestimate. Then, if the intervals are constructed in the right way it\nispossible to say that a certain percentage of the intervals (e.g.\n95% or 99% or whatever we choose) would include the unknown\ntrue value.\nReturning to my friend’s coin, we cannot say for certain that any\nparticular interval, calculated for any particular data sample, will\ncontain the true probability that the coin will show heads. But we\ncan say that 95% (or whatever we choose) of such intervals will\ncontain the true probability. Since 95% of such intervals will\ncontain the true value, we can have considerable confidence that\nthe one interval we did calculate, based on the sample we actually\n84\n\nEstimation and inference\nobtained (HTHTTT in the example) would include the true value.\nFor this reason, such intervals are calledconfidence intervals.\nTurning to Bayesian methods, we saw that the outcome of a\nBayesian analysis is an entire posterior distribution of values. This\ndistribution tells us the strength of our belief that the parameter\nhas any particular value. We could leave things at that. For\nexample, if the distribution had a small standard deviation it\nwould mean we were very confident that the parameter value lay\nin a narrow range. But sometimes it is convenient to summarize\nthings in a way rather analogous to the confidence intervals above,\nand give an interval, defined by a largest and smallest value. For\nexample, we could find an interval which contained 95% of the\narea beneath the posterior probability distribution within it. Since\nthe distributions have the degree of belief interpretation, such\nintervals can be interpreted as giving the probability that the true\nvalue lies within them. To distinguish them from the frequentist\nconfidence intervals, such intervals are calledcredibility intervals.\nTesting\nStatisticians use the phraseshypothesis testingandsignificance\ntestingto describe the processes of exploring whether parameters\nin a model take specified values or lie in certain ranges. At its\nsimplest level, this might mean testing just a single parameter. For\nexample, we might know that 50% of patients suffering from a\nparticular disease recover under the standard treatment, and we\nmight conjecture that a proposed new drug treatment cures 80%\nof such patients. The single parameter we are interested in testing\nis the cure rate of the new treatment, and we would like to know if\nit is 80% rather than 50%.\nNow, it is a fact that people are different. They differ in terms of\nage, sex, fitness, severity of disease, weight, and a host of other\nthings. This means that, when even similar people are given the\nsame dose of the same drug, the responses differ: some may be\n85\n\nStatistics\ncured and some not. Indeed, it is entirely possible that the\nresponse will differ for the same patient at different times and\nunder different circumstances. A reasonable model for this\nsituation might be that a patient given a drug has a probabilityp\nof being cured. In our example, we know thatp=0.5 under the\nstandard treatment and we conjecture thatp=0.8 under the new\ntreatment.\nIn principle, at this point, to find what proportion are cured by\nthe new drug, what we would like to do is give the new drug to\neveryone in the patient population, under all possible\ncircumstances, and see what proportion are cured. This is clearly\nimpossible, and what we have to do is give the drug to just a\nsample of patients. We can then calculate the proportion cured in\nthe sample. Unfortunately, since we are merely working with a\nsample, and not the entire population, the mere fact that, say,\n80% of the sample is cured, or 60%, or 90%, or whatever, does not\nnecessarily mean that that proportion would be cured in the\npopulation. If we drew a different sample, we would be likely to\nobtain a different result.\nHowever, a sample drawn from a population in which, overall,\nonly 50% of the patients are cured will usually have a lower\nproportion cured than a sample drawn from a population in which\n80% of the patients are cured.\nThis means that we can adopt a threshold,tsay, such that if we\nobserve the proportion cured in the sample to be less thantwe\nwill favour the 50% hypothesis, and if we observe a sample\nproportion cured to be greater thantwe will favour the 80%\nhypothesis. In the latter case, we say that the sample statistic lies\nin therejectionorcritical region,sincethecurerateofthe\nstandard treatment, 50%, has been ‘rejected’.\nIn doing this, we risk making one of two kinds of mistake. We\nmight decide that the new drug cures 80% of the patients in the\n86\n\nEstimation and inference\noverall population when in truth it cures only 50%. Or we might\ndecide that the new drug cures 50% of the patients in the\noverall population when in fact it cures 80%. The so-called\nNeyman-Pearsonhypothesis testing approach arranges things so\nthat the probability of making each of these two kinds of errors is\nknown, and is sufficiently small to give us confidence in the\nconclusions.\nHere is how it works. We begin by making a working assumption:\nlet us assume that the new drug cures only 50% of patients. This\nworking assumption is called thenull hypothesis. The so-called\nalternative hypothesisis that the new drug cures 80% of the\npatients. Using basic probability calculations we can work out\nwhat proportion of samples would show a cure rate, by chance,\ngreater than any chosent, if the 50% assumption (the null\nhypothesis) were true. Typically,tis chosen so that, if the null\nhypothesis were true, only 5% or 1% of the time would the sample\nproportion cured exceedt.\nIn this situation, when the null hypothesis is true (i.e. if only 50%\nof the overall population would be cured) and we actually\nobtained a sample cure proportion greater thant, leading us to\ndecide in favour of the overall 80% cure rate, we would be making\nthe first kind of error noted above (which is conventionally called\naType I error). The symbol\n·is typically used to represent the\nprobability of a Type I error. Our choice oftin the example means\nthat we have fixed\n·at 0.05, or 0.01, or whatever value we chose.\nIf we observe a sample cure proportion greater thant, then either\nthe null hypothesis is true (true rate of 50%) and an event of low\nprobability (sample rate higher thant, occurring with probability\n·) has occurred, or the null hypothesis is incorrect. These are the\nonly possibilities. This is the essence of the Neyman-Pearson\napproach to hypothesis testing. By choosingtso that\n·is small\nenough (and 0.05 and 0.01 are generally thought of as small\nenough), we feel reasonably confident in suggesting that the null\n87\n\nStatistics\nhypothesis is not true because, if it was, an unlikely event would\nhave occurred.\nThe other kind of error (Type II, naturally) arises when the\nalternative hypothesis is true (the 80% one in the example) but the\nobserved sample cure proportion is less thant. Since we chosetto\ncontrol the probability of making a Type I error, we cannot choose\ntalso to control the probability of making a Type II error.\nHowever, we can make the probability of a Type II error as small\nas we like by taking a large enough sample. This is again a\nconsequence of the law of large numbers. Increasing the sample\nsize decreases the range of variability of the sample estimate, and\nhence decreases the probability that the sample estimate will be\nbelowtwhen the true population value is the higher, 80% value.\nIn particular, by making the sample large enough we can reduce\nthe probability of a Type II error to whatever value we think\nappropriate. The symbol‚is typically used to represent the\nprobability of a Type II error. The termpoweris used to represent\n1−‚, the probability of choosing the alternative hypothesis when\nit is true.\nThe hypothesis testing situation described above is analogous to\nthe situation in a court of law, where the accused is initially\npresumed innocent (null hypothesis), and where two kinds of\nmistakes can arise: an innocent person is found guilty (Type I) or a\nguilty person is found innocent (Type II).\nNote that two hypotheses are involved in Neyman-Pearson\nhypothesis testing: the null hypothesis and the alternative\nhypothesis. Insignificance testing, only the null hypothesis is\nconsidered. The aim is to ‘reject’ the null hypothesis if a value of\nsome test statistic (the sample proportion cured in the example\nabove) is sufficiently different from what would be expected under\nthe null hypothesis, or ‘fail to reject’ it if the value is not so\nextreme. No alternative hypothesis is explicitly mentioned. The\ntermp-valueis used to describe the probability that we would\n88\n\nEstimation and inference\nobserve a value of the test statistic as extreme or more extreme\nthan that actually observed, if the null hypothesis were true.\nThe ideas of hypothesis and significance testing have been\ndeveloped for a huge variety of problems. Particular tests have\nbeen developed often named after one of the original developers\n(e.g. the Wald test, the Mann-Whitney test) or named after the\ndistribution of the test statistic involved (e.g. thet-test, the\nchi-squared test).\nIn principle, at least, Bayesian hypothesis testing is more\nstraightforward. Under the Bayesian formulation, we have\nposterior probabilities that each hypothesis is true, so we can use\nthese to choose a hypothesis. In practice, things are sometimes\nrather more complicated.\nDecision theory\nI informally described ‘testing’ as seeing if the parameters of a\nmodel took particular values or fell in certain ranges. This is a\ngood description of much of what goes in a scientific context: the\naim is to discover how things are. But in other contexts, such as\ncommerce or medicine for example, the aim is typically not simply\nto discover what values the parameters have, but to act on this\ninformation. We want to look at a patient, make a number of\nobservations and tests, and, using the resulting data, take the best\ncourse of action. ‘Best’ might mean many different things, but,\nspeaking abstractly, we will want to maximize gain, profit, or\n‘utility’, or, equivalently, to minimize cost or loss. If we can define a\nsuitable suchutility function, describing what the gain will be if\neach action is taken when the unknown truth takes each of its\npossible values, then we can compare differentdecision rules–\nthat is, different ways of choosing between actions. For example,\nwe might choose that decision rule which maximizes the\nminimum gain that could be incurred, whatever the unknown\ntruth. Alternatively, if we are working within a Bayesian\n89\n\nStatistics\nframework, and so have a posterior distribution of probabilities\nacross the unknown state of the truth, we could calculate the\naverage value of the gain for each decision rule, and choose that\nwhich had the largest average value.\nHere is an example. A company might want to know which course\nof action, sending a letter or making a phone call, is most effective\nin encouraging its customers to buy its latest product. Now, it\nwould be unrealistic to imagine that the same action would be\nmost effective for all kinds of customers. Some will respond better\nto the letter, some to the phone call, and we do not know which is\nwhich. But the company might have data about each customer:\nthe information they supplied when they first enrolled, the data\ndescribing their previous purchases, and so on. Using these data,\nwe can formulate decision rules which say things such as ‘if the\ncustomer is aged less than 25 and has a previous pattern of regular\npurchases then take action “phone call”; otherwise take action\n“letter”’. Many such potential decision rules could be formulated.\nFor each of the actions, phone call or letter, we could estimate the\ngain, perhaps even in monetary terms, if we took that action and\nthe customer turned out to be the type who did (or did not)\nrespond well to that action. And then we could choose the decision\nrule which made the minimum gain the largest. Or we could\naverage over the distribution of customers of each type, to yield an\naverage gain for each decision rule, and then choose that rule\nwhich led to the largest average gain.\nSo where are we now?\nOver the years, statistical inference has been the subject of\nconsiderable controversy, sometimes quite heated. Although\ndifferent approaches to inference do sometimes lead to different\nconclusions, experience shows that sensitive use by statisticians\nwho understand the methods they are using generally leads to\nsimilar conclusions. This is all part of the art of statistics and\nshows that carrying out a statistical analysis is not merely a\n90\n\nEstimation and inference\nmechanical exercise in mathematics. It requires understanding of\nthe data and their background, as well as a sound grasp of the\nunderlying inferential theory.\nDifferent schools of statistical inference place varying degrees of\nemphasis on a number of different principles. Examples of these\nprinciples are thelikelihood principle(if two different models\nhave the same likelihood function, then they should lead to the\nsame conclusions), therepeated sampling principle(statistical\nprocedures should be assessed based on how they would behave\n‘on average’ if they were applied to many repeated samples), and\nthesufficiency principle(concerned with summarizing data so\nthat information sufficient for estimating a parameter is retained).\nEach of these principles seems perfectly reasonable, but they may\nsometimes conflict.\nFor many years the classical frequentist methods were the most\nwidely used methods of inference, but Bayesian methods have\ngained considerably in popularity in recent years. This has been as\na direct consequence of the development of powerful computers\nand clever computing methods, as well as of enthusiastic\npromotion of such methods by their supporters. Science takes\nplace in a social context, and the human aspects of how different\nideas about inference have gained and waned in ascendancy over\nthe past few decades is a fascinating story.\nOne final point: as I hope has been made apparent in this chapter,\nthere are different aspects to inference. In particular, we may be\ninterested in trying to find answers to different kinds of questions.\nThese include: what do the data tell me, what should I believe,\nwhat should I do, and so on. Different approaches to inference are\nbest suited to different kinds of questions.\n91\n\nChapter 6\nStatistical models\nand methods\nThe best thing about being a statistician is that you get to play in\neveryone’s backyard.\nJohn W. Tukey\nStatistical models: putting the blocks together\nI have used the phrase ‘statistical model’ at various places in this\nbook without so far defining what I mean. A statistical model is\nsome simple representation or description of the thing or system\nbeing studied. A very simple model might involve just one aspect\nof nature. Indeed, we saw examples of this in Chapter 4 when we\nlooked at distributions of single variables. More generally,\nstatistical models can be very elaborate indeed, perhaps involving\nthousands of variables related in highly complicated ways.\nEconomists trying to guide the decisions of a national bank will\nuse such large models, for example.\nA basic perspective on models is to ask whether they properly\nrepresent the underlying reality: whether they are ‘true’ or not.\nIndeed, this is the perspective we took earlier in the book, when\nwe asked if a proposed parameter value was the true value.\nHowever, a more sophisticated perspective acknowledges that no\nmodel, statistical or otherwise, can take into account all of the\n92\n\nStatistical models and methods\npossible influences and relationships in the real world. It is this\nsort of perspective which has led the eminent statistician George\nBox to assert that ‘all models are wrong, some models are useful’.\nWe build models for a reason: to help us understand, predict,\ndecide, and so on. And while we recognize that our models\nrepresent a necessary simplification of the awesome complexity of\nthe world, if we choose them well then they will enable us to do\nthese things. But if we choose them badly, then we will not\nunderstand, our predictions will go awry, and our decisions will\nlead to mistakes. Our aim, then, is to construct models which are\ngood enough for our purpose.\nStatistical models may be conveniently divided into two types,\noften calledmechanisticandempiricalmodels. A mechanistic\nmodel is based on some solid underlying theory for how things are\nrelated. For example, a theory in physics might tell us how the\nspeed of falling objects increases with the time for which they\nfall. Or another theory might tell us how drugs will disperse\nthroughout the body. In both of these cases, the models will be\nbased on theories about how things actually work. Indeed, the\nmodels will be based on the mathematical equations describing\nthese theories, and the data we collect to evaluate our models will\nbe values of the variables used in the theories, such as speed and\ntime (in the falling object case) and concentration and time\n(in the drug diffusion case). Mechanistic models are thus direct\nmathematical ways of describing theories.\nIn contrast, empirical models are simply attempts to provide\nconvenient summaries for the important aspects of observed data.\nWe might have no theory which says that falling objects increase\ntheir speed as time passes, but we may observe a relationship\nbetween time and speed and, on the basis of this, conjecture some\nincreasing relationship. If there is no underlying theoretical basis\nfor this proposed relationship, the model would be an empirical\nmodel.\n93\n\nStatistics\nMechanistic models are widespread in the physical sciences\nand disciplines such as engineering. The social and behavioural\nsciences tend to make more use of empirical models. Having\nsaid that, obviously there is considerable overlap: the nature\nof the model will depend on what is being modelled and how\nwell it is understood. Economics, a particular social science,\nis full of mechanistic models based on theories about how\neconomic factors are related. In general, it is probably fair to say\nthat, in the initial stages of exploration of a phenomenon,\nempirical models are more common since regularities and\npatterns are being sought in the mass of observations. In later\nstages, when understanding has grown, so mechanistic models\nbecome more important. In any case, as our models for falling\nobjects show, a particular model can be constructed as empirical\nand then become mechanistic, as understanding of the\nphenomenon grows.\nSometimes it is useful to distinguish between the various\npossible uses of statistical models. One such distinction is\nbetweenexplorationandconfirmation. In exploration, we\nseek relationships or patterns. In confirmation, we aim to see\nif data support a proposed explanation. So, for example, in an\nexploratory study we might look for variables that are closely\nrelated. Perhaps one variable takes a high value whenever\nanotheronedoes,orperhapssetsofvariablestakevery\nsimilar values for different objects, and so on. In confirmatory\nstudies, on the other hand, we might use the data to estimate the\nparameters of a proposed statistical model and carry out a\nstatistical test to see if the estimate is close enough to what our\ntheory predicted. Statistical methods of data exploration have\nbecome increasingly important in recent years, with larger and\nlarger data sets accumulating. This is true for both scientific\napplications (e.g. particle physics and astronomy) and\ncommercial applications (e.g. databases containing details of\nsupermarket purchases, telephone calls, or internet click stream\ndata).\n94\n\nStatistical models and methods\nAnother important distinction in statistical modelling is between\ndescriptionandprediction. In describing a data set, the aim is to\nsummarize it in a convenient way. For example, if the data set\nconsists of observations of ten variables (height, weight, time to\ntravel to work, etc.) on each of a million people, then to begin\nto understand it we need to reduce it to a manageable size. For\nexample, we could summarize it in terms of the means and\nstandard deviations of each of the variables, as well as measures of\nhow closely they were related. Then we would have some hope of\nunderstanding what is going on since we would have described the\ngeneral properties of the data in a convenient way. Having said\nthat, as we saw in Chapter 2, such descriptive summaries are not\nwithout their risks. By definition, they simplify the immense\ncomplexity of the entire data set, so we must be alert for the\npossibility that our summary description has left out something\nimportant. For example, perhaps our model has failed to take\naccount of the fact that there are two distinct genetic groups in a\npopulation, so that a more elaborate model is needed to represent\nthis.\nIn prediction, our aim is to use some of the variables to predict\nvalues of others. For example, we might have a collection of data\nshowing details of childhood diet and their later adult height for a\nsample of people. Using this, we could construct a model relating\nadult height to childhood diet, and then use the model to predict\nthe likely future height of a child following a particular diet. Note\na fundamental aspect of the data needed for such modelling: we\nneed values for both the predictor variables and the predicted\nvariable from our sample. This will turn out to be a very important\ndistinction between predictive and descriptive models, as we will\nsee below.\nOnce again, the distinction is not always clear cut. We might\nsimply be concerned with describing the relationship between\nchildhood diet and adult height, with no intention to use the\nmodel to predict one from the other.\n95\n\nStatistics\nAnother important kind of prediction isforecasting.Hereweuse\ndata from the past to construct a model which can be used as the\nbasis for predicting likely values of observations yet to be made.\nFor example, we might look at the monthly pattern of sales of\ntelevision sets over the past five years and extrapolate the trend in\nsales and the seasonal variation to forecast the likely sales over the\nnext twelve months.\nStatistical models also have other uses. We briefly saw their role in\ndecision making in Chapter 5. We also saw in Chapter 5 how the\nparameters of distributions were estimated. This is done by\ndefining a measure of discrepancy between the observed data and\nthe theoretical distribution, and then choosing the estimated\nparameter value which minimizes the discrepancy measure. A\ncommon measure of discrepancy was derived from the likelihood,\nmeasuring how probable it was that data like the observed data\nwould arise if the parameters took various different values. Now,\nsince distributions are merely simple forms of model, exactly the\nsame principles apply when fitting more elaborate models (such as\nthose illustrated below). However, a curious phenomenon arises as\nthe models become more and more elaborate.\nI shall take a simple example to illustrate. Suppose we want to\nconstruct a model to predict initial salaries of graduates, based on\ndata describing their schooling, the subjects they studied at\nuniversity, their examination scores, and also factors such as age,\nsex, where they lived, and so on. Suppose we sample 100 new\ngraduates and collect the data from them. Now, in general, if we\ntry to base our prediction on very few variables (e.g. just age) then\nwe will not obtain very accurate predictions. Age, by itself, just\ndoes not contain enough information to allow us to say very\nprecisely what someone’s graduate salary will be. To improve the\npredictive accuracy we need to add more predictors (e.g. use age\nandsubject of studyandexam scores to predict graduate salary).\nHowever, and here comes the crunch, if we add too many\npredictor variables then the predictive accuracy for the population\n96\n\nStatistical models and methods\ndecreases. Even though we are making use of more information\nabout the graduates, our model is not as good.\nThis seems counterintuitive. How can addingmoreinformation\nlead toworsepredictions?\nThe answer is subtle, and goes under various names, including the\ngraphicoverfitting. To understand it, let us take a step back and\nsee what our real aim is. Our aim isnotto get the best predictions\nwe can for the 100 graduates in our sample: we already know their\ninitial salaries. Rather, it is to get the best predictions we can for\nothergraduates. That is, our aim is togeneralizefrom the sample\nwe have. Now, by adding more and more predictor variables we\nare certainly adding information which will enable us to predict\nmore and more accurately the salaries of those already in our\nsample. But the sample is only a sample: it does not fully represent\nthe salaries of the entire population of graduates. And, after a\nwhile, as we continue to add more predictor variables, so we start\nto predict aspects of the data which are peculiar to the sample.\nThey are not features which apply to the more general population.\nThis phenomenon applies to all statistical modelling: models can\nbe too complicated, so that they fit the observed data very well\nindeed but fail to generalize well to other objects drawn from the\nsame distribution. It means that it is necessary to develop\nstrategies for choosing models of the right complexity: too simple\nand we risk missing out on potential predictability, too complex\nand we risk overfitting. This principle underlies Occam’s razor,\nwhich states that ‘models should be no more complicated than is\nnecessary’ (attributed to the 14th-century Franciscan friar William\nof Occam).\nThe overfitting problem is particularly important in modern\nstatistics. Prior to the advent of the computer, and before it\nbecame commonplace to fit complicated models with very large\nnumbers of parameters, there was less risk of overfitting.\n97\n\nStatistics\nStatistical methods: statistics in action\nThe aim of this section is to outline some important classes of\nstatistical method, to show how they are related, and to illustrate\nthe sorts of problems they can be used to solve.\nLet us begin by noting that we are frequently interested in\nrelationships between pairs of variables. Does risk of heart attack\nincrease with body mass index? Is global warming a consequence\nof human activity? If unemployment goes up will inflation go\ndown? Will improving a car’s safety features increase its sales?\nAnd so on. If two variables are related in the sense that larger\nvalues of one tend to be associated with larger values of the other,\nthen the variables are said to bepositively correlated.Iflarger\nvalues of one tend to be associated with smaller values of the other,\nthey are said to benegatively correlated. Height and weight in\nhumans are positively correlated: taller people tend to be heavier.\nNote that the relationship is not an exact one: there are light tall\npeople (the thin ones) and heavy short people. But, on average,\noverall, tallness is associated with greater weight. We can also see\nfrom this example that just because two variables are correlated\ndoes not mean that one causes the other. Putting someone on a\ndiet of cream buns to increase their weight is unlikely to lead to an\nincrease in height, and putting them on a rack to stretch them is\nunlikely to increase their weight. In fact, confusion between\ncorrelation and causation has been the source of much\nmisunderstanding over the years. A random sample of children\naged between 5 and 16 years old is likely to show a marked positive\ncorrelation between ability to read and ability to do arithmetic.\nBut one is unlikely to cause the other. It is more likely that age is a\ncommon cause of each: the older children are better at both\nreading and arithmetic.\nA single number, acorrelation coefficient, can be used to represent\nthe strength of a correlation. There are various ways in which this\n98\n\nStatistical models and methods\nstrength may be measured, just as we saw that there were various\nways of defining ‘average’ and ‘dispersion’. In general, however,\ncorrelation coefficients are standardized to lie between−1and+1,\nwith 0 meaning no relationship, +1 meaning a perfect positive\ncorrelation, and−1 meaning a perfect negative correlation. A\n‘perfect’ correlation between two variablesxandymeans that if\nyou knowxthen you knowyexactly.\nCorrelation is a symmetric relationship: if height is correlated\nwith weight, then weight is correlated with height, and the\nstrength of this correlation is the same whichever way we look at\nit. In contrast, sometimes we are interested in asymmetric\nrelationships between variables. For example, we might want to\nknow how much weight difference, on average, is associated with a\nheight difference of ten centimetres. This sort of question is\nanswered by the statistical technique ofregression analysis.A\nregression model tells us what is the average value of a variabley\nfor each value of a variablex. In the example above, a ‘regression\nof weight on height’ would tell us the average weight that people of\neach height would take. This is illustrated in Figure 5, where\nweight is plotted on the vertical axis, and height on the horizontal\naxis. Each black dot shows the (weight, height) pair for a person\nfrom our sample. Now it is obvious from this figure that we do not\nhave observed values forallpossible heights. For example, there is\nno data point with a height of exactly 6\n\u0002\n. One way to overcome this\ndifficulty, to construct a model which gives us an average weight\nfor each value of height, is to suppose that there is a simple\nrelationship between height and average weight. A very simple\nsuch relationship is a straight line relationship; an example of\nsuch a line is shown in the figure. For any given height, this line\nallows us to look up the corresponding value of average weight. In\nparticular, for example, it gives us a value for the average weight of\npeople who are 6\n\u0002\ntall.\nThere are several points to make about this approach.\n99\n\nStatistics\nHeight\n5ft\n5ft 6in6ft 6in6ft\nWeight\n8st\n10st\n5. Fitting a line to data\nFirst, it gives theaverageweights at each height. This is\nreasonable: in real life, even people of the same height can weigh\ndifferent amounts.\nSecond, we need to find some way of determining exactly which\nline we are talking about. The figure shows one line, but how did\nwe choose that line rather than some other? Now, lines are\nuniquely specified by two parameters, their intercept (here, the\nvalue of weight at which the line meets the weight axis) and slope,\nso we need to find some way of choosing, or estimating, these two\nparameters. But we know about parameter estimation; we studied\nit in Chapter 5. To estimate parameters we choose those values\nwhich minimize some measure of discrepancy between the model\nand the observed data. For any particular (weight, height) pair in\nthe data, one measure of discrepancy is the squared difference\n(again, squared so as to make things positive) between the\nobserved weight and the predicted weight at that height. An\noverall discrepancy measure based on this is the sum of squared\ndifferences between the observed weights and the predicted\nweights at the heights given in the data. We then estimate the\n100\n\nStatistical models and methods\nintercept and slope by choosing those values which minimize this\nsum of squared differences. In the sense that it minimizes the\n(sum of squared) differences between the observed and predicted\nvalues of weight in the data, thisleast squares regression lineyields\nthe best prediction of average weight for any value of height we\nmight care to choose.\nThe third point is that that the assumption of a straight line\nrelationship might seem fairly arbitrary, adopted with little\njustification. Why choose a straight line, rather than a curved line?\nWithout going into the details here, it is possible to introduce\ncurvature of various degrees so that the line showing the\nrelationship between height and average weight can have more\ncomplicated shapes – perhaps increasing more rapidly at lower\nheights than at higher heights, for example. We do this by making\nthe model more complicated, by introducing extra parameters, in\naddition to the intercept and slope.\nThe height/weight regression example sought to predict average\nweight from only one predictor variable, height. We could also\ninclude other potential predictors, in order to yield more accurate\npredictions. For example, men and women have different body\nshapes, so that, for a given height, some of the difference in\nweights may well be due to gender. We might therefore also\ninclude gender as a predictor. We could continue this, including\nother variables we thought likely to be related to weight. We\nshould not go too far if we have observations on only a fixed\nnumber of people, or once again our model will overfit the data.\nWe therefore might not want to include all of the variables we can\nthink of, but simply include a subset of them.\nIn general, there are also other reasons why we might want to\ninclude only a subset of the potential predictor variables. For\nexample, perhaps measuring additional predictor variables is\nexpensive, or takes a long time, so we will want to keep the\nnumber to a minimum. For these and other reasons, statisticians\n101\n\nStatistics\nhave developed methods for finding good subsets of variables,\nwhere ‘good’ means that they yield the best predictions.\nRegression models relate an outcome or response variable to\none or more predictor variables. This is an extremely common\ntype of problem, and other statistical models have been\ndeveloped to cope with similar situations which differ in some\nways from the straightforward regression situation. Insurvival\nanalysis, for example, the value of the response variable is\nknown only for some of the cases, and its value for the other cases\nknown only to exceed some value. This arises most commonly\n(though certainly not only) when the response variable is time\nduration. Thus, we might want to know how long a patient will\nsurvive (hence the name of the technique) or how long a\ncomponent of a system will last before requiring replacement.\nTaking the first case to illustrate, our data set might show that one\nof the patients lived 5 months, another only 2 months, three\nothers lived 11 months, and so on. However, for practical reasons\nperhaps we could not wait until the last patient in the study had\ndied (which might be years hence), so we stopped taking\nobservations. All we would then know about some of the patients\nis that they livedlongerthan the time between starting and\nstopping observations. Such data are described ascensored.\nTo illustrate the complications they introduce, consider the\ncalculation of the average survival time. To calculate the average,\nwe need to add up the observed times and divide by how many\nthere are. Now we do not actually observe the survival times for\nthose patients who have been censored, so we cannot include them\nin the calculation. But if we leave them out, we will be leaving out\nprecisely those values which are largest, so our estimate will be\nbiased downwards. Conversely, if we include them, using the\nobserved durations, the result will depend on when we happened\nto choose to stop making our observations. Since this is equally\ninappropriate, more sophisticated methods have been developed\nwhich cope with censored data.\n102\n\nStatistical models and methods\nAnother variant on the problem of having a single outcome\nvariable related to one or more predictor variables occurs in\nanalysis of variance.Thisiswidelyusedinagriculture,\npsychology, industrial quality control, manufacturing, and other\nareas. In analysis of variance, the predictor variables are\ncategorical, meaning that they each take only a few values. For\nexample, in manufacturing some chemical we might be able to\ncontrol temperature, pressure, and duration, and have three\nsettings for each: low, intermediate, and high. This sort of\nsituation arose when we discussed experimental design in\nChapter 3, and analysis of variance is often used to analyse\nexperiments. Although typically presented as rather different from\nregression analysis, it is possible to reformulate it as a regression\nmodel. Both are special cases of a broader class of model called a\nlinear model.\nLinear models themselves have been extended in various ways.\nOne very important generalization is to so-calledgeneralized\nlinear models. In regression and analysis of variance, the aim is to\npredict the mean value of the response at each value of the\npredictor(s). Generalized linear models extend this by permitting\nother parameters of the distribution of the response, not merely its\nmean, to be the subject of the prediction.\nYet another variant of the outcome/predictor structure arises\nwhen the response is itself categorical. For example, the response\nmight be a list of possible medical diagnoses, and the predictors\nmight be a combination of symptoms (perhaps coded as present or\nabsent) and the results of medical tests. Such methods go under\nthe general name ofsupervised classification.Themostimportant\nspecial case of such models arises when the response variable is\nbinary, taking only two possible values, such as sick/healthy, good\nrisk/bad risk, profitable/unprofitable, spoken word ‘yes’/spoken\nword ‘no’ (in speech recognition), authorized fingerprint/\nunauthorized fingerprint (in biometrics recognition systems),\n103\n\nStatistics\nfraudulent transaction/legitimate transaction, and so on. In each\ncase, the aim will be to construct a model which will enable us to\ndetermine the most likely category of new cases, using only the\ninformation in the predictor variables.\nA large number of statistical tools have been developed for such\nsituations. Amongst the earliest waslinear discriminant analysis,\ndescribed in the 1930s but still very widely used today, both in its\nbasic form and in more elaborate extensions. Another method\nwhich is very popular in some domains, such as medicine and\ncustomer value management, islogistic discriminant analysis.\nThis is a variant of logistic regression, a type of generalized linear\nmodel, so showing the close link between the classes of tools. In\nfact, logistic regression can be regarded as the most basic kind of\nneural network. Neural networks are so called because they were\noriginally suggested as models for the way the brain worked.\nNowadays, however, the work in the area has largely focused on\ntheir statistical properties as prediction systems, regardless of\nwhether or not they form good models of natural systems.\nOther models for supervised classification includetree classifiers\nandnearest neighbourmethods. A tree model splits variables into\nranges, and classifies new points according to the combination of\nranges in which they lie. For example, analysis of the data might\nshow that people who are aged over 50, have a sedentary lifestyle,\nand have a body mass index greater than 25 are at risk of heart\ndisease. Such models can be represented as tree structures; hence\nthe name. In a nearest-neighbour method, we find the few objects\nin the data set which are most similar (or ‘nearest’) to the new\nobject to be classified, where similarity is defined in terms of the\npredictor variables. Then the new object is simply assigned to the\nsame class as the majority amongst these most similar objects.\nSupervised classification is so called because it needs someone\n(a ‘supervisor’) to provide the class labels for a sample of data,\nfrom which we can construct the classification rule to apply to new\n104\n\nStatistical models and methods\nobjects. In other classification problems, however, there is no\nexisting class label, and the aim is simply to divide up the objects\ninto natural, or perhaps convenient classes. We might say that the\naim is to define the classes. In medicine, for example, we might\nhave a sample of patients for each of whom we have details of their\nsymptom patterns and test results, and we might suspect that\nseveral distinct types of disease are represented in the sample.\nOur aim, then, would be to see if the patients form distinct groups,\nin terms of their symptoms and test results. Statistical tools for\nexploring such groupings are calledcluster analysis.Such\nmethods were helpful in identifying the distinction between\nunipolar and bipolar depression, and are used in a wide variety of\nother areas – including, for example, customer value management\nand marketing, where interest lies in deciding if there are different\ntypes of customer.\nIn cluster analysis, there is no ‘outcome’ or ‘response’ variable.\nRather, the aim is simply to describe the data in a convenient way.\nOther statistical tools have the same objective, though the sort of\ndescription they seek is completely different. For example, a\ngraphical modelis a simplified description of the relationships\nbetween several, possibly a large number, of variables, based on\nthe assumption that the relationships between many of the\nvariables are caused by intermediate relationships with other\nvariables. We saw a very simple example of this above: perhaps the\npositive correlation between reading ability and arithmetic ability\nof children was a consequence of the relationship between each of\nthese variables and age.\nSuch models can be extended by supposing that some of the\nrelationships are caused by unmeasuredlatentvariables which are\nrelated to some of the observed variables and hence induce an\napparent relationship between them. For example, we might\nobserve that the stock market prices of certain companies increase\nor decrease together. One way to explain this might be to\nconjecture the existence of some unobserved variable (some aspect\n105\n\nStatistics\nof the economy, for example), which is related to each of the\nprices, and which therefore induces the correlation between them:\nwhen the unobserved variable increases, so do all of the prices.\nSuch ideas underliefactor analysismodels: the latent variable is\noften called a latentfactor. They also underliehidden Markov\nmodels, in which a sequence of observed values is explained in\nterms of the hidden states of a system. For example, patients with\nsome diseases fluctuate in quality of life, sometimes relapsing and\nsometimes making temporary recoveries. Such progression can be\nmodelled in terms of changing underlying states.\nIf classification methods are named after the sorts of problems\nthey are designed to solve, other methods are named after the\nnature of the data on which they work.Time series analysis\nmethods, for example, work on time series: repeated observations\nof the same variable or variables, at a sequence of times. Such data\nstructures are ubiquitous, occurring in economics (e.g.\nmeasurements of inflation, GDP, and unemployment),\nengineering, medicine (e.g. intensive care units), and any number\nof other domains. In analysing a time series, we might be aiming\nto understand it, to decompose it into key components (e.g. trend,\nseasonality), to detect when system behaviour changes, to detect\nanomalies (e.g. earthquake prediction), to forecast likely future\nvalues, or for a host of other reasons. A wide variety of methods\nhave been developed for analysing such data.\nStatistical graphics\nOne particular class of statistical tools is so important that it\ndeserves special mention. This is the use of graphics. The human\neye has been honed by aeons of evolution to be able to perceive\nstructures and patterns in the signals reaching it. Statisticians\nmake extensive use of this by representing data in a huge range of\ndifferent kinds of graphical display. When data are displayed well,\nrelationships between variables or configurations in data become\nobvious. This is used both in analysing data, to help understand\n106\n\nStatistical models and methods\n6. A ‘scatterplot matrix’, showing the times (in seconds) for the\n100-metre and 400-metre sprint, and the distances (in metres) for the\nshot and discus for competitors in the men’s decathlon in the 1988\nOlympic Games. Each square shows the relationship between two of\nthe four variables. The strong correlation between the scores in the\ntwo throwing events is immediately apparent\nwhat is going on (recall the distribution of baseball salaries in\nFigure 1), and for communicating the findings to others. Some\nillustrations are given in Figures 6 to 8.\nConclusion\nThis chapter has presented a lightning review of just a few\nimportant statistical tools, but there are a great many others I\nhave not mentioned. Different models are suited to different kinds\n107\n\nStatistics\n7. A time series plot showing the amount withdrawn from an ATM\nmachine each day. The figure clearly shows that there are weekly and\nmonthly cycles, and also that there is a gradually increasing trend over\ntime. An anomalously low value near the end of the period is also\napparent\n8. Distribution of the light scatter values from phytoplankton cells of\ndifferent species. In fact, three species are shown here, but two of them\nhave very similar distributions of values, so these combine to form a\nsingle high peak\n108\n\nStatistical models and methods\nof problems and different kinds of data, and there is an unlimited\nnumber of problems and data structures. It is also important to\nappreciate that models are not isolated entities. The truth is that\ndifferent models are related in multiple ways. They may generalize\nor be special cases of other kinds of models or be adapted to\ndifferent kinds of data, but they are all embedded in a rich\nnetwork of relationships.\n109\n\nChapter 7\nStatistical computing\nThe actual magic comes from our statistical analysis team.\nSam Alkhalaf\nStatistics changes its spots\nIn the discussions above we saw that overfitting could be a\nproblem. We also left the solution rather in the air, simply saying\nthat it was necessary to choose models which were neither too\ncomplicated nor too simple. Without substantial experience in\nstatistical modelling that is not very helpful advice, and more\nobjective approaches are needed. One is based on the principle of\ncross-validation.\nWe have seen that, in general, as the complexity of a model\nincreases, so its goodness of fit to the available data continues to\nimprove but that its goodness of fit to other samples drawn from\nthe same distribution (or its ‘out of sample performance’) typically\ninitially improves but then begins to deteriorate. Here the ‘other\nsamples’ are representative of new data, which is what we are\nreally interested in. The point at which the model best fits data\nfrom some ‘other sample’ would seem to give a model of the\nappropriate level of complexity. And that is the key to the solution:\nwe should estimate the model’s parameters using one sample, and\nevaluate its performance using some other sample.\n110\n\nStatistical computing\nUnfortunately, we typically have only one sample. One approach is\ntherefore to (randomly) split this sample into two subsamples.\nOne subsample (thetrainingordesign sample) is used for\nparameter estimation and the other (thevalidation sample)for\nassessing performance and choosing the model. This is the\ncross-validation approach. Typically, to ease any problems arising\nfrom the fact that the subsample used for estimating the\nparameters is not the entirety of the original sample, the\nprocedure is repeated multiple times. That is, the original sample\nis randomly divided into two, parameters are estimated using one\nsubsample, and the model is evaluated using the other. This is\nrepeated for different random divisions of the sample. Finally, the\nevaluation results from each split are averaged, to yield an overall\nmeasure of likely future performance.\nCross-validation is an example of acomputationally intensive\napproach – so called for the obvious reason that multiple models\nhave to be built. Another important class of such methods is\nbootstrap resampling. Bootstrap methods have a variety of uses,\nbut one important one is estimating the uncertainty associated\nwith complex models; that is, determining how different we might\nexpect the model to be if we had drawn a different sample of data.\nBootstrap methods work by taking random subsamples of the\nsame size as the original sample from the original sample (which\nmeans some data points will be used more than once). A new\nmodel, of the same form as that being evaluated, is built on each of\nthese subsamples. It is as if we had multiple samples, all of the\nsame size, from the original distribution, each yielding an\nestimated model. This collection of models can then be used to\ninvestigate how different the model would have been, had we\ndrawn a different sample.\nOne of the most striking illustrations of how the power of the\ncomputer has changed modern statistics is in the impact of\ncomputer-intensive methods on the Bayesian approach to\ninference, described in Chapter 5. To use Bayesian methods in\n111\n\nStatistics\npractice, it is necessary to calculate complicated functions of\ndistributions (in mathematical terms, high-dimensional\nintegrations are needed). The computer has allowed this problem\nto be sidestepped. Instead of evaluating the distributions\nmathematically, the computer draws large numbers of random\nsamples from them. The properties of the distributions can be\nestimated from these random samples, in just the same way that\nwe used the sample mean to estimate the mean of a population.\nSuchMarkov chain Monte Carlomethods have revolutionized the\npractice of Bayesian statistics, essentially transforming it from a\ntheoretically attractive but practically limited set of ideas to a\npowerful technology for data analysis.\nThe previous chapter drew attention to the power of graphical\nmethods, for both elucidation and communication, but the\ncomputer has shifted graphical methods to an altogether new\nplane. Whereas, in the past, we might have had static black and\nwhite images, we now have dynamic colour images. Even more\nimportantly, we can now interact directly with the image. To take\njust one simple example, it is possible to simultaneously display\nmultiple plots, each one showing the relationships between\ndifferent pairs of variables associated with the objects, like the\nscatterplot matrix in Figure 6, but now with the displays linked via\nthe computer. Then highlighting or otherwise manipulating a set\nof points manifests itself simultaneously in all the plots. Other\ntools allow one to dynamically ‘fly’ through high-dimensional data\nspaces, displaying the data in multiple ways.\nBecause statistics is used so universally, and because the computer\nplays such a central role, it is hardly surprising that user-friendly\nstatistical software packages have been developed. Some of these\nare so important that they have become industry standards in\ncertain application areas. But this should not lead us to forget that\neffective application of statistical tools requires careful thought.\nIndeed, in the early days of the development of statistical software,\nsome feared that the availability of such tools would remove the\n112\n\nStatistical computing\nneed for the statistician, since then ‘anyone could do a statistical\nanalysis: all they had to do was give the computer appropriate\ninstructions’. The fact is, however, that the reverse has proven to\nbe the case. There is more and more demand for statisticians as\ntime goes on. There are several reasons for this.\nOne reason is that, increasingly, data are recorded automatically.\nIn everyday life, every time you make a credit card purchase or\nshop in a supermarket, details of the transaction are automatically\nstored; in the natural sciences, digital instruments record physical\nand chemical properties without needing human intervention; in\nhospitals, electronic devices automatically monitor patients; and\nso on. We are faced with a data avalanche. This represents a\ntremendous opportunity, but statistical skills are needed to take\nadvantage of it.\nA second reason is that new areas requiring statistical skills are\nappearing. Bioinformatics and genomics are teasing apart the\nawesome complexity of the human body from experimental and\nobservational data, and are based on statistical inference. The\nhedge fund industry has been described as ‘an industry built on\nstatistics’. It uses statistical tools to model how stocks and other\nprice indices behave.\nA third reason is that it is one thing to give commands to a\ncomputer, but it is quite another to know what commands to give\nand to understand the results. It is certainly not merely a question\nof choosing the right tool for the job and letting the computer do\nthe rest. It requires statistical expertise and understanding. For an\namateur, it is important to know one’s limits, and when one should\ncall on the advice of an expert statistician. Regrettably, every week\nthe media provide illustrations of people who are stretching\nthemselves beyond their statistical understanding.\nFor these reasons and more, statistics is experiencing a golden\nage.\n113\n\nStatistics\nWe have now reached the end of this very short introduction. We\nhave seen something of the extraordinary breadth of statistics: the\nfact that it is applied in almost all walks of life. We have seen\nsomething of its methods: the sophisticated tools and procedures\nit uses. We have also seen that it is a dynamic discipline, still\ngrowing and developing. Above all, however, I hope I have made\nit clear that modern statistics, based on deep philosophical\nfoundations, is the art of discovery. Modern statistics enables us to\ntease out the secrets of the universe around us. Modern statistics\nenables understanding.\n114\n\nFurther reading\nChapter 1\nA. R. Jadad and M. W. Enkin,Randomised Controlled Trials:\nQuestions, Answers and Musings, 2nd edn. (Malden,\nMassachusetts: Blackwell Publishing, 2007).\nJoel Best,Damned Lies and Statistics: Untangling Numbers from the\nMedia, Politicians, and Activists(Berkeley: University of California\nPress, 2001).\nJohn Chambers, Greater or lesser statistics: a choice for future\nresearch,Statistics and Computing, 3 (1993): 18–24.\nFoundation for the Study of Infant Death.<http://www.fsid.org.uk/\ncot-death.html>. Accessed 6 April 2007.\nHelen Joyce, Beyond reasonable doubt,Plus Magazine(2002).\n<http://www.plus.maths.org/issue21/features/clark/index.html>.\nAccessed 14 July 2008.\n<http://www.sallyclark.org.uk/>. Accessed 14 July 2008.\nChapter 2\nD. J. Hand,Information Generation: How Data Rule Our World\n(Oxford: Oneworld, 2007).\nF. Daly, D. J. Hand, M. C. Jones, A. D. Lunn, and K. McConway,\nElements of Statistics(Harlow: Addison-Wesley, 1995).\nChapter 3\nS. Benvenga, Errors based on units of measure,The Lancet,363\n(2004): 1368.\n115\n\nStatistics\nT. L. Fine,Theories of Probability: An Examination of Foundations\n(New York: Academic Press, 1973).\nChapter 4\nD. R. Cox,Principles of Statstical Inference(Cambridge: Cambridge\nUniversity Press, 2006).\nH. S. Migon and D. Gamerman,Statistical Inference: An Integrated\nApproach(London: Arnold, 1999).\nChapter 5\nD. C. Montgomery,Design and Analysis of Experiments(New York:\nJohn Wiley and Sons, 2004).\nL. Kish,Survey Sampling(New York: John Wiley and Sons, 1995).\nChapter 6\nG. E. P. Box, Robustness in the strategy of scientific model building,\ntechnical report, Madison Mathematics Research Center,\nWisconsin University, 1979.\nE. Tufte,The Visual Display of Quantitative Information(Cheshire,\nCT: Graphics Press, 2001).\nA. Unwin, M. Theus, and H. Hofmann,Graphics of Large Data Sets:\nVisualising a Million(New York: Springer-Verlag, 2006).\n116\n\nEndnote\nIn Chapter 1, answers to elementary misunderstandings:\n(1) Clearly, the sooner a disease is detected, the longer that patient\nwill still have to live, regardless of any medical intervention.\nSomehow this needs to be taken into account.\n(2) A 25% reduction means the price is reduced by a quarter. But that\nmeans that to get back to the original price you have to increase\nthe reduced price by a third (33%), not a quarter (25%). For\nexample, a 25% discount on an original price of £100 leads to a\nstated price of £75. To get back to the original price we have to\nincrease this by £25, which is 33% of £75.\n(3) This assumes that life expectancy will continue to increase at the\nsame rate as it has increased in the past.\n(4) If one child was gunned down in 1950, the statement would mean\nthat two were gunned down in 1951, four in 1952, eight in 1953,\nsixteen in 1954, and so on. Continuing to double in this way would\nmean that by now more children are gunned down each year than\nthere are people in the world. (This example is from the excellent\nbook by Joel Best, listed in the Further reading.)\n117\n\nThis page intentionally left blank \n\nIndex\nA\nAbraham de Moivre 57\nabsolute scale 25\naccidents 41\nalternative hypothesis 87, 88\nAmerican Statistical Association\n11\nanalysis of variance 103\nAndrei Kolmogorow 57\nanemometer 43\nanomalies 43\nAntoine Cournot 57\narithmetic mean,seemean\nArthur Hailey 6\nastrology 10\nAstronomer Royal 41\nastronomy 3, 11, 15, 41, 74, 94\nastrononomic objects 15–16\nasymmetry 34, 99\nATM machines 108\nattributes 23\nAudrey Habera 6\nautomated editing 44\nautopilots 10\naverage, definition of 27–31\naxioms of probability 57\nB\nbag of tools perspective 21\nbalance 46, 48, 50, 52, 53\nbaseball players 30, 31, 35, 107\nBayesian hypothesis testing 89\nBayesian inference 80, 85, 91, 111\nBayes’s rule 62\nBayes’s theorem 62–3, 80\nbell-shaped distribution 70\nBenjamin Disraeli 5\nBernoulli distribution 68–72, 76,\n81\nbias49,54,82–3,84(see also\nselection bias)\nbinomial distribution 68, 69, 71\nBlaise Pascal 57\nblood pressure 41\nbody mass index 98, 104\nbootstrap resampling 111\nBritish Crime Survey 6\nBritish Empire 41\nC\ncalcium 42\ncalibration 43\ncensored data 102\ncensus 3, 41, 44\nCentral limit theorem 52, 73\nChallenger space shuttle 38\ncharacteristics 23\nCharles Goodhart 7\nchemicals 16–17, 103, 113\nchi-squared test 89\nChristiaan Huygens 57\nclassical inference,see\nfrequentist inference\nclassical probability,see\nprobability\nClimate Orbiter Mars probe 42\nclinical trial 9, 37, 45, 48, 49, 50,\n75\ncluster analysis 105\ncluster sampling 53\ncomplexity of models 97, 110\ncomputationally intensive\nmethods 111\ncomputer error 45\nconditional probability,\ndefinition of 61\nconfidence intervals 85\nconfirmation 94\nConsumer Price Index 19\n119\n\nStatistics\ncontinuous random variable 69,\n70\ncorrelation 97–9\ncorrelation coefficient 97–9\ncredibility intervals 85\ncredit card 3, 18, 19, 22, 38, 113\ncredit score 38\ncrime 3, 6, 7, 8, 40\ncritical region 86\ncross-validation 110\ncumulative probability\ndistribution 65–6\ncurvature 101\ncustomer satisfaction 17–18\ncustomer value management 47,\n104\nD\ndata, as evidence 9, 25\ncapture 45\ncollection cost 47, 52\nmining 12\nnature of 9–11, 22–6\norigin of word 4\npreprocessing 43–5\nquality 4, 13, 36–42\ndatum 4\nDavid Kinnebrook 41\ndecile 35\ndecision rule 89, 90\ndecision theory 89–90\ndegree of belief 57, 58, 85\ndependence,seeindependence,\ncorrelation\ndesign sample 111\ndiagnosis 8, 103\ndie 59, 62, 63, 65\ndiet 7, 23, 95, 98\ndirty data 36, 37\ndiscrete random variable 69\ndispersion, definition of 31–4\ndistribution, definition of 26\ndistributions 64–74\ndouble blind 49\ndrop outs 37\ndrug 13, 26, 75, 76, 85, 86, 87, 93\nE\neconomic indicators 10\nequally likely events 59\nerror propagation 42\nestimation 75–84 (see also\nmaximum likelihood,\nleast squares estimation,\npoint estimation,\ninterval estimation)\nethical issues 50\nevidence, data as 9\nexperimental design 17, 47,\n48–50, 52, 103\nexperimental study 45, 46, 47\n(see alsoexperimental\ndesign)\nexploration 94\nexponential distribution 70–2\nextreme values 30, 43\nF\nfactor analysis 106\nfactorial experiment 50\nfarmer 2, 25, 49, 50\nfeatures 23\nfertilizer 49, 50\nforecast 3, 38, 96, 106\nFoundation for the Study of\nInfant Death 15\nfraud3,18–19,104\nfrequentist inference 80, 81, 82,\n91\nfrequentist probability,see\nprobability\nG\ngalaxy 16, 45, 47\ngarbage in, garbage out 54\n120\n\nIndex\nGaussian distribution 70 (see also\nnormal distribution)\nGDP 10, 106\ngeneralized linear model\n103\nGeorge Box 93\nglass vases 69–70, 72–3\nGoodhart’s Law 7\ngoodness of fit 110\nGoogle 5\ngraphical model 105\ngraphics 106–9, 112\ndynamic 112\ngreater statistics 11–12\nGreenwich 41\nH\nHelen Joyce 15\nhidden Markov model 106\nhypothesis testing 85–9\nI\nincomplete data 37–40\nincorrect data 40–2\nindependence 60–1\ninflation10,19,20,98,106\ninsurance 3, 40\nintensive care units 10\ninteraction 50\ninterval estimation 83–5\nJ\nJacob Bernoulli 57\nJean Baudrillard 5\nJohn Venn 57\njoint probability 61–3\nK\nKolmogorov’s axioms 57\nL\nLandon 38\nlatent variable 105\nlaw of large numbers 47, 52, 56,\n60,72,73,88\nlaws of chance 60–3\nleast squares estimation 79\nleast squares regression line 101\nleft skewed 34\nlikelihood function 78\nlikelihood principle 91\nlinear discriminant analysis 104\nlinear model 103\nLiterary Digest 38\nloan 38, 39, 45\nlocal group of galaxies 16\nlocal supercluster 16\nlogistic discriminant analysis 104\nlogistic regression 104\nlong tail 34\nlower quartile 35\nM\nmachine learning 12\nMann-Whitney test 89\nmanufacturing 16–17, 20, 46, 47,\n103\nMark Twain 5\nMarkov chain Monte Carlo 112\nMartian atmosphere 42\nmaximum likelihood 78\nmean squared deviation 33\nmean squared error 83\nmean, comparison with median\n29–30\ndefinition of 27–8\nmedian, comparison with mean\n29–30\ndefinition of 29\nmeridian 41\nmessy data 36\nmicroarray 22\nmissing data 37–40, 54\n121\n\nStatistics\nmode 30\nmodel complexity 97, 110\ndefinition of 92–7\ndescriptive 95\nempirical 93–4\nmechanistic 93–4\npredictive 95\nN\nNational Patient Safety Agency 41\nnational statistical office 11\nnearest neighbour methods 10\nnegative correlation,see\ncorrelation\nneural network 104\nNeville Maskelyne 41\nNeyman-Pearson hypothesis\ntesting 87\nnon-response 39, 54\nnormal distribution 70–1, 73, 76,\n78, 81\nnull hypothesis 87–9\nO\nobservational study 45–7\nOccam’s razor 97\nOlympic Games 107\nordinal scale 25\noutlier 43, 44\noutlying points 34 (see also\noutlier)\noverfitting 97, 101, 110\nP\nparameter, definition of 72\nestimation of 75–84\nparameters, large numbers of 97\nparticle 22, 44, 94\npattern recognition 12\npercentile 35, 65\npersonal probability,see\nprobability\nphytoplankton 108\nPierre de Fermat 57\nPierre Simon Laplace 57\nplacebo 50\npoint estimation 76–81\nPoisson distribution 69, 71\npositive correlation,see\ncorrelation\nposterior distribution 79–81, 85,\n90\npower of statistical test 88\npreprocessing data 36, 43–5\nprior distribution 79–81\nprior knowledge 59 (see also\nprior distribution)\nprobability 55–74\ncalculus 57, 60\ndensity function 66–74\ndistribution 65–74\nclassical 59\nfrequentist 58, 59\nhistory 11\nin definitions of statistics 2\npersonal 58\nrules of 48, 55–74\nsubjective 58\nProsecutor’s fallacy 8, 62\np-value 88\nQ\nquality control 103\nquantile 35\nquartile 35\nquestionnaire 9, 18, 25, 37, 38, 39\nR\nrandom allocation 48, 49, 52\nsampling 52, 53\nvariable 64–74\nvariable, definition of 65\n122\n\nIndex\nrandomization 47, 50\nrandomized clinical trial 48, 49,\n75\ncontrolled trial 2\nrange 32, 33, 34, 84, 85\nratio scale 25\nreading ability 46, 47, 105\nRecorded Crime Statistics 6\nregression 99–102, 103\nrejection region 86\nrepeated sampling principle\n91\nrepresentative sample 9, 37, 38,\n39, 51, 52, 53, 110\nrepresentative value,see\naverage, mean, median,\nmode\nresponse surface 17\nRetail Price Index 19\nRichard Runyon 6\nright skewed 34, 35\nRoosevelt 38\nRoy Meadow 14\nRoyal Statistical Society 11\nS\nsalaries 20, 30, 31, 32, 34, 35, 54,\n96, 97, 107\nSally Clark 14–15, 61\nSalvatore Benvenga 42\nsample,seesurvey sampling,\nrepresentative sample,\nrandom sampling\nsampling frame 53\nsatellite images 5\nSatNav systems 10\nscatterplot matrix 107\nselection bias 37, 39\nside effects 50\nsignificance testing 85–9\nSiméon-Denis Poisson 57\nsimple random sampling 53\nskewness 34, 35\nsoftware 112\nspace shuttle 38\nspam 3, 13–14\nspeed of light 75\nsphygmomanometer 41\nstandard deviation 33, 34, 73, 76,\n84, 85, 95\ndefinition 33\nstar 3, 15, 16, 26, 41\nstatistic, definition of 3\nStatistical Science 3\nstatistics discipline, definitions of\n2–3\nstratified sampling 53\nsubjective probability,see\nprobability\nsufficiency principle 91\nsuicide 40\nsummaries of data 95\nsummary statistics 26–35\nsupervised classification 103,\n104\nsurvey sampling 47, 51–4\nsurveys 44, 47, 74\naims 47\npilot 45\nsurvival analysis 102\nsymmetry 59, 99\nsynaesthesia 24\nT\ntail 34, 43\nteaching method 46, 47, 49\ntest scores 23, 28, 29, 33\ntests, statistical 85–9\ntime series analysis 106\ntime series plot 108\nTom Burnan 5\ntraining sample 111\ntreatment 47, 48, 49, 50, 51, 85,\n86\ntree classifiers 104\nt-test 89\n123\n\nStatistics\ntype I error 87, 88\ntype II error 88\nU\nunbiased estimate 82–3\nuncertainty 2, 3, 13, 55–7, 111\nunemployment 76, 98, 106\nuniform distribution 69\nunits of measurement 26, 33, 42\nUniversity College, London 11\nupper quartile 35\nUS Presidential election 38, 51\nutility function 89\nV\nvalidation sample 111\nvariable, definition of 23\nvariance, definition of 33\nviagra 14\nW\nWald test 89\nweb search 5\nweight 23, 25, 26, 28, 42, 48, 65,\n66, 67, 68, 85, 98, 99,\n100, 101\n124",
      "metadata": {
        "pages": 137,
        "info": {
          "PDFFormatVersion": "1.6",
          "IsAcroFormPresent": false,
          "IsXFAPresent": false,
          "Title": "Statistics: A Very Short Introduction (Very Short Introductions, 196)",
          "Author": "David J. Hand",
          "Subject": "Oxford University Press, USA ",
          "Keywords": "ISBN-13:    9780199233564",
          "CreationDate": "D:20100207164847+01'00'",
          "ModDate": "D:20100207164934+01'00'"
        },
        "metadata": {
          "_metadata": {
            "xmp:modifydate": "2010-02-07T16:49:34+01:00",
            "xmp:createdate": "2010-02-07T16:48:47+01:00",
            "xmp:metadatadate": "2010-02-07T16:49:34+01:00",
            "dc:format": "application/pdf",
            "dc:title": "Statistics: A Very Short Introduction (Very Short Introductions, 196)",
            "dc:description": "Oxford University Press, USA",
            "dc:creator": "David J. Hand",
            "dc:subject": "ISBN-13:9780199233564",
            "xmpmm:documentid": "uuid:b7b6ee87-98c5-4233-85c5-470ae89bfdc7",
            "xmpmm:instanceid": "uuid:1a012c0a-7f7b-4384-9e6e-fa83b0acca2e",
            "pdf:keywords": "ISBN-13:    9780199233564"
          }
        }
      }
    }
  }
]